\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrtnat}
\citation{schechter2017converting}
\citation{genthial2016image}
\citation{bian2022handwritten}
\@writefile{toc}{\contentsline {section}{\numberline {1}Github Link}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Related work}{1}{section.3}\protected@file@percent }
\citation{transformer}
\citation{visiontransformer}
\citation{kanervisto_2016_56198}
\citation{gervais2024mathwritingdatasethandwrittenmathematical}
\citation{kanervisto_2016_56198}
\citation{gervais2024mathwritingdatasethandwrittenmathematical}
\@writefile{toc}{\contentsline {section}{\numberline {4}Dataset and Features}{2}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Formulas breakdown by length}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:formula_length}{{1}{2}{Formulas breakdown by length}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methods}{2}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}CNN encoder and GRU/LSTM}{2}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Encoder architecture consists of 3 convolution-max pooling blocks (50,200) -> (25,100) -> (12,5) which is flattened and fed into Dense layer (256 units) }}{3}{figure.2}\protected@file@percent }
\newlabel{fig:cnn_lstm}{{2}{3}{Encoder architecture consists of 3 convolution-max pooling blocks (50,200) -> (25,100) -> (12,5) which is flattened and fed into Dense layer (256 units)}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}LSTM with funetuning with pretrained Resnet50}{3}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Pretrained ResNet50 Encoder with LSTM Decoder.}}{3}{figure.3}\protected@file@percent }
\newlabel{fig:resnet_lstm}{{3}{3}{Pretrained ResNet50 Encoder with LSTM Decoder}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Vision transformer encoder and transformer decoder}{3}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Vision Transformer Encoder}{3}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Original latex image and the generated patches}}{3}{figure.4}\protected@file@percent }
\citation{transformer}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Transformer encoder architecture}}{4}{figure.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Vision Transformer Decoder}{4}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Transformer encoder architecture from \cite  {transformer}}}{4}{figure.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments}{4}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Setup/Hyperparameters/Metrics}{4}{subsection.6.1}\protected@file@percent }
\citation{*}
\bibdata{final_report}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}CNN-RNN baseline}{5}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Results}{5}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion/Future Work}{5}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Contributions}{5}{section.8}\protected@file@percent }
\bibcite{schechter2017converting}{{1}{2017}{{Schechter et~al.}}{{Schechter, Borus, and Bakst}}}
\bibcite{genthial2016image}{{2}{2017{a}}{{Genthial and Sauvestre}}{{}}}
\bibcite{bian2022handwritten}{{3}{2022}{{Bian et~al.}}{{Bian, Qin, Xin, Li, Su, and Wang}}}
\bibcite{transformer}{{4}{2023}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{visiontransformer}{{5}{2021}{{Dosovitskiy et~al.}}{{Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby}}}
\bibcite{kanervisto_2016_56198}{{6}{2016}{{Kanervisto}}{{}}}
\bibcite{gervais2024mathwritingdatasethandwrittenmathematical}{{7}{2024}{{Gervais et~al.}}{{Gervais, Fadeeva, and Maksai}}}
\bibcite{DengKR16}{{8}{2016}{{Deng et~al.}}{{Deng, Kanervisto, and Rush}}}
\bibcite{abs-1908-11415}{{9}{2019}{{Wang and Liu}}{{}}}
\bibcite{cs230:1}{{10}{2018}{{Wang and Liu}}{{}}}
\bibcite{cs230:2}{{11}{2017{b}}{{Genthial and Sauvestre}}{{}}}
\bibcite{DBLP:journals/corr/abs-2003-00817}{{12}{2020}{{Wang and Shan}}{{}}}
\bibcite{gurgurov2024imagetolatexconvertermathematicalformulas}{{13}{2024}{{Gurgurov and Morshnev}}{{}}}
\bibcite{OSheaN15}{{14}{2015}{{O'Shea and Nash}}{{}}}
\bibcite{6795963}{{15}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{papineni-etal-2002-bleu}{{16}{2002}{{Papineni et~al.}}{{Papineni, Roukos, Ward, and Zhu}}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Appendix}{7}{section.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Dataset: Most popular symbols and frequencies.}}{7}{figure.7}\protected@file@percent }
\newlabel{fig:vocab_freq_1}{{7}{7}{Dataset: Most popular symbols and frequencies}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Dataset: Least popular symbols and frequencies.}}{7}{figure.8}\protected@file@percent }
\newlabel{fig:vocab_freq_2}{{8}{7}{Dataset: Least popular symbols and frequencies}{figure.8}{}}
\gdef \@abspage@last{7}
