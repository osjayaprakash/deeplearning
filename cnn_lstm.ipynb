{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/osjayaprakash/deeplearning/blob/main/cnn_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kta8EgzKhJZZ"
   },
   "source": [
    "\n",
    "```\n",
    "## This is formatted as code\n",
    "python3 -m venv ~/cs230\n",
    "source ~/cs230/bin/activate\n",
    "pip3 install kagglehub kaggle tensorflow tensorflow-macos tensorflow-metal\n",
    "brew install hdf5\n",
    "pip install line_profiler\n",
    "\n",
    "## AMAZON AWS\n",
    "sudo apt update\n",
    "sudo apt install nvidia-driver-535\n",
    "reboot  # Restart the system after installation\n",
    "\n",
    "nvidia-smi\n",
    "\n",
    "## Verify that the GPUs are available\n",
    "python3\n",
    "import tensorflow as tf\n",
    "tf.sysconfig.get_build_info()\n",
    "python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices());\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKAOqBE2Wzwj"
   },
   "outputs": [],
   "source": [
    "!pip install line_profiler\n",
    "!pip install memory_profiler\n",
    "!pip install kagglehub\n",
    "!pip install matplotlib pandas scikit-learn scipy tensorflow\n",
    "!pip install tensorflow[and-cuda]\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xZgd8NVaFjfO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Path to dataset files: /home/ubuntu/.cache/kagglehub/datasets/shahrukhkhan/im2latex100k/versions/7\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "root_dir = kagglehub.dataset_download(\"shahrukhkhan/im2latex100k\")\n",
    "# path = kagglehub.dataset_download(\"gregoryeritsyan/im2latex-230k\")\n",
    "\n",
    "print(\"Path to dataset files:\", root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "6TKz3RA-FuOp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Linux-5.15.0-1044-aws-x86_64-with-glibc2.29\n",
      "Tensor Flow Version: 2.13.1\n",
      "\n",
      "Python 3.8.10 (default, Nov  7 2024, 13:10:47) \n",
      "[GCC 9.4.0]\n",
      "Pandas 2.0.3\n",
      "Scikit-Learn 1.3.2\n",
      "SciPy 1.10.1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Flatten,\n",
    "                                     Dense, GRU, Embedding, Bidirectional,\n",
    "                                     TimeDistributed, Concatenate, RepeatVector, LSTM)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "#print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(f\"SciPy {sp.__version__}\")\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Initialize Tokenizer (Configure it with LaTeX vocabulary)\n",
    "vocab_size = None  # Adjust based on your dataset\n",
    "max_seq_length = 149  # Max length of output sequence\n",
    "RESNET_MODEL = True\n",
    "IMG_SIZE = [50,224,1] # height, width, channels\n",
    "BASE_DIR = \"/Users/jayaprakash/\"\n",
    "#BASE_DIR = \"/home/ubuntu/\"\n",
    "\n",
    "OUTPUT_MODEL_NAME = \"latex_model_cnn_lstm\"\n",
    "EMBEDDING_DIM = 256\n",
    "lstm_units = 265\n",
    "if RESNET_MODEL:\n",
    "    IMG_SIZE = [224,224,3]\n",
    "    OUTPUT_MODEL_NAME = \"latex_model_resnet_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "gbyzYAzjFwap"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, filters='', lower=False)\n",
    "def fit_tokenizer(texts):\n",
    "    \"\"\"Fit the tokenizer on the LaTeX text corpus.\"\"\"\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    # max_seq_length = max(len(seq) for seq in tokenizer.texts_to_sequences(texts))\n",
    "    acutal_max_seq_length = max(len(seq) for seq in tokenizer.texts_to_sequences(texts))\n",
    "    assert max_seq_length >= acutal_max_seq_length,  f\"max_seq_length ({max_seq_length}) should be greater than or equal to acutal_max_seq_length ({acutal_max_seq_length})\"\n",
    "    print(f\"Vocabulary size: {vocab_size}, Max sequence length: {max_seq_length}\")\n",
    "    return vocab_size, max_seq_length\n",
    "\n",
    "def text_to_sequence(text):\n",
    "    \"\"\"Convert LaTeX text to a sequence of tokens.\"\"\"\n",
    "    return tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "def sequence_to_text(sequence):\n",
    "    \"\"\"Convert token sequence back to LaTeX text.\"\"\"\n",
    "    return tokenizer.sequences_to_texts([sequence])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo6QNApGGgIk"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "wAMBW0OFF_VN"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the input image: Resize and normalize.\"\"\"\n",
    "    image = tf.image.resize(image, (IMG_SIZE[0], IMG_SIZE[1]))\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    \"\"\"Load and preprocess a batch of images.\"\"\"\n",
    "    # Use Gray scale\n",
    "    images = [\n",
    "        preprocess_image(\n",
    "            tf.io.decode_image(\n",
    "                tf.io.read_file(path), channels=IMG_SIZE[2]))\n",
    "              for path in image_paths]\n",
    "    return tf.stack(images)\n",
    "\n",
    "def prepare_sequences(latex_texts, max_seq_length):\n",
    "    \"\"\"Convert LaTeX texts to padded sequences of tokens.\"\"\"\n",
    "    sequences = [text_to_sequence(text) for text in latex_texts]\n",
    "    return pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "4NIjhtisIi1W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images: (1000, 224, 224, 3)\n",
      "train_sequences: (1000, 149)\n",
      " CPU times: user 1.61 s, sys: 82.3 ms, total: 1.69 s\n",
      "Wall time: 1.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         960541 function calls (945895 primitive calls) in 1.621 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     6133    0.927    0.000    0.927    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_FastPathExecute}\n",
       "     3039    0.079    0.000    0.084    0.000 constant_op.py:65(convert_to_eager_tensor)\n",
       "     1035    0.053    0.000    0.053    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_Execute}\n",
       "197310/197308    0.021    0.000    0.033    0.000 {built-in method builtins.isinstance}\n",
       "     1000    0.020    0.000    0.923    0.001 image_ops_impl.py:1446(_resize_images_common)\n",
       "7131/4065    0.019    0.000    1.226    0.000 dispatch.py:1162(op_dispatch_handler)\n",
       "    48382    0.017    0.000    0.035    0.000 tensor_shape.py:725(as_dimension)\n",
       "     6210    0.015    0.000    0.161    0.000 tensor_conversion_registry.py:164(convert)\n",
       "     7176    0.013    0.000    0.044    0.000 tensor_shape.py:817(__init__)\n",
       "     1001    0.013    0.000    0.013    0.000 tensor_util.py:978(<listcomp>)\n",
       "     9963    0.013    0.000    0.016    0.000 dtypes.py:787(as_dtype)\n",
       "    12719    0.013    0.000    0.013    0.000 context.py:1010(executing_eagerly)\n",
       "    23786    0.011    0.000    0.012    0.000 {built-in method builtins.getattr}\n",
       "    43318    0.011    0.000    0.014    0.000 tensor_shape.py:201(__init__)\n",
       "8238/3100    0.010    0.000    1.340    0.000 traceback_utils.py:138(error_handler)\n",
       "    26301    0.010    0.000    0.030    0.000 tensor_shape.py:827(<genexpr>)\n",
       "     5061    0.007    0.000    0.041    0.000 ops.py:1238(shape)\n",
       "     2422    0.007    0.000    0.007    0.000 {built-in method tensorflow.python.util._pywrap_utils.Flatten}\n",
       "     1000    0.007    0.000    0.072    0.000 math_ops.py:1569(_truediv_python3)\n",
       "     2017    0.007    0.000    0.045    0.000 tensor_shape.py:1301(is_compatible_with)\n",
       "     2036    0.006    0.000    0.007    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
       "1004/1002    0.006    0.000    0.053    0.000 series.py:368(__init__)\n",
       "     1045    0.006    0.000    0.006    0.000 {method '_numpy_internal' of 'tensorflow.python.framework.ops.EagerTensor' objects}\n",
       "        1    0.006    0.006    1.394    1.394 685174634.py:10(<listcomp>)\n",
       "     3152    0.005    0.000    0.012    0.000 dtypes.py:200(is_compatible_with)\n",
       "     9514    0.005    0.000    0.015    0.000 context.py:2250(executing_eagerly)\n",
       "    12378    0.005    0.000    0.006    0.000 {built-in method _abc._abc_instancecheck}\n",
       "     4124    0.005    0.000    0.014    0.000 ops.py:6178(name_scope)\n",
       "     1000    0.005    0.000    0.117    0.000 gen_io_ops.py:560(read_file)\n",
       "    10174    0.004    0.000    0.021    0.000 tensor_shape.py:908(<listcomp>)\n",
       "     3527    0.004    0.000    0.005    0.000 dtypes.py:248(__eq__)\n",
       "     8122    0.004    0.000    0.006    0.000 ops.py:1111(dtype)\n",
       "     3064    0.004    0.000    0.101    0.000 constant_op.py:267(_constant_impl)\n",
       "        1    0.004    0.004    1.621    1.621 <string>:1(<module>)\n",
       "     1000    0.004    0.000    0.177    0.000 image_ops_impl.py:3252(decode_image)\n",
       "     1000    0.004    0.000    1.087    0.001 685174634.py:1(preprocess_image)\n",
       "     6196    0.004    0.000    0.166    0.000 trace.py:178(wrapped)\n",
       "     6196    0.004    0.000    0.162    0.000 ops.py:1428(convert_to_tensor)\n",
       "     4021    0.004    0.000    0.004    0.000 {method '_shape_tuple' of 'tensorflow.python.framework.ops.EagerTensor' objects}\n",
       "     1008    0.004    0.000    0.008    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
       "     1007    0.004    0.000    0.019    0.000 construction.py:494(sanitize_array)\n",
       "    10174    0.004    0.000    0.024    0.000 tensor_shape.py:896(dims)\n",
       "     3064    0.004    0.000    0.008    0.000 ops.py:1326(__tf_tensor__)\n",
       "     7355    0.004    0.000    0.004    0.000 dtypes.py:83(_is_ref_dtype)\n",
       "     1005    0.003    0.000    0.151    0.000 math_ops.py:1458(binary_op_wrapper)\n",
       "     1000    0.003    0.000    0.097    0.000 gen_io_ops.py:601(read_file_eager_fallback)\n",
       "     4086    0.003    0.000    0.003    0.000 context.py:1032(device_name)\n",
       "     1008    0.003    0.000    0.065    0.000 math_ops.py:1403(maybe_promote_tensors)\n",
       "24928/20910    0.003    0.000    0.004    0.000 {built-in method builtins.len}\n",
       "    29212    0.003    0.000    0.003    0.000 tensor_shape.py:267(value)\n",
       "     2000    0.003    0.000    0.012    0.000 series.py:992(__getitem__)\n",
       "     3004    0.003    0.000    0.023    0.000 generic.py:5975(__getattr__)\n",
       "     1000    0.003    0.000    0.377    0.000 gen_image_ops.py:3661(resize_bilinear)\n",
       "     2411    0.003    0.000    0.013    0.000 nest.py:194(flatten)\n",
       "2005/2003    0.003    0.000    0.311    0.000 deprecation.py:542(new_func)\n",
       "     1002    0.003    0.000    0.029    0.000 tensor_util.py:957(constant_value_as_shape)\n",
       "     1007    0.003    0.000    0.003    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "     5033    0.003    0.000    0.004    0.000 tensor_shape.py:273(is_compatible_with)\n",
       "    12378    0.002    0.000    0.008    0.000 abc.py:96(__instancecheck__)\n",
       "     8240    0.002    0.000    0.011    0.000 traceback_utils.py:32(is_traceback_filtering_enabled)\n",
       "     1002    0.002    0.000    0.004    0.000 generic.py:5931(__finalize__)\n",
       "     7355    0.002    0.000    0.006    0.000 dtypes.py:96(base_dtype)\n",
       "     1008    0.002    0.000    0.012    0.000 np_dtypes.py:102(_result_type)\n",
       "     8164    0.002    0.000    0.003    0.000 tensor_shape.py:889(rank)\n",
       "     1035    0.002    0.000    0.057    0.000 execute.py:28(quick_execute)\n",
       "     1023    0.002    0.000    0.002    0.000 dtypes.py:115(as_numpy_dtype)\n",
       "     3039    0.002    0.000    0.086    0.000 constant_op.py:283(_constant_eager_impl)\n",
       "     1002    0.002    0.000    0.006    0.000 blocks.py:2385(new_block)\n",
       "        1    0.002    0.002    0.002    0.002 c_parser_wrapper.py:60(__init__)\n",
       "     2000    0.002    0.000    0.006    0.000 series.py:1099(_get_value)\n",
       "     1023    0.002    0.000    0.007    0.000 math_ops.py:938(cast)\n",
       "     3064    0.002    0.000    0.103    0.000 constant_op.py:166(constant)\n",
       "     1000    0.002    0.000    0.194    0.000 array_ops.py:4377(squeeze)\n",
       "     1001    0.002    0.000    0.058    0.000 frame.py:1354(iterrows)\n",
       "     1000    0.002    0.000    0.379    0.000 image_ops_impl.py:1739(resize_fn)\n",
       "     2016    0.002    0.000    0.033    0.000 math_ops.py:1437(_promote_or_cast)\n",
       "     2443    0.002    0.000    0.009    0.000 nest_util.py:710(_tf_core_flatten)\n",
       "     2016    0.002    0.000    0.009    0.000 math_ops.py:1386(_maybe_get_dtype)\n",
       "     1000    0.002    0.000    0.924    0.001 image_ops_impl.py:1610(resize_images_v2)\n",
       "     1000    0.002    0.000    0.190    0.000 gen_array_ops.py:10350(squeeze)\n",
       "     1005    0.002    0.000    0.002    0.000 generic.py:265(__init__)\n",
       "     1005    0.002    0.000    0.009    0.000 cast.py:1171(maybe_infer_to_datetimelike)\n",
       "     4007    0.002    0.000    0.031    0.000 ops.py:1251(get_shape)\n",
       "     3057    0.002    0.000    0.002    0.000 tensor_conversion_registry.py:134(get)\n",
       "     1004    0.002    0.000    0.006    0.000 generic.py:5991(__setattr__)\n",
       "     1000    0.002    0.000    0.103    0.000 gen_array_ops.py:2298(expand_dims)\n",
       "     2001    0.002    0.000    0.007    0.000 tensor_shape.py:136(dimension_at_index)\n",
       "        1    0.002    0.002    0.002    0.002 {method 'read_low_memory' of 'pandas._libs.parsers.TextReader' objects}\n",
       "     2000    0.002    0.000    0.002    0.000 base.py:5109(__contains__)\n",
       "     3056    0.001    0.000    0.103    0.000 constant_op.py:321(_constant_tensor_conversion_function)\n",
       "     1000    0.001    0.000    0.049    0.000 gen_math_ops.py:7849(real_div)\n",
       "     2474    0.001    0.000    0.010    0.000 nest_util.py:604(flatten)\n",
       "     1000    0.001    0.000    0.167    0.000 gen_image_ops.py:1002(decode_image)\n",
       "2216/2215    0.001    0.000    0.004    0.000 {built-in method builtins.all}\n",
       "    14891    0.001    0.000    0.001    0.000 context.py:2220(context_safe)\n",
       "     4079    0.001    0.000    0.001    0.000 context.py:968(_handle)\n",
       "     2000    0.001    0.000    0.007    0.000 base.py:5212(_can_hold_identifiers_and_holds_name)\n",
       "     2086    0.001    0.000    0.013    0.000 tensor_shape.py:1521(as_shape)\n",
       "     1003    0.001    0.000    0.003    0.000 config.py:116(_get_single_key)\n",
       "     1044    0.001    0.000    0.010    0.000 ops.py:1117(numpy)\n",
       "     1055    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\n",
       "     2005    0.001    0.000    0.005    0.000 context.py:2867(_tmp_in_graph_mode)\n",
       "     2000    0.001    0.000    0.002    0.000 base.py:3625(get_loc)\n",
       "     2006    0.001    0.000    0.004    0.000 common.py:158(is_object_dtype)\n",
       "     1008    0.001    0.000    0.004    0.000 numeric.py:290(full)\n",
       "     1000    0.001    0.000    0.108    0.000 array_ops.py:312(expand_dims)\n",
       "     1002    0.001    0.000    0.008    0.000 managers.py:1873(from_array)\n",
       "     1008    0.001    0.000    0.043    0.000 ops.py:1279(set_shape)\n",
       "     8123    0.001    0.000    0.001    0.000 {method '_datatype_enum' of 'tensorflow.python.framework.ops.EagerTensor' objects}\n",
       "     2005    0.001    0.000    0.001    0.000 managers.py:2011(internal_values)\n",
       "     1025    0.001    0.000    0.008    0.000 array_ops.py:1524(_should_not_autopack)\n",
       "     2021    0.001    0.000    0.002    0.000 common.py:1494(_is_dtype_type)\n",
       "     1000    0.001    0.000    0.002    0.000 numeric.py:1878(isscalar)\n",
       "     1003    0.001    0.000    0.003    0.000 generic.py:723(_set_axis)\n",
       "     2000    0.001    0.000    0.002    0.000 indexing.py:2609(check_dict_or_set_indexers)\n",
       "       67    0.001    0.000    0.001    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_FinishOperation}\n",
       "     1002    0.001    0.000    0.002    0.000 blocks.py:2305(maybe_coerce_values)\n",
       "     2002    0.001    0.000    0.002    0.000 data_adapter.py:1960(_is_scipy_sparse)\n",
       "     4074    0.001    0.000    0.001    0.000 generic.py:37(_check)\n",
       "     4074    0.001    0.000    0.002    0.000 generic.py:42(_instancecheck)\n",
       "     1008    0.001    0.000    0.010    0.000 math_ops.py:1436(<listcomp>)\n",
       "     6575    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
       "     4056    0.001    0.000    0.001    0.000 array_ops.py:1530(<genexpr>)\n",
       "     4013    0.001    0.000    0.001    0.000 base.py:875(__len__)\n",
       "     1000    0.001    0.000    0.104    0.000 array_ops.py:385(expand_dims_v2)\n",
       "     1006    0.001    0.000    0.003    0.000 series.py:671(name)\n",
       "     1010    0.001    0.000    0.006    0.000 <__array_function__ internals>:177(result_type)\n",
       "     1003    0.001    0.000    0.001    0.000 blocks.py:2334(get_block_type)\n",
       "     1002    0.001    0.000    0.001    0.000 blocks.py:2401(check_ndim)\n",
       "     4090    0.001    0.000    0.001    0.000 context.py:571(ensure_initialized)\n",
       "     1008    0.001    0.000    0.034    0.000 math_ops.py:1443(<listcomp>)\n",
       "       67    0.001    0.000    0.004    0.000 ops.py:1690(_create_c_op)\n",
       "     1003    0.001    0.000    0.001    0.000 config.py:596(_get_root)\n",
       "     1000    0.001    0.000    0.117    0.000 io_ops.py:96(read_file)\n",
       "     2006    0.001    0.000    0.001    0.000 config.py:610(_get_deprecated_option)\n",
       "     1007    0.001    0.000    0.001    0.000 series.py:621(name)\n",
       "     1096    0.001    0.000    0.001    0.000 {built-in method _abc._abc_subclasscheck}\n",
       "      123    0.001    0.000    0.001    0.000 inspect.py:2901(_bind)\n",
       "     1068    0.001    0.000    0.001    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_TapeSetIsEmpty}\n",
       "       35    0.001    0.000    0.019    0.001 op_def_library.py:751(_apply_op_helper)\n",
       "     4347    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
       "     1003    0.001    0.000    0.005    0.000 config.py:134(_get_option)\n",
       "     1008    0.001    0.000    0.001    0.000 tensor_shape.py:1407(as_list)\n",
       "     4100    0.001    0.000    0.001    0.000 ops.py:177(__exit__)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method io.open}\n",
       "     2005    0.001    0.000    0.002    0.000 series.py:718(_values)\n",
       "4405/4101    0.001    0.000    0.001    0.000 {built-in method builtins.hash}\n",
       "     2000    0.001    0.000    0.004    0.000 data_adapter.py:597(_is_composite)\n",
       "     1008    0.001    0.000    0.002    0.000 <__array_function__ internals>:177(copyto)\n",
       "     1036    0.001    0.000    0.001    0.000 backprop.py:154(_must_record_gradient)\n",
       "  417/163    0.001    0.000    0.002    0.000 base_layer.py:3153(__setattr__)\n",
       "     1007    0.001    0.000    0.001    0.000 construction.py:644(_sanitize_ndim)\n",
       "     2015    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
       "     1008    0.001    0.000    0.001    0.000 np_dtypes.py:111(<listcomp>)\n",
       "       67    0.001    0.000    0.001    0.000 {built-in method tensorflow.python.util._tf_stack.extract_stack_for_op}\n",
       "      102    0.001    0.000    0.001    0.000 typing.py:958(_get_protocol_attrs)\n",
       "     3055    0.001    0.000    0.002    0.000 tf_utils.py:387(is_extension_type)\n",
       "     1001    0.001    0.000    0.002    0.000 tf_utils.py:620(get_tensor_spec)\n",
       "      131    0.001    0.000    0.001    0.000 inspect.py:2124(_signature_from_function)\n",
       "       35    0.001    0.000    0.005    0.000 op_def_library.py:410(_ExtractInputsAndAttrs)\n",
       "       67    0.001    0.000    0.007    0.000 ops.py:1780(from_node_def)\n",
       "     3150    0.001    0.000    0.001    0.000 ops.py:961(__tf_tensor__)\n",
       "     2010    0.001    0.000    0.001    0.000 tensor_shape.py:910(ndims)\n",
       "       26    0.001    0.000    0.002    0.000 tensor_util.py:421(make_tensor_proto)\n",
       "     2000    0.001    0.000    0.001    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
       "     2000    0.001    0.000    0.001    0.000 generic.py:599(_info_axis)\n",
       "     2016    0.001    0.000    0.001    0.000 np_dtypes.py:104(preprocess_float)\n",
       "     1006    0.001    0.000    0.002    0.000 common.py:1631(validate_all_hashable)\n",
       "     1000    0.001    0.000    0.073    0.000 math_ops.py:1618(truediv)\n",
       "     2014    0.001    0.000    0.001    0.000 inference.py:328(is_hashable)\n",
       "       70    0.001    0.000    0.001    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_OperationGetAttrValueProto}\n",
       "     4100    0.001    0.000    0.001    0.000 ops.py:171(__init__)\n",
       "     1003    0.001    0.000    0.002    0.000 base.py:58(_validate_set_axis)\n",
       "     1045    0.001    0.000    0.006    0.000 ops.py:1105(_numpy)\n",
       "       32    0.000    0.000    0.020    0.001 atomic_function.py:163(__call__)\n",
       "     1002    0.000    0.000    0.000    0.000 flags.py:85(allows_duplicate_labels)\n",
       "     2010    0.000    0.000    0.001    0.000 base.py:7072(ensure_index)\n",
       "     1007    0.000    0.000    0.001    0.000 construction.py:683(_sanitize_str_dtypes)\n",
       "     2012    0.000    0.000    0.001    0.000 common.py:1650(<genexpr>)\n",
       "     1005    0.000    0.000    0.000    0.000 flags.py:49(__init__)\n",
       "  153/147    0.000    0.000    0.002    0.000 inspect.py:2218(_signature_from_callable)\n",
       "     2004    0.000    0.000    0.000    0.000 generic.py:359(flags)\n",
       "     1025    0.000    0.000    0.009    0.000 array_ops.py:1534(_autopacking_conversion_function)\n",
       "     1003    0.000    0.000    0.002    0.000 managers.py:223(set_axis)\n",
       "  229/209    0.000    0.000    0.006    0.000 {built-in method builtins.any}\n",
       " 1426/466    0.000    0.000    0.001    0.000 options.py:617(__getattribute__)\n",
       "       67    0.000    0.000    0.011    0.000 ops.py:3322(_create_op_internal)\n",
       "       67    0.000    0.000    0.001    0.000 ops.py:1924(_init)\n",
       "     1060    0.000    0.000    0.001    0.000 dtypes.py:261(__ne__)\n",
       "        1    0.000    0.000    0.116    0.116 text_vectorization.py:423(adapt)\n",
       "     2000    0.000    0.000    0.001    0.000 common.py:367(apply_if_callable)\n",
       "       67    0.000    0.000    0.001    0.000 ops.py:3426(_create_op_helper)\n",
       "     1005    0.000    0.000    0.000    0.000 construction.py:458(ensure_wrapped_if_datetimelike)\n",
       "     4130    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
       "       42    0.000    0.000    0.003    0.000 function_type.py:411(canonicalize_to_monomorphic)\n",
       "      210    0.000    0.000    0.001    0.000 inspect.py:2772(__init__)\n",
       " 1239/954    0.000    0.000    0.004    0.000 {built-in method builtins.next}\n",
       "     1008    0.000    0.000    0.003    0.000 construction.py:396(extract_array)\n",
       "     2012    0.000    0.000    0.001    0.000 common.py:144(<lambda>)\n",
       "     2002    0.000    0.000    0.004    0.000 data_adapter.py:614(<genexpr>)\n",
       "     2012    0.000    0.000    0.000    0.000 common.py:142(classes)\n",
       "      393    0.000    0.000    0.000    0.000 contextlib.py:82(__init__)\n",
       "     1003    0.000    0.000    0.005    0.000 config.py:260(__call__)\n",
       "       67    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_NewOperation}\n",
       "     1007    0.000    0.000    0.001    0.000 base.py:7167(maybe_extract_name)\n",
       "        4    0.000    0.000    0.004    0.001 auto_control_deps.py:343(__exit__)\n",
       "       67    0.000    0.000    0.001    0.000 ops.py:1663(_NodeDef)\n",
       "     1013    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
       "       38    0.000    0.000    0.047    0.001 tracing_compiler.py:324(_maybe_define_function)\n",
       "      685    0.000    0.000    0.001    0.000 options.py:99(get_fn)\n",
       "     1004    0.000    0.000    0.001    0.000 common.py:571(require_length_match)\n",
       "     4005    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
       "     4100    0.000    0.000    0.000    0.000 ops.py:174(__enter__)\n",
       "     1007    0.000    0.000    0.000    0.000 construction.py:703(_maybe_repeat)\n",
       "     1096    0.000    0.000    0.001    0.000 abc.py:100(__subclasscheck__)\n",
       "      812    0.000    0.000    0.000    0.000 function_type.py:168(parameters)\n",
       "    46/42    0.000    0.000    0.001    0.000 nest_util.py:534(_tf_core_packed_nest_with_indices)\n",
       "       32    0.000    0.000    0.051    0.002 polymorphic_function.py:797(__call__)\n",
       "  376/188    0.000    0.000    0.001    0.000 type_spec.py:568(__make_cmp_key)\n",
       "     1003    0.000    0.000    0.000    0.000 managers.py:1847(__init__)\n",
       "  393/255    0.000    0.000    0.001    0.000 contextlib.py:117(__exit__)\n",
       "     1003    0.000    0.000    0.001    0.000 config.py:649(_warn_if_deprecated)\n",
       "       86    0.000    0.000    0.002    0.000 func_graph.py:445(inner_cm)\n",
       "      536    0.000    0.000    0.001    0.000 compat.py:89(as_text)\n",
       "      145    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_SetAttrValueProto}\n",
       "      400    0.000    0.000    0.001    0.000 op_def_library.py:54(<genexpr>)\n",
       "     2001    0.000    0.000    0.000    0.000 deprecation.py:658(deprecated_argument_lookup)\n",
       "     1003    0.000    0.000    0.000    0.000 __init__.py:33(using_copy_on_write)\n",
       "       86    0.000    0.000    0.001    0.000 ops.py:5335(get_controller)\n",
       "       70    0.000    0.000    0.001    0.000 ops.py:2265(get_attr)\n",
       "     2016    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
       "       69    0.000    0.000    0.001    0.000 ops.py:973(GraphTensor)\n",
       "     2002    0.000    0.000    0.000    0.000 _base.py:1301(isspmatrix)\n",
       "      435    0.000    0.000    0.000    0.000 ops.py:5778(get_default_graph)\n",
       "        2    0.000    0.000    0.020    0.010 data_adapter.py:1328(enumerate_epochs)\n",
       "     1003    0.000    0.000    0.000    0.000 config.py:578(_select_options)\n",
       "     1003    0.000    0.000    0.001    0.000 config.py:637(_translate_key)\n",
       "     1102    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsNested}\n",
       "       35    0.000    0.000    0.001    0.000 op_def_library.py:316(_ExtractAttrProto)\n",
       "     1002    0.000    0.000    0.000    0.000 generic.py:338(attrs)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_GraphToFunction_wrapper}\n",
       "       26    0.000    0.000    0.006    0.000 ops.py:1001(_create_graph_constant)\n",
       "      162    0.000    0.000    0.000    0.000 inspect.py:2489(__init__)\n",
       "       67    0.000    0.000    0.011    0.000 func_graph.py:604(_create_op_internal)\n",
       "       59    0.000    0.000    0.002    0.000 tf_decorator.py:115(make_decorator)\n",
       "       37    0.000    0.000    0.000    0.000 tensor_shape.py:1420(as_proto)\n",
       "     2006    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
       "     1002    0.000    0.000    0.000    0.000 managers.py:1944(_block)\n",
       "       32    0.000    0.000    0.020    0.001 monomorphic_function.py:1274(_call_flat)\n",
       "       64    0.000    0.000    0.003    0.000 auto_control_deps.py:606(_get_resource_inputs)\n",
       "      704    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:6692(_reconstruct_sequence_inputs)\n",
       "     1004    0.000    0.000    0.000    0.000 common.py:1322(is_1d_only_ea_dtype)\n",
       "   100/84    0.000    0.000    0.002    0.000 trace_type_builder.py:125(from_value)\n",
       "    27/25    0.000    0.000    0.006    0.000 nest_util.py:1094(<listcomp>)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:366(_CanExtractAttrsFastPath)\n",
       "       38    0.000    0.000    0.000    0.000 function_context.py:39(make_function_context)\n",
       "     2501    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "      110    0.000    0.000    0.001    0.000 ops.py:3958(name_scope)\n",
       "  393/255    0.000    0.000    0.003    0.000 contextlib.py:108(__enter__)\n",
       "       61    0.000    0.000    0.002    0.000 auto_control_deps_utils.py:85(get_read_write_resource_inputs)\n",
       "     1003    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
       "     2000    0.000    0.000    0.000    0.000 base.py:6354(_maybe_cast_indexer)\n",
       "       67    0.000    0.000    0.000    0.000 lock_util.py:105(_another_group_active)\n",
       "   116/82    0.000    0.000    0.001    0.000 composite_tensor_utils.py:24(flatten_with_variables)\n",
       "       39    0.000    0.000    0.001    0.000 function_type.py:235(bind_with_defaults)\n",
       "     1003    0.000    0.000    0.000    0.000 base_layer.py:1071(<genexpr>)\n",
       "     2016    0.000    0.000    0.000    0.000 np_dtypes.py:75(is_prefer_float32)\n",
       "       85    0.000    0.000    0.000    0.000 inspect.py:2639(args)\n",
       "       36    0.000    0.000    0.001    0.000 ipkernel.py:775(_clean_thread_parent_frames)\n",
       "      435    0.000    0.000    0.000    0.000 ops.py:5312(get_default)\n",
       "      393    0.000    0.000    0.001    0.000 contextlib.py:238(helper)\n",
       "  142/136    0.000    0.000    0.004    0.000 base.py:200(_method_wrapper)\n",
       "       32    0.000    0.000    0.018    0.001 context.py:1447(call_function)\n",
       "       81    0.000    0.000    0.000    0.000 inspect.py:2692(apply_defaults)\n",
       "      167    0.000    0.000    0.000    0.000 compat.py:61(as_bytes)\n",
       "       81    0.000    0.000    0.001    0.000 op_def_library.py:815(value_to_attr_value)\n",
       "     1461    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
       "     1088    0.000    0.000    0.000    0.000 nest_util.py:307(_tf_core_yield_value)\n",
       "     1002    0.000    0.000    0.000    0.000 flags.py:53(allows_duplicate_labels)\n",
       "      305    0.000    0.000    0.000    0.000 object_identity.py:223(update)\n",
       "       37    0.000    0.000    0.007    0.000 resource_variable_ops.py:686(numpy)\n",
       "        1    0.000    0.000    1.621    1.621 {built-in method builtins.exec}\n",
       "      142    0.000    0.000    0.000    0.000 inspect.py:493(unwrap)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:392(_ExtractDefaultTypesAndAllowedTypes)\n",
       "       41    0.000    0.000    0.003    0.000 array_ops.py:247(identity)\n",
       "     1001    0.000    0.000    0.000    0.000 range.py:395(__iter__)\n",
       "      123    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
       "        4    0.000    0.000    0.034    0.009 func_graph.py:920(func_graph_from_py_func)\n",
       "       62    0.000    0.000    0.001    0.000 ops.py:2179(inputs)\n",
       "     1968    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
       "       65    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_AddInput}\n",
       "       37    0.000    0.000    0.005    0.000 resource_variable_ops.py:805(read_value)\n",
       "       76    0.000    0.000    0.000    0.000 ops.py:4080(unique_name)\n",
       "       59    0.000    0.000    0.001    0.000 tf_decorator.py:308(__init__)\n",
       "       39    0.000    0.000    0.001    0.000 function_spec.py:391(bind_function_inputs)\n",
       "      134    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}\n",
       "       70    0.000    0.000    0.001    0.000 function_type.py:137(__eq__)\n",
       "       79    0.000    0.000    0.000    0.000 function_type.py:51(__init__)\n",
       "     1114    0.000    0.000    0.000    0.000 nest_util.py:321(_tf_core_yield_sorted_items)\n",
       "      353    0.000    0.000    0.000    0.000 function_type.py:99(type_constraint)\n",
       "      134    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_OperationGetStackTrace}\n",
       "       97    0.000    0.000    0.001    0.000 op_def_library.py:51(_SatisfiesTypeConstraint)\n",
       "       67    0.000    0.000    0.000    0.000 lock_util.py:95(release)\n",
       "      536    0.000    0.000    0.001    0.000 compat.py:115(as_str)\n",
       "     1008    0.000    0.000    0.000    0.000 np_dtypes.py:93(canonicalize_dtype)\n",
       "       39    0.000    0.000    0.001    0.000 function_spec.py:452(filter_function_inputs)\n",
       "       76    0.000    0.000    0.001    0.000 function_type.py:354(__hash__)\n",
       "       67    0.000    0.000    0.000    0.000 context.py:1510(op_callbacks)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "       31    0.000    0.000    0.021    0.001 tracing_compiler.py:143(__call__)\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:4323(_apply_device_functions)\n",
       "       48    0.000    0.000    0.000    0.000 nest_util.py:174(sequence_like)\n",
       "      188    0.000    0.000    0.001    0.000 type_spec.py:563(__get_cmp_key)\n",
       "       83    0.000    0.000    0.001    0.000 typing.py:1009(__instancecheck__)\n",
       "       37    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.generic' objects}\n",
       "      162    0.000    0.000    0.000    0.000 threading.py:1047(ident)\n",
       "        1    0.000    0.000    0.116    0.116 base_preprocessing_layer.py:162(adapt)\n",
       "     1003    0.000    0.000    0.000    0.000 base_layer.py:3747(<genexpr>)\n",
       "       18    0.000    0.000    0.000    0.000 threading.py:1336(enumerate)\n",
       "     1008    0.000    0.000    0.000    0.000 multiarray.py:1079(copyto)\n",
       "      150    0.000    0.000    0.000    0.000 object_identity.py:182(__init__)\n",
       "       69    0.000    0.000    0.000    0.000 ops.py:3725(_get_tensor_by_tf_output)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
       "        4    0.000    0.000    0.001    0.000 atomic_function.py:368(from_func_graph_no_transforms)\n",
       "     1001    0.000    0.000    0.000    0.000 array_ops.py:1453(<genexpr>)\n",
       "      212    0.000    0.000    0.000    0.000 _collections_abc.py:742(__iter__)\n",
       "       46    0.000    0.000    0.000    0.000 functools.py:34(update_wrapper)\n",
       "       67    0.000    0.000    0.001    0.000 tf_stack.py:169(extract_stack_for_op)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:723(_GetOpDef)\n",
       "     1167    0.000    0.000    0.000    0.000 inspect.py:2551(kind)\n",
       "       68    0.000    0.000    0.001    0.000 function_type.py:347(__eq__)\n",
       "       67    0.000    0.000    0.000    0.000 lock_util.py:85(acquire)\n",
       "       88    0.000    0.000    0.000    0.000 context.py:992(_mode)\n",
       "       33    0.000    0.000    0.006    0.000 data_adapter.py:1390(steps)\n",
       "      134    0.000    0.000    0.000    0.000 ops.py:2200(traceback)\n",
       "       67    0.000    0.000    0.000    0.000 threading.py:341(notify)\n",
       "       15    0.000    0.000    0.001    0.000 options.py:115(merge_options)\n",
       "      108    0.000    0.000    0.000    0.000 base_layer.py:3066(_obj_reference_counts)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:2690(__init__)\n",
       "     1004    0.000    0.000    0.000    0.000 series.py:1323(_clear_item_cache)\n",
       "       83    0.000    0.000    0.000    0.000 function_type.py:161(__init__)\n",
       "       82    0.000    0.000    0.000    0.000 options.py:38(__eq__)\n",
       "     1010    0.000    0.000    0.000    0.000 multiarray.py:668(result_type)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_ContextAddFunction}\n",
       "       35    0.000    0.000    0.000    0.000 ops.py:2965(graph_def_versions)\n",
       "       85    0.000    0.000    0.000    0.000 inspect.py:2662(kwargs)\n",
       "    27/25    0.000    0.000    0.007    0.000 nest_util.py:1064(_tf_core_map_structure)\n",
       "       18    0.000    0.000    0.000    0.000 ipkernel.py:790(<setcomp>)\n",
       "      382    0.000    0.000    0.000    0.000 object_identity.py:239(__iter__)\n",
       "       54    0.000    0.000    0.000    0.000 base_layer.py:3092(__delattr__)\n",
       "      837    0.000    0.000    0.000    0.000 inspect.py:2857(parameters)\n",
       "       13    0.000    0.000    0.000    0.000 numeric.py:2407(array_equal)\n",
       "       32    0.000    0.000    0.051    0.002 polymorphic_function.py:844(_call)\n",
       "      164    0.000    0.000    0.000    0.000 enum.py:313(__call__)\n",
       "      172    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}\n",
       "       43    0.000    0.000    0.002    0.000 func_graph.py:442(as_default)\n",
       "      264    0.000    0.000    0.000    0.000 ops.py:4893(_device_function_stack)\n",
       "      183    0.000    0.000    0.000    0.000 registry.py:81(lookup)\n",
       "       15    0.000    0.000    0.001    0.000 dataset_ops.py:232(__init__)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:699(_ExtractRemainingAttrs)\n",
       "       40    0.000    0.000    0.000    0.000 structure.py:278(get_flat_tensor_specs)\n",
       "       38    0.000    0.000    0.003    0.000 function_spec.py:307(make_canonicalized_monomorphic_type)\n",
       "       80    0.000    0.000    0.001    0.000 function_type.py:145(__hash__)\n",
       "       16    0.000    0.000    0.000    0.000 function_spec.py:133(to_input_signature)\n",
       "      123    0.000    0.000    0.000    0.000 object_identity.py:138(__getitem__)\n",
       "       82    0.000    0.000    0.000    0.000 ops.py:420(__getattr__)\n",
       "      122    0.000    0.000    0.000    0.000 auto_control_deps.py:591(update)\n",
       "       37    0.000    0.000    0.002    0.000 resource_variable_ops.py:781(read_and_set_handle)\n",
       "      122    0.000    0.000    0.000    0.000 auto_control_deps.py:144(op_is_stateful)\n",
       "      103    0.000    0.000    0.000    0.000 traceable_stack.py:109(peek_objs)\n",
       "     1016    0.000    0.000    0.000    0.000 typing.py:1149(cast)\n",
       "       38    0.000    0.000    0.003    0.000 function_cache.py:42(lookup)\n",
       "      2/1    0.000    0.000    0.014    0.014 base_layer.py:1005(__call__)\n",
       "        9    0.000    0.000    0.000    0.000 function_type.py:479(add_type_constraints)\n",
       "       20    0.000    0.000    0.000    0.000 conversion.py:37(<genexpr>)\n",
       "      191    0.000    0.000    0.000    0.000 options.py:33(__init__)\n",
       "       40    0.000    0.000    0.000    0.000 distribute_lib.py:383(_get_per_thread_mode)\n",
       "      181    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}\n",
       "       52    0.000    0.000    0.001    0.000 nest_util.py:855(_tf_core_pack_sequence_as)\n",
       "       71    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_NewBuffer}\n",
       "       83    0.000    0.000    0.001    0.000 typing.py:975(_is_callable_members_only)\n",
       "       63    0.000    0.000    0.001    0.000 {method 'join' of 'str' objects}\n",
       "       55    0.000    0.000    0.001    0.000 ops.py:6249(__enter__)\n",
       "       32    0.000    0.000    0.000    0.000 ops.py:3741(op_def_for_type)\n",
       "       53    0.000    0.000    0.000    0.000 ops.py:445(shape)\n",
       "      768    0.000    0.000    0.000    0.000 inspect.py:2539(name)\n",
       "       80    0.000    0.000    0.000    0.000 record.py:54(stop_recording)\n",
       "      188    0.000    0.000    0.000    0.000 type_spec.py:584(<listcomp>)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:4954(_snapshot_colocation_stack_metadata)\n",
       "       75    0.000    0.000    0.001    0.000 capture_container.py:84(capture_by_value)\n",
       "      199    0.000    0.000    0.000    0.000 ops.py:4989(_distribution_strategy_stack)\n",
       "        2    0.000    0.000    0.000    0.000 version_utils.py:89(swap_class)\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:1950(_control_flow_post_processing)\n",
       "      122    0.000    0.000    0.000    0.000 tpu.py:205(replace_with_unreplicated_resources)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:163(__init__)\n",
       "      202    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "        4    0.000    0.000    0.004    0.001 np_array_ops.py:1533(_slice_helper)\n",
       "      7/4    0.000    0.000    0.025    0.006 api.py:295(converted_call)\n",
       "       37    0.000    0.000    0.003    0.000 resource_variable_ops.py:767(_read_variable_op)\n",
       "       12    0.000    0.000    0.001    0.000 function_spec.py:177(from_function_and_signature)\n",
       "       66    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.FlattenForData}\n",
       "      118    0.000    0.000    0.002    0.000 inspect.py:3103(signature)\n",
       "        1    0.000    0.000    0.000    0.000 resource_variable_ops.py:1838(_init_from_args)\n",
       "       61    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.GetOperationInputs}\n",
       "       86    0.000    0.000    0.000    0.000 stack.py:48(get_controller)\n",
       "      142    0.000    0.000    0.000    0.000 ops.py:4970(_control_dependencies_stack)\n",
       "      252    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
       "      237    0.000    0.000    0.000    0.000 ops.py:3946(_name_stack)\n",
       "       62    0.000    0.000    0.000    0.000 errors_impl.py:284(__init__)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:349(_ExtractOutputStructure)\n",
       "        2    0.000    0.000    0.012    0.006 row_partition.py:195(from_value_rowids)\n",
       "        2    0.000    0.000    0.008    0.004 bincount_ops.py:31(bincount)\n",
       "       67    0.000    0.000    0.000    0.000 op_callbacks.py:114(should_invoke_op_callbacks)\n",
       "       44    0.000    0.000    0.000    0.000 {built-in method FromString}\n",
       "      142    0.000    0.000    0.000    0.000 c_api_util.py:191(tf_buffer)\n",
       "      123    0.000    0.000    0.001    0.000 inspect.py:3032(bind)\n",
       "       26    0.000    0.000    0.000    0.000 tensor_util.py:400(_is_array_like)\n",
       "       41    0.000    0.000    0.002    0.000 gen_array_ops.py:4080(identity)\n",
       "       22    0.000    0.000    0.002    0.000 tensor.py:258(placeholder_value)\n",
       "       16    0.000    0.000    0.000    0.000 function_spec.py:41(to_fullargspec)\n",
       "      142    0.000    0.000    0.002    0.000 inspect.py:2851(from_callable)\n",
       "       82    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_UID}\n",
       "        5    0.000    0.000    0.000    0.000 inspect.py:1102(getfullargspec)\n",
       "       37    0.000    0.000    0.001    0.000 resource_variable_ops.py:329(variable_accessed)\n",
       "       39    0.000    0.000    0.002    0.000 function_spec.py:352(canonicalize_function_inputs)\n",
       "       43    0.000    0.000    0.000    0.000 contextlib.py:211(contextmanager)\n",
       "        6    0.000    0.000    0.001    0.000 tensor.py:299(_graph_placeholder)\n",
       "       45    0.000    0.000    0.001    0.000 function_type.py:398(_make_validated_mono_param)\n",
       "      670    0.000    0.000    0.000    0.000 inspect.py:2547(annotation)\n",
       "      271    0.000    0.000    0.000    0.000 inspect.py:158(isfunction)\n",
       "      225    0.000    0.000    0.000    0.000 function_type.py:94(optional)\n",
       "       46    0.000    0.000    0.000    0.000 op_def_library.py:36(_Attr)\n",
       "       31    0.000    0.000    0.000    0.000 polymorphic_function.py:196(called_without_tracing)\n",
       "       32    0.000    0.000    0.000    0.000 weakref.py:422(__contains__)\n",
       "       37    0.000    0.000    0.000    0.000 tape.py:77(variable_accessed)\n",
       "       21    0.000    0.000    0.000    0.000 tensor_util.py:246(GetFromNumpyDTypeDict)\n",
       "      130    0.000    0.000    0.000    0.000 ops.py:2184(<genexpr>)\n",
       "       61    0.000    0.000    0.000    0.000 tpu.py:186(tpu_replicated_input_resolver)\n",
       "       18    0.000    0.000    0.000    0.000 ops.py:952(__tf_tracing_type__)\n",
       "       82    0.000    0.000    0.000    0.000 tf_decorator.py:272(unwrap)\n",
       "       37    0.000    0.000    0.000    0.000 distribute_lib.py:4192(get_local_results_or_value_container)\n",
       "       69    0.000    0.000    0.000    0.000 ops.py:3700(_get_operation_by_tf_operation)\n",
       "       67    0.000    0.000    0.000    0.000 lock_util.py:73(group)\n",
       "       37    0.000    0.000    0.002    0.000 gen_resource_variable_ops.py:502(read_variable_op)\n",
       "      110    0.000    0.000    0.000    0.000 ops.py:1867(<genexpr>)\n",
       "       44    0.000    0.000    0.000    0.000 context.py:262(push)\n",
       "       54    0.000    0.000    0.000    0.000 base_layer.py:3262(_track_variables)\n",
       "       62    0.000    0.000    0.000    0.000 errors_impl.py:66(__init__)\n",
       "       82    0.000    0.000    0.000    0.000 iterator_ops.py:808(_type_spec)\n",
       "      2/1    0.000    0.000    0.010    0.010 traceback_utils.py:92(error_handler)\n",
       "      317    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
       "        8    0.000    0.000    0.001    0.000 tracing_compiler.py:73(__init__)\n",
       "      192    0.000    0.000    0.000    0.000 object_identity.py:135(_wrap_key)\n",
       "        1    0.000    0.000    0.004    0.004 index_lookup.py:666(finalize_state)\n",
       "       61    0.000    0.000    0.000    0.000 dataset_ops.py:5121(_resource_resolver)\n",
       "      166    0.000    0.000    0.000    0.000 typing.py:977(<genexpr>)\n",
       "       80    0.000    0.000    0.000    0.000 tensor.py:143(__hash__)\n",
       "      357    0.000    0.000    0.000    0.000 ops.py:432(dtype)\n",
       "       34    0.000    0.000    0.000    0.000 ops.py:5154(control_dependencies)\n",
       "      201    0.000    0.000    0.000    0.000 lock_util.py:109(_validate_group_id)\n",
       "      327    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
       "      305    0.000    0.000    0.000    0.000 object_identity.py:224(<listcomp>)\n",
       "       64    0.000    0.000    0.000    0.000 auto_control_deps_utils.py:108(<genexpr>)\n",
       "      355    0.000    0.000    0.000    0.000 {method 'HasField' of 'google._upb._message.Message' objects}\n",
       "       69    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "       35    0.000    0.000    0.000    0.000 monomorphic_function.py:1528(captured_inputs)\n",
       "       43    0.000    0.000    0.002    0.000 tf_contextlib.py:21(contextmanager)\n",
       "      158    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x908780}\n",
       "       69    0.000    0.000    0.000    0.000 control_flow_util.py:262(CheckInputFromValidContext)\n",
       "       62    0.000    0.000    0.001    0.000 type_spec.py:508(__eq__)\n",
       "       37    0.000    0.000    0.000    0.000 tensor_shape.py:1425(<listcomp>)\n",
       "      208    0.000    0.000    0.000    0.000 inspect.py:2631(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 base_layer.py:319(__init__)\n",
       "        4    0.000    0.000    0.001    0.000 polymorphic_function.py:463(__init__)\n",
       "        2    0.000    0.000    0.020    0.010 ragged_string_ops.py:470(string_split_v2)\n",
       "       82    0.000    0.000    0.000    0.000 ops.py:221(uid)\n",
       "       52    0.000    0.000    0.000    0.000 op_def_library.py:187(_MakeType)\n",
       "       67    0.000    0.000    0.000    0.000 threading.py:364(notify_all)\n",
       "        3    0.000    0.000    0.000    0.000 conversion.py:112(is_allowlisted)\n",
       "       67    0.000    0.000    0.000    0.000 lock_util.py:128(__exit__)\n",
       "      137    0.000    0.000    0.000    0.000 ops.py:4939(_colocation_stack)\n",
       "        3    0.000    0.000    0.000    0.000 structure.py:69(normalize_element)\n",
       "        1    0.000    0.000    0.010    0.010 text_vectorization.py:622(call)\n",
       "      9/7    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.AssertSameStructure}\n",
       "       16    0.000    0.000    0.000    0.000 monitoring.py:143(get_cell)\n",
       "       54    0.000    0.000    0.000    0.000 data_structures.py:86(wrap_or_unwrap)\n",
       "        9    0.000    0.000    0.000    0.000 ops.py:641(set_shape)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_ContextGetFunctionDef}\n",
       "        3    0.000    0.000    0.020    0.007 structured_function.py:77(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 polymorphic_function.py:191(_get_detector)\n",
       "      214    0.000    0.000    0.000    0.000 inspect.py:2821(<genexpr>)\n",
       "      349    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
       "        4    0.000    0.000    0.002    0.000 monomorphic_function.py:999(__init__)\n",
       "        4    0.000    0.000    0.036    0.009 tracing_compiler.py:280(_create_concrete_function)\n",
       "        8    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
       "       54    0.000    0.000    0.000    0.000 data_structures.py:124(sticky_attribute_assignment)\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:4914(_snapshot_device_function_stack_metadata)\n",
       "        8    0.000    0.000    0.000    0.000 base.py:542(_track_trackable)\n",
       "      410    0.000    0.000    0.000    0.000 inspect.py:2543(default)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:790(<listcomp>)\n",
       "       63    0.000    0.000    0.000    0.000 nest.py:41(flatten)\n",
       "       64    0.000    0.000    0.000    0.000 polymorphic_function.py:760(experimental_get_tracing_count)\n",
       "        4    0.000    0.000    0.001    0.000 monomorphic_function.py:1080(_initialize_function_spec)\n",
       "        2    0.000    0.000    0.002    0.001 lookup_ops.py:179(__init__)\n",
       "       43    0.000    0.000    0.000    0.000 ops.py:3753(as_default)\n",
       "       64    0.000    0.000    0.001    0.000 type_spec.py:516(__hash__)\n",
       "       67    0.000    0.000    0.000    0.000 _collections_abc.py:676(items)\n",
       "       32    0.000    0.000    0.000    0.000 context.py:199(as_attrs)\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:4487(_control_dependencies_for_inputs)\n",
       "       17    0.000    0.000    0.000    0.000 tensor.py:248(is_subtype_of)\n",
       "      357    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
       "       61    0.000    0.000    0.000    0.000 control_flow_util.py:78(IsInWhileLoop)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:382(_CheckOpDeprecation)\n",
       "       55    0.000    0.000    0.000    0.000 ops.py:6289(__exit__)\n",
       "      136    0.000    0.000    0.000    0.000 ops.py:3376(<genexpr>)\n",
       "        8    0.000    0.000    0.001    0.000 polymorphic_function.py:627(_compiler)\n",
       "       43    0.000    0.000    0.000    0.000 tensor_shape.py:938(__getitem__)\n",
       "      192    0.000    0.000    0.000    0.000 object_identity.py:64(__hash__)\n",
       "       12    0.000    0.000    0.000    0.000 capture_container.py:66(__init__)\n",
       "       37    0.000    0.000    0.000    0.000 resource_variable_ops.py:318(_maybe_set_handle_data)\n",
       "       82    0.000    0.000    0.000    0.000 trace_type_builder.py:29(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 function_type.py:187(from_callable)\n",
       "      110    0.000    0.000    0.000    0.000 ops.py:3953(_name_stack)\n",
       "       28    0.000    0.000    0.000    0.000 tensor.py:103(__init__)\n",
       "       86    0.000    0.000    0.000    0.000 ops.py:1290(graph)\n",
       "      312    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "       34    0.000    0.000    0.001    0.000 type_dispatch.py:75(dispatch)\n",
       "      142    0.000    0.000    0.000    0.000 inspect.py:513(_is_wrapper)\n",
       "      164    0.000    0.000    0.000    0.000 enum.py:631(__new__)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_DeleteFunction}\n",
       "      134    0.000    0.000    0.000    0.000 lock_util.py:106(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:469(__new__)\n",
       "       75    0.000    0.000    0.001    0.000 func_graph.py:674(capture)\n",
       "       19    0.000    0.000    0.000    0.000 options.py:682(_set_mutable)\n",
       "       59    0.000    0.000    0.000    0.000 tf_decorator.py:179(_get_bound_instance)\n",
       "       59    0.000    0.000    0.000    0.000 object_identity.py:141(__setitem__)\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:4521(_record_op_seen_by_control_dependencies)\n",
       "      252    0.000    0.000    0.019    0.000 {built-in method builtins.iter}\n",
       "       61    0.000    0.000    0.000    0.000 auto_control_deps.py:587(_identity_resolver)\n",
       "       38    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsNamedtuple}\n",
       "       69    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_OperationName}\n",
       "    28/26    0.000    0.000    0.007    0.000 nest_util.py:956(map_structure)\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:5012(_mutation_lock)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:106(<listcomp>)\n",
       "        1    0.000    0.000    0.027    0.027 data_adapter.py:240(__init__)\n",
       "       78    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_DeleteBuffer}\n",
       "       12    0.000    0.000    0.000    0.000 dataset_ops.py:680(_common_args)\n",
       "       68    0.000    0.000    0.000    0.000 op_def_library.py:595(<listcomp>)\n",
       "       61    0.000    0.000    0.000    0.000 auto_control_deps.py:159(collective_manager_ids_from_op)\n",
       "        4    0.000    0.000    0.001    0.000 function_type.py:309(placeholder_arguments)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:103(_Flatten)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.SetAttr}\n",
       "       12    0.000    0.000    0.000    0.000 context.py:2118(__enter__)\n",
       "    27/25    0.000    0.000    0.007    0.000 nest.py:538(map_structure)\n",
       "       35    0.000    0.000    0.000    0.000 func_graph.py:1130(device_stack_has_callable)\n",
       "      134    0.000    0.000    0.000    0.000 traceable_stack.py:113(peek_traceable_objs)\n",
       "       32    0.000    0.000    0.000    0.000 context.py:1304(function_call_options)\n",
       "        2    0.000    0.000    0.001    0.000 base_layer.py:753(__new__)\n",
       "       67    0.000    0.000    0.000    0.000 lock_util.py:125(__enter__)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "        4    0.000    0.000    0.000    0.000 function_type.py:539(from_structured_signature)\n",
       "       43    0.000    0.000    0.000    0.000 functools.py:64(wraps)\n",
       "        1    0.000    0.000    0.003    0.003 index_lookup.py:168(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 atomic_function.py:405(<listcomp>)\n",
       "       96    0.000    0.000    0.000    0.000 op_def_registry.py:32(get)\n",
       "       55    0.000    0.000    0.000    0.000 ops.py:6230(__init__)\n",
       "      194    0.000    0.000    0.000    0.000 iterator_ops.py:933(_serialize)\n",
       "       87    0.000    0.000    0.000    0.000 function_type.py:431(<genexpr>)\n",
       "      147    0.000    0.000    0.000    0.000 ops.py:3257(building_function)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_MonitoringGetCellBoolGauge1}\n",
       "        3    0.000    0.000    0.001    0.000 tracing_compiler.py:190(_get_concrete_function_garbage_collected)\n",
       "       15    0.000    0.000    0.000    0.000 os.py:670(__getitem__)\n",
       "       17    0.000    0.000    0.000    0.000 tensor_shape.py:1164(is_subtype_of)\n",
       "        3    0.000    0.000    0.000    0.000 lookup_ops.py:2026(export)\n",
       "        1    0.000    0.000    0.007    0.007 map_op.py:97(__init__)\n",
       "       37    0.000    0.000    0.000    0.000 distribute_lib.py:576(get_strategy_and_replica_context)\n",
       "       38    0.000    0.000    0.000    0.000 save_context.py:59(in_save_context)\n",
       "       67    0.000    0.000    0.000    0.000 threading.py:261(_is_owned)\n",
       "       72    0.000    0.000    0.000    0.000 config_lib.py:29(matches)\n",
       "        9    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google._upb._message.Message' objects}\n",
       "       43    0.000    0.000    0.000    0.000 context.py:2395(graph_mode)\n",
       "        6    0.000    0.000    0.000    0.000 structure.py:321(_to_tensor_list_helper)\n",
       "       15    0.000    0.000    0.000    0.000 ops.py:5120(_colocate_with_for_gradient)\n",
       "       16    0.000    0.000    0.000    0.000 function_spec.py:237(__init__)\n",
       "      165    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "       10    0.000    0.000    0.000    0.000 ragged_tensor.py:904(shape)\n",
       "      120    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "        9    0.000    0.000    0.000    0.000 tensor_shape.py:995(merge_with)\n",
       "        1    0.000    0.000    0.001    0.001 construction.py:411(dict_to_mgr)\n",
       "      199    0.000    0.000    0.000    0.000 ops.py:1991(_get_control_flow_context)\n",
       "       70    0.000    0.000    0.000    0.000 tracing_compiler.py:160(input_signature)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:626(send)\n",
       "        1    0.000    0.000    0.034    0.034 data_adapter.py:1225(__init__)\n",
       "        1    0.000    0.000    0.004    0.004 text_vectorization.py:248(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 dataset_ops.py:4789(__init__)\n",
       "       91    0.000    0.000    0.000    0.000 ops.py:2928(_variable_creator_stack)\n",
       "        3    0.000    0.000    0.008    0.003 structured_function.py:162(wrapper_helper)\n",
       "       79    0.000    0.000    0.000    0.000 object_identity.py:55(__eq__)\n",
       "       54    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
       "      115    0.000    0.000    0.000    0.000 base_layer.py:3075(_maybe_create_attribute)\n",
       "        2    0.000    0.000    0.003    0.002 string_ops.py:235(string_split_v2)\n",
       "       24    0.000    0.000    0.000    0.000 context.py:1042(_set_device)\n",
       "       86    0.000    0.000    0.000    0.000 ops.py:4996(_distribution_strategy_stack)\n",
       "      118    0.000    0.000    0.000    0.000 {method 'keys' of 'mappingproxy' objects}\n",
       "       91    0.000    0.000    0.000    0.000 tf_decorator.py:187(_has_tf_decorator_attr)\n",
       "        1    0.000    0.000    0.006    0.006 map_op.py:136(__init__)\n",
       "        4    0.000    0.000    0.026    0.007 polymorphic_function.py:578(wrapped_fn)\n",
       "       31    0.000    0.000    0.000    0.000 polymorphic_function.py:173(called_without_tracing)\n",
       "        7    0.000    0.000    0.000    0.000 ops.py:2224(_set_attr_with_buf)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:108(__init__)\n",
       "        2    0.000    0.000    0.020    0.010 text_vectorization.py:569(_preprocess)\n",
       "        1    0.000    0.000    0.010    0.010 flat_map_op.py:30(__init__)\n",
       "      129    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
       "       68    0.000    0.000    0.000    0.000 op_def_library.py:83(_IsListParameter)\n",
       "      273    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
       "       12    0.000    0.000    0.000    0.000 weakref.py:343(__init__)\n",
       "        1    0.000    0.000    0.006    0.006 readers.py:540(_read)\n",
       "        1    0.000    0.000    0.001    0.001 common.py:648(get_handle)\n",
       "       35    0.000    0.000    0.000    0.000 ops.py:5851(_get_graph_from_inputs)\n",
       "      114    0.000    0.000    0.000    0.000 op_def_library.py:99(_IsListValue)\n",
       "       44    0.000    0.000    0.000    0.000 context.py:282(pop)\n",
       "      192    0.000    0.000    0.000    0.000 object_identity.py:32(__init__)\n",
       "        3    0.000    0.000    0.019    0.006 polymorphic_function.py:1148(_get_concrete_function_garbage_collected)\n",
       "       64    0.000    0.000    0.000    0.000 function_type.py:338(flat_outputs)\n",
       "      212    0.000    0.000    0.000    0.000 function_type.py:172(captures)\n",
       "        5    0.000    0.000    0.000    0.000 func_graph.py:81(encode_arg)\n",
       "        2    0.000    0.000    0.019    0.010 iterator_ops.py:714(_create_iterator)\n",
       "       37    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_TapeSetRestartOnThread}\n",
       "       51    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
       "      162    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
       "       80    0.000    0.000    0.000    0.000 tensor_shape.py:1485(__hash__)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:311(_from_row_partition)\n",
       "       61    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
       "       11    0.000    0.000    0.000    0.000 monitoring.py:359(get_cell)\n",
       "       69    0.000    0.000    0.000    0.000 control_flow_util.py:176(GetOutputContext)\n",
       "        1    0.000    0.000    0.001    0.001 ragged_tensor.py:1795(to_tensor)\n",
       "       39    0.000    0.000    0.000    0.000 function_spec.py:477(<listcomp>)\n",
       "       41    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsResourceVariable}\n",
       "        7    0.000    0.000    0.001    0.000 gen_math_ops.py:1981(cast)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
       "       57    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsNestedOrComposite}\n",
       "        2    0.000    0.000    0.000    0.000 prefetch_op.py:34(__init__)\n",
       "       67    0.000    0.000    0.000    0.000 lock_util.py:121(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 concat.py:33(concat_compat)\n",
       "    36/23    0.000    0.000    0.000    0.000 tensor_util.py:279(_GetDenseDimensions)\n",
       "       83    0.000    0.000    0.000    0.000 structure.py:291(<genexpr>)\n",
       "      152    0.000    0.000    0.000    0.000 tensor.py:124(dtype)\n",
       "       23    0.000    0.000    0.000    0.000 tensor_util.py:370(_AssertCompatible)\n",
       "       24    0.000    0.000    0.000    0.000 context.py:1037(device_spec)\n",
       "        8    0.000    0.000    0.000    0.000 func_graph.py:64(convert_structure_to_signature)\n",
       "      189    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
       "        4    0.000    0.000    0.002    0.000 gen_array_ops.py:10554(strided_slice)\n",
       "       37    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_VariableWatcherVariableAccessed}\n",
       "       12    0.000    0.000    0.000    0.000 function_type.py:195(<listcomp>)\n",
       "        4    0.000    0.000    0.004    0.001 np_array_ops.py:1820(_getitem)\n",
       "    23/13    0.000    0.000    0.000    0.000 nest_util.py:1160(_tf_core_yield_flat_up_to)\n",
       "        4    0.000    0.000    0.000    0.000 tensor_util.py:745(_ConstantValue)\n",
       "       61    0.000    0.000    0.000    0.000 registry.py:73(list)\n",
       "        2    0.000    0.000    0.012    0.006 ragged_tensor.py:357(from_value_rowids)\n",
       "        7    0.000    0.000    0.000    0.000 ops.py:2215(_set_attr)\n",
       "       12    0.000    0.000    0.000    0.000 context.py:1046(device)\n",
       "        1    0.000    0.000    0.002    0.002 index_lookup.py:871(_lookup_table_from_tokens)\n",
       "       32    0.000    0.000    0.000    0.000 weakref.py:382(__getitem__)\n",
       "       47    0.000    0.000    0.000    0.000 ops.py:2622(name_from_scope_name)\n",
       "       62    0.000    0.000    0.000    0.000 {method 'throw' of 'generator' objects}\n",
       "       12    0.000    0.000    0.000    0.000 context.py:2152(__exit__)\n",
       "        1    0.000    0.000    0.003    0.003 readers.py:1688(read)\n",
       "        2    0.000    0.000    0.000    0.000 sparse_tensor.py:116(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 ops.py:5394(init_scope)\n",
       "        1    0.000    0.000    0.003    0.003 readers.py:1629(_make_engine)\n",
       "       37    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_TapeVariableAccessed}\n",
       "        1    0.000    0.000    0.006    0.006 readers.py:814(read_csv)\n",
       "      108    0.000    0.000    0.000    0.000 object_identity.py:132(__init__)\n",
       "       64    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "       20    0.000    0.000    0.000    0.000 conversion.py:33(_is_of_known_loaded_module)\n",
       "       33    0.000    0.000    0.000    0.000 nest_util.py:718(pack_sequence_as)\n",
       "       35    0.000    0.000    0.000    0.000 monomorphic_function.py:1535(<listcomp>)\n",
       "       12    0.000    0.000    0.000    0.000 function_type.py:202(get_default_values)\n",
       "       15    0.000    0.000    0.000    0.000 dataset_ops.py:672(_metadata)\n",
       "        2    0.000    0.000    0.002    0.001 math_ops.py:2123(range)\n",
       "        4    0.000    0.000    0.000    0.000 structure.py:196(_from_tensor_list_helper)\n",
       "        1    0.000    0.000    0.001    0.001 frame.py:641(__init__)\n",
       "       42    0.000    0.000    0.000    0.000 capture_container.py:246(get_by_ref_snapshot)\n",
       "        5    0.000    0.000    0.019    0.004 iterator_ops.py:672(__init__)\n",
       "       86    0.000    0.000    0.000    0.000 ops.py:2952(_variable_creator_stack)\n",
       "        3    0.000    0.000    0.000    0.000 lookup_ops.py:1930(remove)\n",
       "       67    0.000    0.000    0.000    0.000 _collections_abc.py:698(__init__)\n",
       "      150    0.000    0.000    0.000    0.000 object_identity.py:183(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 np_math_ops.py:1414(enable_numpy_methods_on_tensor)\n",
       "       67    0.000    0.000    0.000    0.000 traceable_stack.py:117(__len__)\n",
       "       69    0.000    0.000    0.000    0.000 config_lib.py:46(get_action)\n",
       "        8    0.000    0.000    0.001    0.000 polymorphic_function.py:572(_compiler_with_scope)\n",
       "      134    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
       "       45    0.000    0.000    0.000    0.000 ops.py:4930(_device_function_stack)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:597(_handle_deferred_dependencies)\n",
       "      110    0.000    0.000    0.000    0.000 traceable_stack.py:111(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 function_cache.py:63(add)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
       "        6    0.000    0.000    0.000    0.000 base_layer.py:3320(_flatten_modules)\n",
       "        2    0.000    0.000    0.000    0.000 options.py:648(_to_proto)\n",
       "       20    0.000    0.000    0.000    0.000 base.py:325(_maybe_initialize_trackable)\n",
       "        2    0.000    0.000    0.001    0.000 from_tensors_op.py:29(__init__)\n",
       "      8/4    0.000    0.000    0.000    0.000 default_types.py:212(_to_tensors)\n",
       "        4    0.000    0.000    0.000    0.000 atomic_function.py:98(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 ragged_functional_ops.py:25(map_flat_values)\n",
       "        6    0.000    0.000    0.000    0.000 structure.py:343(reduce_fn)\n",
       "        4    0.000    0.000    0.041    0.010 polymorphic_function.py:659(_initialize)\n",
       "        2    0.000    0.000    0.000    0.000 row_partition.py:118(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 c_parser_wrapper.py:222(read)\n",
       "       12    0.000    0.000    0.000    0.000 function_spec.py:414(_validate_signature)\n",
       "       48    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsMutableMapping}\n",
       "      199    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 c_parser_wrapper.py:368(_concatenate_chunks)\n",
       "      142    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
       "       93    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "        2    0.000    0.000    0.000    0.000 repeat_op.py:31(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 handle_data_util.py:83(create_handle_data)\n",
       "       10    0.000    0.000    0.000    0.000 tensor_shape.py:1055(concatenate)\n",
       "       10    0.000    0.000    0.000    0.000 row_partition.py:847(static_nrows)\n",
       "       21    0.000    0.000    0.000    0.000 tensor_util.py:254(GetNumpyAppendFn)\n",
       "       85    0.000    0.000    0.000    0.000 iterator_ops.py:926(__init__)\n",
       "       37    0.000    0.000    0.000    0.000 func_graph.py:1132(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 cache.py:39(has)\n",
       "       32    0.000    0.000    0.000    0.000 record.py:119(could_possibly_record)\n",
       "       91    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
       "        1    0.000    0.000    0.001    0.001 lookup_ops.py:1817(__init__)\n",
       "       24    0.000    0.000    0.000    0.000 capture_container.py:34(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "       54    0.000    0.000    0.000    0.000 base_layer_utils.py:942(has_weights)\n",
       "        9    0.000    0.000    0.000    0.000 function_spec.py:485(_get_variable_specs)\n",
       "        4    0.000    0.000    0.000    0.000 object_identity.py:220(add)\n",
       "       36    0.000    0.000    0.000    0.000 trace.py:50(__init__)\n",
       "       40    0.000    0.000    0.000    0.000 distribute_lib.py:704(_get_default_replica_mode)\n",
       "        7    0.000    0.000    0.040    0.006 tracing_compiler.py:165(_maybe_define_concrete_function)\n",
       "        1    0.000    0.000    0.001    0.001 from_tensor_slices_op.py:31(__init__)\n",
       "       38    0.000    0.000    0.000    0.000 nest_util.py:159(is_namedtuple)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_AddInputList}\n",
       "        3    0.000    0.000    0.002    0.001 gen_array_ops.py:8487(reshape)\n",
       "        2    0.000    0.000    0.003    0.001 gen_string_ops.py:1326(string_split_v2)\n",
       "        1    0.000    0.000    0.002    0.002 index_lookup.py:781(_lookup_dense)\n",
       "       68    0.000    0.000    0.000    0.000 ops.py:2956(_check_not_finalized)\n",
       "        1    0.000    0.000    0.003    0.003 readers.py:1362(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 ops.py:6431(__enter__)\n",
       "      2/1    0.000    0.000    0.000    0.000 variables.py:191(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:4632(_reduce)\n",
       "       12    0.000    0.000    0.000    0.000 conversion.py:42(_is_known_loaded_type)\n",
       "        4    0.000    0.000    0.001    0.000 math_ops.py:2218(_ReductionDims)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "       32    0.000    0.000    0.000    0.000 monomorphic_function.py:1677(_build_call_outputs)\n",
       "       59    0.000    0.000    0.000    0.000 nest_util.py:1089(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 dataset_ops.py:635(_flat_shapes)\n",
       "       12    0.000    0.000    0.000    0.000 ops.py:5031(device)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:222(__init__)\n",
       "      123    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
       "        3    0.000    0.000    0.000    0.000 common.py:1656(pandas_dtype)\n",
       "       64    0.000    0.000    0.000    0.000 atomic_function.py:115(function_type)\n",
       "       13    0.000    0.000    0.003    0.000 array_ops_stack.py:24(stack)\n",
       "       30    0.000    0.000    0.000    0.000 resource.py:167(resource_handle)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:2249(_stack_arrays)\n",
       "       69    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:2191(_form_blocks)\n",
       "       13    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_MonitoringGetCellBoolGauge0}\n",
       "       32    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_TapeSetPossibleGradientTypes}\n",
       "        2    0.000    0.000    0.001    0.001 gen_array_ops.py:1241(concat_v2)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:1469(_clean_options)\n",
       "        3    0.000    0.000    0.000    0.000 api.py:493(tf_convert)\n",
       "        8    0.000    0.000    0.000    0.000 nest.py:1260(flatten_with_tuple_paths)\n",
       "       19    0.000    0.000    0.000    0.000 inspect.py:1520(currentframe)\n",
       "       15    0.000    0.000    0.001    0.000 options.py:691(merge)\n",
       "        3    0.000    0.000    0.000    0.000 gen_lookup_ops.py:823(lookup_table_export_v2)\n",
       "       10    0.000    0.000    0.000    0.000 type_spec.py:966(_type_spec_from_value)\n",
       "       32    0.000    0.000    0.000    0.000 polymorphic_function.py:793(_run_functions_eagerly)\n",
       "       40    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_TapeSetIsStopped}\n",
       "       32    0.000    0.000    0.000    0.000 data_adapter.py:1441(should_sync)\n",
       "        4    0.000    0.000    0.000    0.000 execute.py:222(args_to_matching_eager)\n",
       "      100    0.000    0.000    0.000    0.000 trace_type_builder.py:46(is_legacy_signature)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
       "        4    0.000    0.000    0.000    0.000 monitoring.py:514(__exit__)\n",
       "        9    0.000    0.000    0.000    0.000 tensor_util.py:879(constant_value)\n",
       "        4    0.000    0.000    0.001    0.000 monomorphic_function.py:148(__init__)\n",
       "        3    0.000    0.000    0.003    0.001 resource.py:89(__call__)\n",
       "       32    0.000    0.000    0.000    0.000 nest_util.py:267(_tf_core_sorted)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:1151(_is_binary_mode)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:108(<listcomp>)\n",
       "       24    0.000    0.000    0.000    0.000 nest.py:419(pack_sequence_as)\n",
       "        8    0.000    0.000    0.000    0.000 tf_logging.py:246(vlog)\n",
       "        5    0.000    0.000    0.024    0.005 api.py:449(_call_unconverted)\n",
       "        2    0.000    0.000    0.001    0.000 array_ops.py:669(shape_internal)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:285(_get_filepath_or_buffer)\n",
       "       79    0.000    0.000    0.000    0.000 object_identity.py:39(_assert_type)\n",
       "        9    0.000    0.000    0.000    0.000 nest_util.py:911(_tf_data_pack_sequence_as)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
       "        1    0.000    0.000    0.000    0.000 resource_variable_ops.py:381(__init__)\n",
       "       36    0.000    0.000    0.000    0.000 polymorphic_function.py:439(__init__)\n",
       "       88    0.000    0.000    0.000    0.000 context.py:2100(context_switches)\n",
       "        8    0.000    0.000    0.000    0.000 ops.py:3864(get_collection)\n",
       "       20    0.000    0.000    0.000    0.000 structure.py:295(get_flat_tensor_shapes)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_NewBufferFromString}\n",
       "        1    0.000    0.000    0.003    0.003 index_lookup.py:630(update_state)\n",
       "        4    0.000    0.000    0.000    0.000 monomorphic_function.py:64(_parse_func_attrs)\n",
       "        1    0.000    0.000    0.001    0.001 index_lookup.py:866(_uninitialized_lookup_table)\n",
       "       40    0.000    0.000    0.000    0.000 object_identity.py:236(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 range.py:108(__new__)\n",
       "        1    0.000    0.000    0.005    0.005 data_adapter.py:1102(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 conversion.py:69(is_unsupported)\n",
       "        4    0.000    0.000    0.000    0.000 lock_util.py:52(__init__)\n",
       "       22    0.000    0.000    0.000    0.000 trace_type_builder.py:59(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 function_spec.py:296(arg_names)\n",
       "       67    0.000    0.000    0.000    0.000 ops.py:4956(<dictcomp>)\n",
       "        1    0.000    0.000    0.017    0.017 __autograph_generated_fileqqpl0fq9.py:7(tf__adapt_step)\n",
       "        1    0.000    0.000    0.028    0.028 data_adapter.py:703(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:2378(_instrument_layer_creation)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_MonitoringGetCellCounter0}\n",
       "       82    0.000    0.000    0.000    0.000 iterator_ops.py:862(element_spec)\n",
       "        3    0.000    0.000    0.008    0.003 api.py:682(wrapper)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:1999(insert)\n",
       "       32    0.000    0.000    0.000    0.000 gradients_util.py:1038(PossibleTapeGradientTypes)\n",
       "        5    0.000    0.000    0.000    0.000 tf_inspect.py:267(getfullargspec)\n",
       "       33    0.000    0.000    0.000    0.000 ag_ctx.py:28(_control_ctx)\n",
       "       14    0.000    0.000    0.000    0.000 weakref.py:419(get)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:640(_simple_new)\n",
       "    27/17    0.000    0.000    0.000    0.000 dataset_ops.py:4454(element_spec)\n",
       "        5    0.000    0.000    0.000    0.000 monitoring.py:199(get_cell)\n",
       "        2    0.000    0.000    0.001    0.001 array_ops.py:4925(gather)\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:1451(internal_convert_n_to_tensor)\n",
       "       21    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "        3    0.000    0.000    0.003    0.001 resource.py:91(default_resource_creator)\n",
       "       14    0.000    0.000    0.000    0.000 ag_logging.py:110(get_verbosity)\n",
       "       74    0.000    0.000    0.000    0.000 resource_variable_ops.py:623(handle)\n",
       "        4    0.000    0.000    0.001    0.000 gen_math_ops.py:444(add_v2)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:820(_engine)\n",
       "        2    0.000    0.000    0.002    0.001 lookup_ops.py:307(__init__)\n",
       "      3/2    0.000    0.000    0.000    0.000 ragged_functional_ops.py:139(_replace_ragged_with_flat_values)\n",
       "       13    0.000    0.000    0.000    0.000 tensor_util.py:341(_check_not_tensor)\n",
       "        2    0.000    0.000    0.001    0.000 math_ops.py:4304(cumsum)\n",
       "       89    0.000    0.000    0.000    0.000 function_spec.py:268(function_type)\n",
       "        2    0.000    0.000    0.019    0.010 dataset_ops.py:493(__iter__)\n",
       "       12    0.000    0.000    0.000    0.000 context.py:2412(device)\n",
       "        2    0.000    0.000    0.002    0.001 gen_array_ops.py:9572(_slice)\n",
       "        1    0.000    0.000    0.000    0.000 range_op.py:31(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 inspect_utils.py:62(isbuiltin)\n",
       "        3    0.000    0.000    0.001    0.000 auto_control_deps.py:206(mark_as_return)\n",
       "       10    0.000    0.000    0.000    0.000 context.py:1027(scope_name)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:1573(construct_1d_object_array_from_listlike)\n",
       "        2    0.000    0.000    0.000    0.000 capture_container.py:260(_create_placeholder_helper)\n",
       "        2    0.000    0.000    0.001    0.000 gen_math_ops.py:6146(maximum)\n",
       "      3/2    0.000    0.000    0.000    0.000 type_spec.py:144(most_specific_common_supertype)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:377(urlparse)\n",
       "        1    0.000    0.000    0.001    0.001 lookup_ops.py:1956(lookup)\n",
       "       10    0.000    0.000    0.002    0.000 tensor_conversion.py:165(convert_to_tensor_v2)\n",
       "        4    0.000    0.000    0.000    0.000 preprocessing_utils.py:29(ensure_tensor)\n",
       "        4    0.000    0.000    0.004    0.001 array_ops.py:933(_slice_helper)\n",
       "        2    0.000    0.000    0.000    0.000 layer_utils.py:776(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:1917(size)\n",
       "        1    0.000    0.000    0.005    0.005 data_adapter.py:316(slice_batch_indices)\n",
       "        4    0.000    0.000    0.000    0.000 monomorphic_function.py:1096(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 inspect.py:1812(_signature_bound_method)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:653(is_integer_dtype)\n",
       "        2    0.000    0.000    0.001    0.000 math_ops.py:2839(reduce_prod)\n",
       "        3    0.000    0.000    0.001    0.000 structured_function.py:235(trace_tf_function)\n",
       "       40    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:10967(_logical_func)\n",
       "       78    0.000    0.000    0.000    0.000 function_spec.py:278(input_signature)\n",
       "        2    0.000    0.000    0.001    0.000 gen_math_ops.py:1833(bincount)\n",
       "        8    0.000    0.000    0.000    0.000 ops.py:2818(_variable_creator_scope)\n",
       "       85    0.000    0.000    0.000    0.000 function_spec.py:263(default_values)\n",
       "       69    0.000    0.000    0.000    0.000 ops.py:3014(_get_control_flow_context)\n",
       "      2/1    0.000    0.000    0.014    0.014 traceback_utils.py:59(error_handler)\n",
       "        4    0.000    0.000    0.000    0.000 auto_control_deps.py:265(__enter__)\n",
       "       33    0.000    0.000    0.000    0.000 iterator_ops.py:898(__tf_tracing_type__)\n",
       "       34    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsTypeSpec}\n",
       "       70    0.000    0.000    0.000    0.000 op_def_library.py:249(_MaybeColocateWith)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:561(initialize)\n",
       "        7    0.000    0.000    0.000    0.000 func_graph.py:859(internal_captures)\n",
       "       38    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsCompositeTensor}\n",
       "        9    0.000    0.000    0.000    0.000 atomic_function.py:433(<genexpr>)\n",
       "       20    0.000    0.000    0.000    0.000 structure.py:305(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 lookup_ops.py:226(lookup)\n",
       "       40    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsAttrs}\n",
       "        1    0.000    0.000    0.000    0.000 base.py:5314(equals)\n",
       "       32    0.000    0.000    0.000    0.000 tensor_shape.py:915(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 resource_variable_ops.py:150(_variable_handle_from_shape_and_dtype)\n",
       "        4    0.000    0.000    0.001    0.000 math_ops.py:1809(_add_dispatch)\n",
       "       15    0.000    0.000    0.000    0.000 ops.py:5143(colocate_with)\n",
       "        2    0.000    0.000    0.000    0.000 gen_dataset_ops.py:7529(tensor_dataset)\n",
       "        1    0.000    0.000    0.000    0.000 gen_array_ops.py:12157(unique_with_counts)\n",
       "        9    0.000    0.000    0.000    0.000 execute.py:177(make_type)\n",
       "       17    0.000    0.000    0.000    0.000 structure.py:308(get_flat_tensor_types)\n",
       "        2    0.000    0.000    0.001    0.000 gen_math_ops.py:7703(_range)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "        2    0.000    0.000    0.002    0.001 lookup_ops.py:350(_create_resource)\n",
       "       13    0.000    0.000    0.000    0.000 nest.py:1184(yield_flat_paths)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:1373(get_function_def)\n",
       "        1    0.000    0.000    0.000    0.000 base_layer.py:3002(_maybe_build)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:2061(__init__)\n",
       "       38    0.000    0.000    0.000    0.000 typing.py:1017(<genexpr>)\n",
       "        2    0.000    0.000    0.002    0.001 gen_lookup_ops.py:432(hash_table_v2)\n",
       "        1    0.000    0.000    0.001    0.001 concatenate_op.py:29(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 backend.py:1174(unique_object_name)\n",
       "      177    0.000    0.000    0.000    0.000 options.py:84(<lambda>)\n",
       "        1    0.000    0.000    0.001    0.001 gen_dataset_ops.py:3007(iterator_get_next)\n",
       "       10    0.000    0.000    0.000    0.000 tensor_util.py:324(inner)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:531(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:125(__init__)\n",
       "        3    0.000    0.000    0.008    0.003 structured_function.py:237(wrapped_fn)\n",
       "        2    0.000    0.000    0.001    0.000 gen_math_ops.py:4066(greater)\n",
       "       34    0.000    0.000    0.000    0.000 function_spec.py:156(<genexpr>)\n",
       "       32    0.000    0.000    0.000    0.000 atomic_function.py:135(cached_definition)\n",
       "        1    0.000    0.000    0.002    0.002 index_lookup.py:738(call)\n",
       "        2    0.000    0.000    0.000    0.000 gen_math_ops.py:6394(minimum)\n",
       "        1    0.000    0.000    0.007    0.007 data_adapter.py:372(slice_inputs)\n",
       "        6    0.000    0.000    0.000    0.000 converter.py:147(__init__)\n",
       "       40    0.000    0.000    0.000    0.000 atomic_function.py:143(name)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.platform._pywrap_tf2.is_enabled}\n",
       "        1    0.000    0.000    0.000    0.000 series.py:521(_init_dict)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:259(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 options.py:406(_to_proto)\n",
       "        1    0.000    0.000    0.000    0.000 base_preprocessing_layer.py:97(make_adapt_function)\n",
       "        3    0.000    0.000    0.002    0.001 array_ops.py:62(reshape)\n",
       "        7    0.000    0.000    0.000    0.000 variable_utils.py:37(_convert_resource_variable_to_tensor)\n",
       "       39    0.000    0.000    0.000    0.000 function_spec.py:393(<dictcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 policy.py:468(get_policy)\n",
       "        2    0.000    0.000    0.001    0.000 math_ops.py:1953(wrapper)\n",
       "       12    0.000    0.000    0.000    0.000 dataset_ops.py:644(_flat_types)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\n",
       "        9    0.000    0.000    0.000    0.000 structure.py:442(type_spec_from_value)\n",
       "       22    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsNestedForData}\n",
       "        4    0.000    0.000    0.000    0.000 common.py:460(is_categorical_dtype)\n",
       "        4    0.000    0.000    0.001    0.000 func_graph.py:1030(convert)\n",
       "        1    0.000    0.000    0.000    0.000 zip_op.py:30(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 ops.py:6465(__exit__)\n",
       "        1    0.000    0.000    0.001    0.001 gen_dataset_ops.py:7607(tensor_slice_dataset)\n",
       "       13    0.000    0.000    0.000    0.000 nest_util.py:1126(yield_flat_up_to)\n",
       "        8    0.000    0.000    0.000    0.000 ag_ctx.py:76(__exit__)\n",
       "        4    0.000    0.000    0.000    0.000 context.py:1333(add_c_function)\n",
       "       38    0.000    0.000    0.000    0.000 inspect.py:80(ismethod)\n",
       "       64    0.000    0.000    0.000    0.000 context.py:180(config_proto_serialized)\n",
       "       36    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsMapping}\n",
       "        3    0.000    0.000    0.000    0.000 traceable_stack.py:31(set_filename_and_line_from_caller)\n",
       "       11    0.000    0.000    0.000    0.000 monitoring.py:324(set)\n",
       "        9    0.000    0.000    0.000    0.000 tensor_shape.py:1078(assert_same_rank)\n",
       "        5    0.000    0.000    0.000    0.000 ops.py:2012(device)\n",
       "      7/4    0.000    0.000    0.000    0.000 type_spec.py:163(make_supertype_attribute)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:1881(_refine_defaults_read)\n",
       "        8    0.000    0.000    0.000    0.000 tensor.py:337(_cast)\n",
       "       36    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.IsMappingView}\n",
       "       10    0.000    0.000    0.000    0.000 nest_util.py:402(assert_same_structure)\n",
       "        7    0.000    0.000    0.000    0.000 conversion.py:214(is_in_allowlist_cache)\n",
       "        2    0.000    0.000    0.001    0.000 gen_array_ops.py:3915(gather_v2)\n",
       "       66    0.000    0.000    0.000    0.000 tensor.py:119(shape)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:155(get_effective_source_map)\n",
       "       38    0.000    0.000    0.000    0.000 save_context.py:42(in_save_context)\n",
       "       79    0.000    0.000    0.000    0.000 ops.py:2810(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:1414(_get_options_with_defaults)\n",
       "        3    0.000    0.000    0.000    0.000 dtypes.py:70(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 tracing_compiler.py:476(_insert_capture_type)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
       "       16    0.000    0.000    0.000    0.000 threading.py:81(RLock)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_FunctionSetAttrValueProto}\n",
       "        2    0.000    0.000    0.003    0.001 base_layer.py:3417(_set_save_spec)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:1056(concatenate_dataset)\n",
       "        5    0.000    0.000    0.000    0.000 ops.py:5532(inside_function)\n",
       "        2    0.000    0.000    0.000    0.000 _ufunc_config.py:33(seterr)\n",
       "        2    0.000    0.000    0.000    0.000 contextlib.py:482(__exit__)\n",
       "        9    0.000    0.000    0.000    0.000 function_type.py:483(<listcomp>)\n",
       "       37    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_TapeSetStopOnThread}\n",
       "        1    0.000    0.000    0.000    0.000 tf_inspect.py:289(getcallargs)\n",
       "       79    0.000    0.000    0.000    0.000 ops.py:2803(_c_graph)\n",
       "       14    0.000    0.000    0.000    0.000 os.py:766(getenv)\n",
       "       20    0.000    0.000    0.000    0.000 ops.py:3839(get_collection_ref)\n",
       "        9    0.000    0.000    0.001    0.000 dataset_ops.py:4438(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 array_ops.py:806(size_internal)\n",
       "        4    0.000    0.000    0.002    0.000 array_ops.py:1189(strided_slice)\n",
       "        3    0.000    0.000    0.000    0.000 shape_util.py:42(maybe_set_static_shape)\n",
       "        5    0.000    0.000    0.000    0.000 tensor.py:406(_from_compatible_tensor_list)\n",
       "       24    0.000    0.000    0.000    0.000 conversion.py:95(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:1137(has_mutation)\n",
       "       62    0.000    0.000    0.000    0.000 errors_impl.py:96(message)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:108(check_table_dtypes)\n",
       "       15    0.000    0.000    0.000    0.000 os.py:748(encode)\n",
       "       36    0.000    0.000    0.000    0.000 polymorphic_function.py:449(__exit__)\n",
       "        2    0.000    0.000    0.002    0.001 gen_lookup_ops.py:932(lookup_table_find_v2)\n",
       "      9/7    0.000    0.000    0.000    0.000 nest_util.py:510(_tf_core_assert_same_structure)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_ContextSyncExecutors}\n",
       "        1    0.000    0.000    0.001    0.001 gen_lookup_ops.py:508(hash_table_v2_eager_fallback)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:2119(create_block_manager_from_column_arrays)\n",
       "       11    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_MonitoringBoolGaugeCellSet}\n",
       "        4    0.000    0.000    0.000    0.000 variable_scope.py:1470(get_variable_scope)\n",
       "        1    0.000    0.000    0.003    0.003 string_lookup.py:310(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:2670(convert_to_tensor_or_ragged_tensor)\n",
       "       12    0.000    0.000    0.000    0.000 default_types.py:162(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:3904(get_all_collection_keys)\n",
       "        2    0.000    0.000    0.001    0.000 gen_math_ops.py:6072(_max)\n",
       "        3    0.000    0.000    0.000    0.000 api.py:679(decorator)\n",
       "        2    0.000    0.000    0.001    0.000 gen_math_ops.py:7137(prod)\n",
       "       12    0.000    0.000    0.000    0.000 context.py:2225(ensure_initialized)\n",
       "        1    0.000    0.000    0.003    0.003 data_adapter.py:448(can_handle)\n",
       "        2    0.000    0.000    0.001    0.000 gen_math_ops.py:2774(cumsum)\n",
       "       12    0.000    0.000    0.000    0.000 device.py:40(is_device_spec)\n",
       "        2    0.000    0.000    0.013    0.006 map_op.py:27(_map_v2)\n",
       "       61    0.000    0.000    0.000    0.000 control_flow_util.py:187(GetContainingWhileContext)\n",
       "        4    0.000    0.000    0.000    0.000 capture_container.py:298(capture_types)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:1497(log)\n",
       "        3    0.000    0.000    0.000    0.000 lookup_ops.py:131(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 polymorphic_function.py:997(input_signature)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4652(_attr_scope)\n",
       "       18    0.000    0.000    0.000    0.000 function_spec.py:298(<genexpr>)\n",
       "        6    0.000    0.000    0.000    0.000 common.py:1244(is_bool_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 np_config.py:23(enable_numpy_behavior)\n",
       "       43    0.000    0.000    0.000    0.000 iterator_ops.py:940(_to_components)\n",
       "        3    0.000    0.000    0.000    0.000 function_utils.py:85(get_func_name)\n",
       "        2    0.000    0.000    0.000    0.000 tf_export.py:100(get_canonical_name_for_symbol)\n",
       "       13    0.000    0.000    0.000    0.000 _methods.py:61(_all)\n",
       "        3    0.000    0.000    0.001    0.000 data_adapter.py:1150(_convert_single_tensor)\n",
       "        8    0.000    0.000    0.000    0.000 tensor_shape.py:1529(unknown_shape)\n",
       "       43    0.000    0.000    0.000    0.000 function_spec.py:287(is_pure)\n",
       "        1    0.000    0.000    0.000    0.000 transpiler.py:186(instantiate)\n",
       "        4    0.000    0.000    0.000    0.000 tensor.py:45(sanitize_spec_name)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:1335(is_extension_array_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:259(schedule)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method _functools.reduce}\n",
       "       60    0.000    0.000    0.000    0.000 resource.py:149(_resource_handle)\n",
       "        3    0.000    0.000    0.000    0.000 data_adapter.py:223(can_handle)\n",
       "        2    0.000    0.000    0.000    0.000 options.py:118(_to_proto)\n",
       "        8    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
       "        4    0.000    0.000    0.001    0.000 atomic_function.py:354(from_func_graph)\n",
       "        7    0.000    0.000    0.000    0.000 tensor_shape.py:1106(with_rank)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1677(as_array)\n",
       "        9    0.000    0.000    0.000    0.000 tensor_shape.py:303(merge_with)\n",
       "       32    0.000    0.000    0.000    0.000 atomic_function.py:42(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 <string>:2(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 execute.py:187(make_shape)\n",
       "       48    0.000    0.000    0.000    0.000 tensor.py:432(_flat_tensor_specs)\n",
       "        2    0.000    0.000    0.001    0.000 base_preprocessing_layer.py:56(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 gen_lookup_ops.py:1160(lookup_table_remove_v2)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:692(getsourcefile)\n",
       "        4    0.000    0.000    0.000    0.000 op_def_library.py:196(_MakeShape)\n",
       "        1    0.000    0.000    0.000    0.000 gen_array_ops.py:1293(concat_v2_eager_fallback)\n",
       "        8    0.000    0.000    0.000    0.000 ag_ctx.py:68(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 handle_data_util.py:24(get_resource_handle_data)\n",
       "       38    0.000    0.000    0.000    0.000 options.py:65(_set_mutable)\n",
       "        4    0.000    0.000    0.000    0.000 auto_control_deps.py:201(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 cast.py:123(maybe_convert_platform)\n",
       "        1    0.000    0.000    0.001    0.001 iterator_ops.py:757(_next_internal)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:854(external_captures)\n",
       "        8    0.000    0.000    0.000    0.000 nest.py:69(pack_sequence_as)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:534(infer_compression)\n",
       "       13    0.000    0.000    0.000    0.000 nest.py:159(is_nested)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:5106(reindex)\n",
       "       37    0.000    0.000    0.000    0.000 distribute_lib.py:1203(extended)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:152(<lambda>)\n",
       "       30    0.000    0.000    0.000    0.000 op_def_library.py:44(_AttrValue)\n",
       "        1    0.000    0.000    0.000    0.000 base_preprocessing_layer.py:269(_configure_steps_per_execution)\n",
       "        6    0.000    0.000    0.001    0.000 dataset_ops.py:4449(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 gen_array_ops.py:9357(shape)\n",
       "        7    0.000    0.000    0.000    0.000 variable_utils.py:23(convert_variables_to_tensors)\n",
       "       17    0.000    0.000    0.000    0.000 structure.py:318(<listcomp>)\n",
       "       13    0.000    0.000    0.000    0.000 tensor_util.py:342(<listcomp>)\n",
       "        4    0.000    0.000    0.040    0.010 tracing_compiler.py:173(_get_concrete_function_internal_garbage_collected)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4166(colocate_with)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.util._pywrap_utils.AssertSameStructureForData}\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:1689(isEnabledFor)\n",
       "        2    0.000    0.000    0.000    0.000 tf_decorator.py:200(rewrap)\n",
       "       12    0.000    0.000    0.000    0.000 context.py:2111(__init__)\n",
       "       17    0.000    0.000    0.000    0.000 traceable_stack.py:73(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 resource.py:153(_resource_handle)\n",
       "        1    0.000    0.000    0.001    0.001 lookup_ops.py:1873(_create_resource)\n",
       "        4    0.000    0.000    0.000    0.000 cache.py:46(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:2635(from_value)\n",
       "        3    0.000    0.000    0.000    0.000 traceable_stack.py:82(push_obj)\n",
       "        5    0.000    0.000    0.000    0.000 tensor_shape.py:1393(is_fully_defined)\n",
       "        2    0.000    0.000    0.001    0.000 gen_math_ops.py:6559(mul)\n",
       "       79    0.000    0.000    0.000    0.000 ops.py:2813(get)\n",
       "        8    0.000    0.000    0.002    0.000 tensor_conversion.py:95(convert_to_tensor_v2_with_dispatch)\n",
       "        8    0.000    0.000    0.000    0.000 options.py:52(__setattr__)\n",
       "        2    0.000    0.000    0.000    0.000 variables.py:160(validate_synchronization_aggregation_trainable)\n",
       "       38    0.000    0.000    0.000    0.000 function_spec.py:318(<dictcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_MonitoringCounterCellIncrementBy}\n",
       "       26    0.000    0.000    0.000    0.000 flags.py:25(config)\n",
       "        4    0.000    0.000    0.000    0.000 tensor.py:62(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 conversion.py:222(cache_allowlisted)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:1365(catch_stop_iteration)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:178(_validate_parse_dates_presence)\n",
       "        7    0.000    0.000    0.000    0.000 object_identity.py:211(_wrap_key)\n",
       "        1    0.000    0.000    0.000    0.000 function_wrappers.py:43(__init__)\n",
       "       36    0.000    0.000    0.000    0.000 polymorphic_function.py:445(__enter__)\n",
       "        4    0.000    0.000    0.001    0.000 monomorphic_function.py:1074(_set_function_spec)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:428(urlsplit)\n",
       "        2    0.000    0.000    0.001    0.000 math_ops.py:3189(reduce_max_with_dims)\n",
       "        3    0.000    0.000    0.000    0.000 inference.py:267(is_dict_like)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:264(_get_values)\n",
       "        8    0.000    0.000    0.000    0.000 function_cache.py:34(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 range.py:166(_simple_new)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:3907(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 row_partition.py:669(_convert_row_partition)\n",
       "       17    0.000    0.000    0.000    0.000 dtypes.py:220(is_subtype_of)\n",
       "       14    0.000    0.000    0.000    0.000 ag_logging.py:117(has_verbosity)\n",
       "        1    0.000    0.000    0.005    0.005 data_adapter.py:1100(select_data_adapter)\n",
       "        1    0.000    0.000    0.000    0.000 gen_control_flow_ops.py:464(no_op)\n",
       "        2    0.000    0.000    0.000    0.000 math_ops.py:1969(equal)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:306(apply)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:499(nanany)\n",
       "        5    0.000    0.000    0.000    0.000 monitoring.py:165(increase_by)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:1190(is_potential_multi_index)\n",
       "        2    0.000    0.000    0.000    0.000 tensor_shape.py:1224(most_specific_common_supertype)\n",
       "        8    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
       "       32    0.000    0.000    0.000    0.000 cancellation.py:46(context)\n",
       "       40    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
       "       79    0.000    0.000    0.000    0.000 ops.py:2807(__enter__)\n",
       "       10    0.000    0.000    0.000    0.000 object_identity.py:144(__delitem__)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:189(_isna)\n",
       "       13    0.000    0.000    0.000    0.000 ag_logging.py:134(log)\n",
       "        4    0.000    0.000    0.000    0.000 default_types.py:296(_to_tensors)\n",
       "        1    0.000    0.000    0.000    0.000 gen_array_ops.py:8591(reshape_eager_fallback)\n",
       "        4    0.000    0.000    0.000    0.000 monitoring.py:499(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 tf_stack.py:74(update)\n",
       "        4    0.000    0.000    0.000    0.000 np_array_ops.py:1486(_as_index)\n",
       "        2    0.000    0.000    0.001    0.001 array_ops.py:1558(concat)\n",
       "       35    0.000    0.000    0.000    0.000 op_def_library.py:743(_CheckAllInputsUsed)\n",
       "        7    0.000    0.000    0.000    0.000 converter.py:168(__hash__)\n",
       "        1    0.000    0.000    0.000    0.000 transpiler.py:432(transform_function)\n",
       "       10    0.000    0.000    0.000    0.000 cache.py:88(_get_key)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:6342(copy)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:141(is_url)\n",
       "        2    0.000    0.000    0.000    0.000 enum_type_wrapper.py:92(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:2717(_set_dtype_policy)\n",
       "       37    0.000    0.000    0.000    0.000 resource_variable_ops.py:667(trainable)\n",
       "       16    0.000    0.000    0.000    0.000 trace_type_builder.py:168(<genexpr>)\n",
       "        5    0.000    0.000    0.000    0.000 traceable_stack.py:65(copy_metadata)\n",
       "       32    0.000    0.000    0.000    0.000 atomic_function.py:48(__exit__)\n",
       "        6    0.000    0.000    0.000    0.000 base_layer.py:3313(_flatten_layers)\n",
       "        2    0.000    0.000    0.000    0.000 backend.py:872(get_default_graph_uid_map)\n",
       "        7    0.000    0.000    0.000    0.000 func_graph.py:869(deferred_internal_captures)\n",
       "        3    0.000    0.000    0.000    0.000 config_lib.py:58(get_action)\n",
       "        6    0.000    0.000    0.000    0.000 nest.py:45(assert_same_structure)\n",
       "       30    0.000    0.000    0.000    0.000 tensor_shape.py:1222(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:4252(device)\n",
       "        3    0.000    0.000    0.003    0.001 resource.py:97(<lambda>)\n",
       "       31    0.000    0.000    0.000    0.000 tensor_shape.py:860(_v2_behavior)\n",
       "       13    0.000    0.000    0.000    0.000 nest_util.py:134(is_nested)\n",
       "        2    0.000    0.000    0.000    0.000 sre_parse.py:1054(expand_template)\n",
       "        1    0.000    0.000    0.000    0.000 range_op.py:42(_parse_args)\n",
       "        2    0.000    0.000    0.000    0.000 version_utils.py:47(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 resource_variable_ops.py:337(default_variable_creator_v2)\n",
       "        3    0.000    0.000    0.000    0.000 distribute_lib.py:540(get_strategy)\n",
       "        1    0.000    0.000    0.001    0.001 base_preprocessing_layer.py:139(compile)\n",
       "        4    0.000    0.000    0.000    0.000 monomorphic_function.py:114(_inference_name)\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:1551(internal_convert_to_tensor_or_composite)\n",
       "       16    0.000    0.000    0.000    0.000 func_graph.py:503(outer_graph)\n",
       "        8    0.000    0.000    0.000    0.000 variable_scope.py:1233(set_use_resource)\n",
       "      2/1    0.000    0.000    0.000    0.000 variables.py:1187(_variable_call)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:400(_make)\n",
       "        5    0.000    0.000    0.000    0.000 execute.py:163(make_str)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'extend' of 'google._upb._message.RepeatedCompositeContainer' objects}\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:6349(get_current_name_scope)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:2813(_init_set_name)\n",
       "        3    0.000    0.000    0.000    0.000 tf_utils.py:489(is_ragged)\n",
       "        6    0.000    0.000    0.000    0.000 tf2.py:35(enabled)\n",
       "       32    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 base_preprocessing_layer.py:278(_adapt_maybe_build)\n",
       "       21    0.000    0.000    0.000    0.000 function_spec.py:429(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 trace_type_builder.py:160(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:573(variables)\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:75(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 trace.py:87(set_metadata)\n",
       "       18    0.000    0.000    0.000    0.000 function_type.py:486(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 polymorphic_function.py:201(called_with_tracing)\n",
       "       11    0.000    0.000    0.000    0.000 common.py:1435(_is_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:2636(_set_training_mode)\n",
       "        8    0.000    0.000    0.000    0.000 traceable_stack.py:121(copy)\n",
       "       42    0.000    0.000    0.000    0.000 inspect.py:2635(signature)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2955(prod)\n",
       "        1    0.000    0.000    0.018    0.018 autograph_util.py:38(autograph_handler)\n",
       "        4    0.000    0.000    0.000    0.000 variable_scope.py:1457(get_variable_scope_store)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:595(_set_noconvert_dtype_columns)\n",
       "        2    0.000    0.000    0.000    0.000 traceback_utils.py:77(inject_argument_info_in_traceback)\n",
       "        2    0.000    0.000    0.000    0.000 tf_stack.py:45(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 c_parser_wrapper.py:201(_set_noconvert_columns)\n",
       "        2    0.000    0.000    0.000    0.000 capture_container.py:153(add_or_replace)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_MonitoringGetCellCounter1}\n",
       "        2    0.000    0.000    0.000    0.000 options.py:291(_to_proto)\n",
       "        3    0.000    0.000    0.000    0.000 resource.py:273(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 context.py:1022(scope_name)\n",
       "       32    0.000    0.000    0.000    0.000 context.py:172(executor_type)\n",
       "        1    0.000    0.000    0.000    0.000 typing.py:868(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 autograph_util.py:23(py_func_from_autograph)\n",
       "        8    0.000    0.000    0.000    0.000 base.py:49(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:319(decode)\n",
       "        6    0.000    0.000    0.000    0.000 common.py:1209(is_float_dtype)\n",
       "       13    0.000    0.000    0.000    0.000 op_def_library.py:166(_MakeInt)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:812(_from_nested_row_partitions)\n",
       "        5    0.000    0.000    0.000    0.000 ops.py:6413(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 ag_ctx.py:34(control_status_ctx)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:2411(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 gen_math_ops.py:3272(equal)\n",
       "       36    0.000    0.000    0.000    0.000 trace.py:121(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4245(_add_device_to_stack)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.array_equivalent_object}\n",
       "        4    0.000    0.000    0.000    0.000 re.py:325(_subx)\n",
       "        4    0.000    0.000    0.000    0.000 converter.py:171(__eq__)\n",
       "        4    0.000    0.000    0.000    0.000 re.py:203(sub)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'extend' of 'google._upb._message.RepeatedScalarContainer' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _asarray.py:31(require)\n",
       "        4    0.000    0.000    0.000    0.000 default_types.py:653(_to_tensors)\n",
       "        4    0.000    0.000    0.000    0.000 math_ops.py:2236(_has_fully_defined_shape)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:2737(_maybe_cast_inputs)\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:727(reset_state)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:620(copy)\n",
       "        3    0.000    0.000    0.000    0.000 resource.py:115(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 generic_utils.py:480(to_snake_case)\n",
       "        9    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_GetBuffer}\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:5348(<genexpr>)\n",
       "        1    0.000    0.000    0.016    0.016 text_vectorization.py:475(update_state)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:11010(any)\n",
       "        2    0.000    0.000    0.001    0.000 math_ops.py:3139(reduce_max)\n",
       "        2    0.000    0.000    0.013    0.006 dataset_ops.py:2121(map)\n",
       "        3    0.000    0.000    0.000    0.000 tf_inspect.py:399(isfunction)\n",
       "        1    0.000    0.000    0.000    0.000 tf_stack.py:71(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 dataset_ops.py:705(from_tensors)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:2761(async_wait)\n",
       "        1    0.000    0.000    0.000    0.000 math_ops.py:1495(r_binary_op_wrapper)\n",
       "       10    0.000    0.000    0.000    0.000 map_op.py:177(element_spec)\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:965(_num_tokens)\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:401(vocabulary_size)\n",
       "       36    0.000    0.000    0.000    0.000 trace.py:83(__enter__)\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:552(_record_tape)\n",
       "        4    0.000    0.000    0.000    0.000 capture_container.py:42(__setitem__)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4441(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:438(_record_vocabulary_size)\n",
       "        8    0.000    0.000    0.000    0.000 base.py:423(_lookup_dependency)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\n",
       "       25    0.000    0.000    0.000    0.000 tensor.py:129(name)\n",
       "        9    0.000    0.000    0.000    0.000 tensor_shape.py:1039(<listcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 options.py:256(_set_mutable)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1340(_capture_as_const)\n",
       "        2    0.000    0.000    0.000    0.000 type_spec.py:220(placeholder_value)\n",
       "        4    0.000    0.000    0.000    0.000 atomic_function.py:385(<listcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 atomic_function.py:445(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:856(_convert_values_and_partition)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:214(size)\n",
       "      4/2    0.000    0.000    0.000    0.000 data_adapter.py:695(_is_list_of_scalars)\n",
       "        2    0.000    0.000    0.000    0.000 readers.py:486(validate_integer)\n",
       "        4    0.000    0.000    0.000    0.000 structure.py:217(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 posixpath.py:228(expanduser)\n",
       "        4    0.000    0.000    0.000    0.000 type_dispatch.py:38(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 dataset_ops.py:1326(repeat)\n",
       "        6    0.000    0.000    0.000    0.000 options.py:629(__setattr__)\n",
       "        2    0.000    0.000    0.000    0.000 _ufunc_config.py:132(geterr)\n",
       "       16    0.000    0.000    0.000    0.000 inspect.py:2246(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 device.py:128(shortcut_string_merge)\n",
       "       11    0.000    0.000    0.000    0.000 atomic_function.py:384(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:574(_homogenize)\n",
       "       12    0.000    0.000    0.000    0.000 execute.py:152(make_int)\n",
       "        5    0.000    0.000    0.000    0.000 ops.py:6455(_restore_name_scope)\n",
       "        1    0.000    0.000    0.000    0.000 polymorphic_function.py:1583(decorated)\n",
       "        2    0.000    0.000    0.000    0.000 nest_util.py:573(_tf_data_packed_nest_with_indices)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:97(arrays_to_mgr)\n",
       "        6    0.000    0.000    0.000    0.000 api.py:283(autograph_artifact)\n",
       "        2    0.000    0.000    0.019    0.009 gen_dataset_ops.py:3402(make_iterator)\n",
       "        6    0.000    0.000    0.000    0.000 nest_util.py:530(_tf_data_assert_same_structure)\n",
       "        2    0.000    0.000    0.001    0.000 prefetch_op.py:24(_prefetch)\n",
       "        5    0.000    0.000    0.000    0.000 structure.py:390(to_tensor_list)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:6144(get_collection)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:162(string_merge)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:3373(_init_call_fn_args)\n",
       "        1    0.000    0.000    0.000    0.000 gen_math_ops.py:9780(select_v2)\n",
       "       37    0.000    0.000    0.000    0.000 distribute_lib.py:4080(value_container)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:1346(_truncate_execution_to_epoch)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:1099(_make_date_converter)\n",
       "        2    0.000    0.000    0.000    0.000 policy.py:191(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer_utils.py:505(enter)\n",
       "        2    0.000    0.000    0.000    0.000 lookup_ops.py:503(_shared_name)\n",
       "        4    0.000    0.000    0.000    0.000 inspect.py:2865(replace)\n",
       "        1    0.000    0.000    0.000    0.000 blocks.py:534(copy)\n",
       "        4    0.000    0.000    0.000    0.000 default_types.py:253(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 {method 'WhichOneof' of 'google._upb._message.Message' objects}\n",
       "        4    0.000    0.000    0.000    0.000 tensor_shape.py:1268(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:755(can_handle)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:2993(_shape_as_tensor)\n",
       "        3    0.000    0.000    0.000    0.000 iterator_ops.py:943(_from_components)\n",
       "       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "        2    0.000    0.000    0.000    0.000 options.py:232(_to_proto)\n",
       "       26    0.000    0.000    0.000    0.000 ops.py:1865(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 re.py:289(_compile)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:1365(_validate_parse_dates_arg)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:1185(flatten)\n",
       "        5    0.000    0.000    0.000    0.000 tensor_shape.py:885(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:553(_array_equivalent_object)\n",
       "        1    0.000    0.000    0.000    0.000 base_layer.py:2422(_clear_losses)\n",
       "        4    0.000    0.000    0.000    0.000 capture_container.py:238(merge_by_ref_with)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:11311(any)\n",
       "        4    0.000    0.000    0.000    0.000 structure.py:231(from_compatible_tensor_list)\n",
       "       19    0.000    0.000    0.000    0.000 {built-in method sys._getframe}\n",
       "       13    0.000    0.000    0.000    0.000 tensor_shape.py:103(dimension_value)\n",
       "        1    0.000    0.000    0.004    0.004 text_vectorization.py:478(finalize_state)\n",
       "        1    0.000    0.000    0.000    0.000 resource_variable_ops.py:1694(__init__)\n",
       "       17    0.000    0.000    0.000    0.000 common.py:1459(get_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 tensor_shape.py:928(__iter__)\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(concatenate)\n",
       "        5    0.000    0.000    0.000    0.000 structure.py:411(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:3743(_in_functional_construction_mode)\n",
       "        4    0.000    0.000    0.000    0.000 type_dispatch.py:49(add_target)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
       "        8    0.000    0.000    0.000    0.000 op_def_library.py:62(_SatisfiesLengthConstraint)\n",
       "        3    0.000    0.000    0.000    0.000 version_utils.py:72(should_use_v2)\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(prod)\n",
       "        2    0.000    0.000    0.000    0.000 gen_dataset_ops.py:6265(repeat_dataset)\n",
       "        1    0.000    0.000    1.395    1.395 685174634.py:7(load_and_preprocess_images)\n",
       "        1    0.000    0.000    0.000    0.000 gen_ragged_conversion_ops.py:218(ragged_tensor_to_tensor)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:654(getfile)\n",
       "        2    0.000    0.000    0.000    0.000 tf_export.py:150(get_canonical_name)\n",
       "        2    0.000    0.000    0.000    0.000 device.py:167(is_null_merge)\n",
       "        2    0.000    0.000    0.001    0.000 math_ops.py:1840(_mul_dispatch)\n",
       "        2    0.000    0.000    0.000    0.000 contextlib.py:415(enter_context)\n",
       "        1    0.000    0.000    0.000    0.000 tf_stack.py:117(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 data_adapter.py:1953(_get_tensor_types)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:2970(_get_row_partition_type_tensor_pairs)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:864(deferred_external_captures)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:3800(add_to_collection)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:767(__iter__)\n",
       "        3    0.000    0.000    0.019    0.006 polymorphic_function.py:1187(get_concrete_function)\n",
       "       24    0.000    0.000    0.000    0.000 trace_type_builder.py:98(unnest_only)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:565(_ensure_array)\n",
       "       19    0.000    0.000    0.000    0.000 options.py:460(_set_mutable)\n",
       "        4    0.000    0.000    0.000    0.000 context.py:2240(global_seed)\n",
       "        2    0.000    0.000    0.000    0.000 type_spec.py:335(_without_tensor_names)\n",
       "        3    0.000    0.000    0.000    0.000 monomorphic_function.py:1365(name)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1968(colocation_groups)\n",
       "        2    0.000    0.000    0.001    0.000 dataset_ops.py:2954(with_options)\n",
       "       32    0.000    0.000    0.000    0.000 atomic_function.py:45(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:5401(identical)\n",
       "        1    0.000    0.000    0.000    0.000 nest_util.py:1100(_tf_data_map_structure)\n",
       "       22    0.000    0.000    0.000    0.000 dataset_ops.py:270(_variant_tensor)\n",
       "        4    0.000    0.000    0.000    0.000 inspect_utils.py:76(isconstructor)\n",
       "        2    0.000    0.000    0.000    0.000 gen_dataset_ops.py:5909(prefetch_dataset)\n",
       "        2    0.000    0.000    0.000    0.000 tf_utils.py:496(is_sparse)\n",
       "        2    0.000    0.000    0.000    0.000 gen_dataset_ops.py:4574(options_dataset)\n",
       "        2    0.000    0.000    0.002    0.001 array_ops.py:1133(slice)\n",
       "        4    0.000    0.000    0.000    0.000 default_types.py:581(__init__)\n",
       "       24    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 polymorphic_function.py:134(called_with_tracing)\n",
       "        7    0.000    0.000    0.000    0.000 op_def_library.py:473(<genexpr>)\n",
       "        7    0.000    0.000    0.000    0.000 tensor_util.py:1111(is_tf_type)\n",
       "        3    0.000    0.000    0.000    0.000 record.py:81(record_operation)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:1311(_configure_dataset_and_inferred_steps)\n",
       "        5    0.000    0.000    0.000    0.000 ragged_tensor.py:1053(flat_values)\n",
       "        1    0.000    0.000    0.001    0.001 data_adapter.py:1133(_process_tensorlike)\n",
       "        8    0.000    0.000    0.000    0.000 traceable_stack.py:26(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 cast.py:1388(np_find_common_type)\n",
       "        1    0.000    0.000    0.000    0.000 type_spec.py:242(_to_tensors)\n",
       "        5    0.000    0.000    0.000    0.000 structure.py:250(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:1219(dedup_names)\n",
       "        2    0.000    0.000    0.000    0.000 policy.py:204(_parse_name)\n",
       "        5    0.000    0.000    0.000    0.000 tensor.py:399(_to_components)\n",
       "        8    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
       "        3    0.000    0.000    0.000    0.000 inspect.py:726(getmodule)\n",
       "        7    0.000    0.000    0.000    0.000 monomorphic_function.py:1053(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:117(close)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:395(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:523(_get_axis)\n",
       "        4    0.000    0.000    0.000    0.000 base_layer.py:3385(_expects_mask_arg)\n",
       "        2    0.000    0.000    0.000    0.000 gen_dataset_ops.py:188(anonymous_iterator_v3)\n",
       "        7    0.000    0.000    0.000    0.000 object_identity.py:61(__hash__)\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:307(_isna_string_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 gen_lookup_ops.py:1241(lookup_table_size_v2)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:6599(_op_to_colocate_with)\n",
       "        8    0.000    0.000    0.000    0.000 api.py:291(is_autograph_artifact)\n",
       "       10    0.000    0.000    0.000    0.000 execute.py:170(make_bool)\n",
       "        1    0.000    0.000    0.001    0.001 array_ops.py:1439(_autopacking_helper)\n",
       "        8    0.000    0.000    0.000    0.000 func_graph.py:129(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:1456(_infer_steps)\n",
       "        1    0.000    0.000    0.000    0.000 tf_stack.py:95(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 saveable_object.py:21(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 contextlib.py:458(_push_cm_exit)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:1458(_check_file_or_buffer)\n",
       "       11    0.000    0.000    0.000    0.000 monitoring.py:316(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 iterator_ops.py:936(_component_specs)\n",
       "        3    0.000    0.000    0.000    0.000 common.py:169(_expand_user)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:450(_engine_type)\n",
       "        2    0.000    0.000    0.000    0.000 converter.py:178(uses)\n",
       "        9    0.000    0.000    0.000    0.000 op_def_library.py:181(_MakeBool)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer_utils.py:822(v2_dtype_behavior_enabled)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape.py:875(__str__)\n",
       "        8    0.000    0.000    0.000    0.000 options.py:105(set_fn)\n",
       "       15    0.000    0.000    0.000    0.000 converter.py:164(as_tuple)\n",
       "        6    0.000    0.000    0.000    0.000 tensor_shape.py:1094(assert_has_rank)\n",
       "        5    0.000    0.000    0.000    0.000 tensor.py:436(_to_tensor_list)\n",
       "        1    0.000    0.000    0.000    0.000 tf_stack.py:98(update)\n",
       "        1    0.000    0.000    0.000    0.000 resource.py:213(__del__)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:2917(_get_input_masks)\n",
       "        2    0.000    0.000    0.005    0.002 data_adapter.py:591(can_handle)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:4901(reindex)\n",
       "        2    0.000    0.000    0.001    0.000 dataset_ops.py:1216(prefetch)\n",
       "        1    0.000    0.000    0.000    0.000 variables.py:1208(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 dataset_ops.py:976(range)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'add_index_reference' of 'pandas._libs.internals.BlockValuesRefs' objects}\n",
       "        1    0.000    0.000    0.000    0.000 distributed_training_utils.py:133(maybe_preemption_handler_scope)\n",
       "        1    0.000    0.000    0.001    0.001 dataset_ops.py:749(from_tensor_slices)\n",
       "        4    0.000    0.000    0.000    0.000 atomic_function.py:406(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 math_ops.py:2241(_may_reduce_to_scalar)\n",
       "        8    0.000    0.000    0.000    0.000 util.py:21(is_namedtuple)\n",
       "        2    0.000    0.000    0.000    0.000 autocast_variable.py:620(__exit__)\n",
       "        4    0.000    0.000    0.000    0.000 op_def_library.py:857(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 gen_lookup_ops.py:1109(lookup_table_insert_v2)\n",
       "        1    0.000    0.000    0.000    0.000 atomic_function.py:129(definition)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\n",
       "        4    0.000    0.000    0.000    0.000 object_identity.py:257(__iter__)\n",
       "        3    0.000    0.000    0.000    0.000 handle_data_util.py:36(get_handle_data)\n",
       "        1    0.000    0.000    0.000    0.000 dataset_ops.py:1019(zip)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'close' of 'pandas._libs.parsers.TextReader' objects}\n",
       "        1    0.000    0.000    0.001    0.001 from_tensor_slices_op.py:24(_from_tensor_slices)\n",
       "        3    0.000    0.000    0.000    0.000 op_def_library.py:175(_MakeStr)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
       "        2    0.000    0.000    0.000    0.000 autocast_variable.py:616(__enter__)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:1153(check_func_mutation)\n",
       "        2    0.000    0.000    0.000    0.000 contextlib.py:463(_push_exit_callback)\n",
       "        8    0.000    0.000    0.000    0.000 tf_logging.py:93(get_logger)\n",
       "        4    0.000    0.000    0.000    0.000 polymorphic_function.py:549(_get_key_for_call_stats)\n",
       "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:430(__enter__)\n",
       "        9    0.000    0.000    0.000    0.000 lookup_ops.py:1913(name)\n",
       "        2    0.000    0.000    0.001    0.001 array_ops.py:5141(gather_v2)\n",
       "        6    0.000    0.000    0.000    0.000 nest_util.py:370(_tf_data_yield_value)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:8126(zip_dataset)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:1195(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.TF_OperationDevice}\n",
       "        1    0.000    0.000    0.000    0.000 threading.py:1071(is_alive)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:1989(_is_distributed_dataset)\n",
       "        4    0.000    0.000    0.000    0.000 nest.py:294(assert_same_structure)\n",
       "        1    0.000    0.000    0.011    0.011 dataset_ops.py:2286(flat_map)\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:1528(convert_to_tensor_or_composite)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:1291(is_keras_tensor)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:260(_convert_actual)\n",
       "        1    0.000    0.000    0.000    0.000 gen_resource_variable_ops.py:122(assign_variable_op)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:1409(close)\n",
       "       13    0.000    0.000    0.000    0.000 tensor_shape.py:289(assert_is_compatible_with)\n",
       "        3    0.000    0.000    0.000    0.000 range_op.py:65(_build_tensor)\n",
       "        4    0.000    0.000    0.000    0.000 monitoring.py:483(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 base_preprocessing_layer.py:299(_disallow_inside_tf_function)\n",
       "        1    0.000    0.000    0.000    0.000 dataset_ops.py:4529(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 func_graph.py:402(control_dependencies)\n",
       "        2    0.000    0.000    0.001    0.000 array_ops.py:642(shape)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:125(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 lookup_ops.py:206(_initialize)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4451(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:455(array_equivalent)\n",
       "        9    0.000    0.000    0.000    0.000 inference.py:294(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 gen_dataset_ops.py:5768(parallel_map_dataset_v2)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:727(sync_executors)\n",
       "        1    0.000    0.000    0.000    0.000 type_spec.py:105(is_subtype_of)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:2370(_get_cell_name)\n",
       "        3    0.000    0.000    0.000    0.000 tf_inspect.py:364(getmodule)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:1491(_validate_data_handler)\n",
       "        2    0.000    0.000    0.001    0.000 math_ops.py:481(multiply)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:509(_get_axis_number)\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:1730(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 tf_decorator.py:343(decorated_target)\n",
       "        1    0.000    0.000    0.001    0.001 data_adapter.py:300(permutation)\n",
       "        2    0.000    0.000    0.000    0.000 repeat_op.py:24(_repeat)\n",
       "        2    0.000    0.000    0.000    0.000 tensor_shape.py:1273(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 inspect.py:72(isclass)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:61(__iter__)\n",
       "        1    0.000    0.000    0.001    0.001 gen_dataset_ops.py:2342(flat_map_dataset)\n",
       "        1    0.000    0.000    0.000    0.000 array_ops.py:4589(where_v2)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4406(__init__)\n",
       "       13    0.000    0.000    0.000    0.000 numeric.py:2403(_array_equal_dispatcher)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
       "        8    0.000    0.000    0.000    0.000 trace_type_builder.py:114(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 concat.py:73(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:855(_do_date_conversions)\n",
       "        4    0.000    0.000    0.000    0.000 inspect.py:63(ismodule)\n",
       "        8    0.000    0.000    0.000    0.000 func_graph.py:96(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _asarray.py:112(<setcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 options.py:282(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4530(control_dependencies)\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:949(clean_reindex_fill_method)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:7878(isna)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:2714(_convert_to_ragged_tensor_values)\n",
       "        2    0.000    0.000    0.000    0.000 parse.py:121(_coerce_args)\n",
       "        3    0.000    0.000    0.000    0.000 structured_function.py:240(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 dataset_ops.py:701(_type_spec)\n",
       "        3    0.000    0.000    0.000    0.000 index_lookup.py:919(_token_start_index)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:273(is_fsspec_url)\n",
       "        1    0.000    0.000    0.001    0.001 gen_dataset_ops.py:3450(map_dataset)\n",
       "       17    0.000    0.000    0.000    0.000 structured_function.py:292(output_structure)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:736(get_size)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:229(stringify_path)\n",
       "        5    0.000    0.000    0.000    0.000 type_spec.py:484(_deserialize)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:1077(needs_i8_conversion)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 re.py:331(filter)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:5499(executing_eagerly_outside_functions)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
       "        1    0.000    0.000    0.001    0.001 dataset_ops.py:1085(concatenate)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:453(_validate_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 op_def_library.py:853(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 tf_stack.py:59(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 base_layer.py:1210(dynamic)\n",
       "        1    0.000    0.000    0.000    0.000 array_ops.py:1488(_get_dtype_from_nested_lists)\n",
       "        1    0.000    0.000    0.000    0.000 _methods.py:55(_any)\n",
       "        1    0.000    0.000    0.000    0.000 transpiler.py:426(_cached_factory)\n",
       "        9    0.000    0.000    0.000    0.000 dataset_ops.py:4442(_inputs)\n",
       "        2    0.000    0.000    0.001    0.000 from_tensors_op.py:22(_from_tensors)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer_utils.py:591(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4476(_pop_control_dependencies_controller)\n",
       "        2    0.000    0.000    0.000    0.000 dtypes.py:224(most_specific_common_supertype)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1860(from_blocks)\n",
       "        7    0.000    0.000    0.000    0.000 func_graph.py:1097(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:6036(range_dataset)\n",
       "        1    0.000    0.000    0.000    0.000 array_ops.py:1899(unique_with_counts)\n",
       "        3    0.000    0.000    0.000    0.000 base_layer.py:1213(<genexpr>)\n",
       "       22    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "        2    0.000    0.000    0.000    0.000 autocast_variable.py:611(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 variables.py:18(ld)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
       "        5    0.000    0.000    0.000    0.000 ag_ctx.py:64(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:148(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:354(_make_index)\n",
       "        1    0.000    0.000    0.000    0.000 gen_lookup_ops.py:1028(lookup_table_import_v2)\n",
       "        7    0.000    0.000    0.000    0.000 object_identity.py:33(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 concat.py:55(is_nonempty)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_TapeSetRecordOperation}\n",
       "        9    0.000    0.000    0.000    0.000 common.py:147(classes_and_not_datetimelike)\n",
       "        6    0.000    0.000    0.000    0.000 common.py:1389(is_ea_or_datetimelike_dtype)\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:6214(<genexpr>)\n",
       "       10    0.000    0.000    0.000    0.000 options.py:403(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method tensorflow.python.client._pywrap_tf_session.GetHandleShapeAndType}\n",
       "        3    0.000    0.000    0.000    0.000 base.py:583(_dtype_to_subclass)\n",
       "       24    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:6080(add_to_collection)\n",
       "        5    0.000    0.000    0.000    0.000 monitoring.py:157(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:3380(_expects_training_arg)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:5540(isna)\n",
       "        1    0.000    0.000    0.000    0.000 range_op.py:24(_range)\n",
       "        4    0.000    0.000    0.000    0.000 func_graph.py:575(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 map_op.py:125(element_spec)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:188(validate_header_arg)\n",
       "        1    0.000    0.000    0.000    0.000 blocks.py:2465(extend_blocks)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:1938(_check_data_cardinality)\n",
       "        1    0.000    0.000    0.000    0.000 concatenate_op.py:34(common_supertype)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:4963(_get_engine_target)\n",
       "        1    0.000    0.000    0.001    0.001 gen_array_ops.py:6536(pack)\n",
       "        6    0.000    0.000    0.000    0.000 data_adapter.py:238(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 func_graph.py:879(function_captures)\n",
       "        1    0.000    0.000    0.000    0.000 transpiler.py:266(transform)\n",
       "        6    0.000    0.000    0.000    0.000 ragged_tensor.py:3107(_is_supported_ragged_values_type)\n",
       "        1    0.000    0.000    0.001    0.001 gen_lookup_ops.py:1777(mutable_hash_table_v2)\n",
       "        2    0.000    0.000    0.000    0.000 options.py:496(_to_proto)\n",
       "        1    0.000    0.000    0.000    0.000 zip_op.py:23(_zip)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:1215(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:2242(_type_spec)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1805(is_consolidated)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:427(_unbatch)\n",
       "        3    0.000    0.000    0.000    0.000 execute.py:271(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 gen_resource_variable_ops.py:1203(var_handle_op)\n",
       "        4    0.000    0.000    0.000    0.000 index_lookup.py:914(_oov_start_index)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4149(_colocate_with_for_gradient)\n",
       "        1    0.000    0.000    0.000    0.000 base_preprocessing_layer.py:264(_reset_state_wrapper)\n",
       "       10    0.000    0.000    0.000    0.000 row_partition.py:896(static_uniform_row_length)\n",
       "        4    0.000    0.000    0.000    0.000 tensor.py:330(_to_tensors)\n",
       "        1    0.000    0.000    0.000    0.000 tf_utils.py:193(get_shapes)\n",
       "        3    0.000    0.000    0.000    0.000 tensor_shape.py:1348(assert_is_compatible_with)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:2175(_grouping_func)\n",
       "        1    0.000    0.000    0.000    0.000 function_wrappers.py:79(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1046(__bool__)\n",
       "        1    0.000    0.000    0.000    0.000 tf_stack.py:139(get_filtered_filenames)\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:266(_isna_array)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer_utils.py:461(call_context)\n",
       "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(lexsort)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
       "        1    0.000    0.000    0.000    0.000 nest.py:1284(list_to_tuple)\n",
       "        2    0.000    0.000    0.000    0.000 ragged_tensor.py:993(_nested_row_partitions)\n",
       "        2    0.000    0.000    0.000    0.000 inference.py:99(is_file_like)\n",
       "        1    0.000    0.000    0.000    0.000 __autograph_generated_fileqqpl0fq9.py:5(inner_factory)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer_utils.py:574(__enter__)\n",
       "        4    0.000    0.000    0.000    0.000 layer_utils.py:72(validate_string_arg)\n",
       "       12    0.000    0.000    0.000    0.000 object_identity.py:36(unwrapped)\n",
       "        2    0.000    0.000    0.000    0.000 type_spec.py:348(rename)\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:47(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 variable_scope.py:1197(use_resource)\n",
       "        4    0.000    0.000    0.000    0.000 construction.py:636(_sanitize_non_ordered)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:735(__hash__)\n",
       "        4    0.000    0.000    0.000    0.000 concat.py:76(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:2915(_resource_creator_stack)\n",
       "        5    0.000    0.000    0.000    0.000 trace_type_builder.py:87(update_naming_scope)\n",
       "        1    0.000    0.000    0.001    0.001 concatenate_op.py:22(_concatenate)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:265(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:4876(switch_to_thread_local)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:46(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:271(_extract_multi_indexer_columns)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:560(get_shape)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:809(_reset_identity)\n",
       "        4    0.000    0.000    0.000    0.000 context.py:1442(function_scope_id)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:66(copy)\n",
       "        1    0.000    0.000    0.000    0.000 base_layer.py:2397(_add_trackable)\n",
       "        1    0.000    0.000    0.000    0.000 data_structures.py:62(_should_wrap_tuple)\n",
       "        7    0.000    0.000    0.000    0.000 monomorphic_function.py:303(forward)\n",
       "        3    0.000    0.000    0.000    0.000 structured_function.py:41(_should_pack)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 resource_variable_ops.py:198(eager_safe_variable_handle)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:1806(_clean_na_values)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4463(add_op)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:899(dtype)\n",
       "        4    0.000    0.000    0.000    0.000 monomorphic_function.py:1380(structured_input_signature)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:2257(is_ragged)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'append' of 'google._upb._message.RepeatedCompositeContainer' objects}\n",
       "        1    0.000    0.000    0.000    0.000 c_parser_wrapper.py:194(close)\n",
       "        1    0.000    0.000    0.000    0.000 execute.py:267(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer_utils.py:569(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:104(__init__)\n",
       "        1    0.000    0.000    0.010    0.010 flat_map_op.py:22(_flat_map)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:296(maybe_iterable_to_list)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_all_arraylike}\n",
       "        2    0.000    0.000    0.000    0.000 layer_utils.py:957(split_out_first_arg)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'tobytes' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 context.py:2401(eager_mode)\n",
       "        9    0.000    0.000    0.000    0.000 tensor_shape.py:1396(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:687(can_handle)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer_utils.py:539(training)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 contextlib.py:385(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 layer_utils.py:844(expects_mask_arg)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:481(build)\n",
       "        3    0.000    0.000    0.000    0.000 base_layer.py:1254(input_spec)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:1211(_process_date_conversion)\n",
       "        3    0.000    0.000    0.000    0.000 op_def_library.py:504(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 c_parser_wrapper.py:383(<setcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 c_parser_wrapper.py:405(ensure_dtype_objs)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:714(_try_cast)\n",
       "        1    0.000    0.000    0.001    0.001 data_adapter.py:391(grab_batch)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_util.py:607(<listcomp>)\n",
       "       13    0.000    0.000    0.000    0.000 type_spec.py:544(__tf_tracing_type__)\n",
       "        6    0.000    0.000    0.000    0.000 type_spec.py:186(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 capture_container.py:322(by_val_internal)\n",
       "        2    0.000    0.000    0.000    0.000 function_type.py:177(output)\n",
       "        1    0.000    0.000    0.000    0.000 dataset_ops.py:4627(_to_tensor_list)\n",
       "        2    0.000    0.000    0.000    0.000 c_parser_wrapper.py:382(<setcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 atomic_function.py:409(<listcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 common.py:705(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 type_spec.py:158(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 execute.py:328(_is_keras_symbolic_tensor)\n",
       "        2    0.000    0.000    0.000    0.000 device.py:61(merge_device)\n",
       "        3    0.000    0.000    0.000    0.000 api.py:652(convert)\n",
       "        8    0.000    0.000    0.000    0.000 capture_container.py:314(by_ref_external)\n",
       "        3    0.000    0.000    0.000    0.000 traceable_stack.py:101(pop_obj)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
       "        3    0.000    0.000    0.000    0.000 tensor_shape.py:1126(with_rank_at_least)\n",
       "        3    0.000    0.000    0.000    0.000 resource.py:130(_resource_type)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:11286(values)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1813(_consolidate_check)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:408(_deferred_dependencies)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:3042(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:4982(_control_dependencies_stack)\n",
       "        4    0.000    0.000    0.000    0.000 atomic_function.py:407(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:1362(sync)\n",
       "        1    0.000    0.000    0.000    0.000 array_ops.py:774(size)\n",
       "        4    0.000    0.000    0.000    0.000 monomorphic_function.py:1885(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 py_builtins.py:60(overload_of)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4473(_push_control_dependencies_controller)\n",
       "        3    0.000    0.000    0.000    0.000 data_adapter.py:1969(_is_pandas_series)\n",
       "        1    0.000    0.000    0.000    0.000 polymorphic_function.py:1238(function)\n",
       "        4    0.000    0.000    0.000    0.000 device_spec.py:450(__hash__)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
       "       10    0.000    0.000    0.000    0.000 monomorphic_function.py:1370(graph)\n",
       "        1    0.000    0.000    0.000    0.000 resource_variable_ops.py:87(_set_handle_shapes_and_types)\n",
       "        2    0.000    0.000    0.000    0.000 ragged_tensor.py:3044(_get_optional_partition_dtype)\n",
       "        3    0.000    0.000    0.000    0.000 structured_function.py:62(_should_unpack)\n",
       "        1    0.000    0.000    0.001    0.001 data_adapter.py:393(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:186(all_none)\n",
       "        1    0.000    0.000    0.000    0.000 base_layer.py:1186(dtype)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1823(_consolidate_inplace)\n",
       "        4    0.000    0.000    0.000    0.000 inspect.py:285(isbuiltin)\n",
       "        3    0.000    0.000    0.000    0.000 eager_function_run.py:24(functions_run_eagerly)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:3111(_assert_is_supported_ragged_values_type)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:479(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 traceable_stack.py:105(peek_top_obj)\n",
       "        1    0.000    0.000    0.000    0.000 typing.py:771(__subclasscheck__)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
       "        6    0.000    0.000    0.000    0.000 trace_type_builder.py:106(composite_device_name)\n",
       "        3    0.000    0.000    0.000    0.000 row_partition.py:1024(_has_precomputed_value_rowids)\n",
       "        8    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
       "        6    0.000    0.000    0.000    0.000 policy.py:274(compute_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 tracing_compiler.py:156(function_spec)\n",
       "        6    0.000    0.000    0.000    0.000 trace_type_builder.py:102(with_none_control_dependencies)\n",
       "        1    0.000    0.000    0.000    0.000 zip_op.py:48(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 ragged_functional_ops.py:109(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 type_spec.py:917(type_spec_from_value)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
       "        4    0.000    0.000    0.000    0.000 inspect.py:702(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:112(ensure_python_int)\n",
       "        1    0.000    0.000    0.000    0.000 type_spec.py:123(check_attribute)\n",
       "        6    0.000    0.000    0.000    0.000 structured_function.py:314(function)\n",
       "        1    0.000    0.000    0.000    0.000 threading.py:1017(_wait_for_tstate_lock)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:7646(<listcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 capture_container.py:310(by_ref_internal)\n",
       "        1    0.000    0.000    0.001    0.001 iterator_ops.py:812(__next__)\n",
       "        4    0.000    0.000    0.000    0.000 trace_type_builder.py:43(get_placeholder_mapping)\n",
       "        2    0.000    0.000    0.000    0.000 concat.py:66(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 trace_type_builder.py:117(allow_specs)\n",
       "        6    0.000    0.000    0.000    0.000 trace_type_builder.py:94(context_graph)\n",
       "        1    0.000    0.000    0.000    0.000 typing.py:768(__instancecheck__)\n",
       "        1    0.000    0.000    0.000    0.000 nest.py:92(map_structure)\n",
       "        4    0.000    0.000    0.000    0.000 tensor_shape.py:1258(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 nest_util.py:1123(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:2983(seed)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:1939(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 monomorphic_function.py:1888(release)\n",
       "        4    0.000    0.000    0.000    0.000 dtypes.py:227(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:994(can_handle)\n",
       "        2    0.000    0.000    0.000    0.000 generic_utils.py:523(is_default)\n",
       "        3    0.000    0.000    0.000    0.000 inspect.py:699(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:1103(_maybe_memory_map)\n",
       "        8    0.000    0.000    0.000    0.000 ragged_tensor.py:969(values)\n",
       "        1    0.000    0.000    0.000    0.000 tf_inspect.py:419(ismethod)\n",
       "        2    0.000    0.000    0.000    0.000 tensor.py:445(_without_tensor_names)\n",
       "        8    0.000    0.000    0.000    0.000 {method 'get' of 'ContextVar' objects}\n",
       "        4    0.000    0.000    0.000    0.000 tf_export.py:163(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:778(is_)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "        9    0.000    0.000    0.000    0.000 inspect.py:2861(return_annotation)\n",
       "        2    0.000    0.000    0.000    0.000 c_parser_wrapper.py:380(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:494(find)\n",
       "        3    0.000    0.000    0.000    0.000 data_adapter.py:233(_is_tensor)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:1004(row_splits)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\n",
       "        3    0.000    0.000    0.000    0.000 concatenate_op.py:61(element_spec)\n",
       "        3    0.000    0.000    0.000    0.000 op_def_library.py:616(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 contextlib.py:697(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 device_spec.py:455(to_string)\n",
       "        1    0.000    0.000    0.000    0.000 zip_op.py:52(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 array_ops.py:740(size_v2)\n",
       "        1    0.000    0.000    0.000    0.000 converter.py:182(call_options)\n",
       "        1    0.000    0.000    0.000    0.000 saveable_object.py:59(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 tensor.py:154(_serialize)\n",
       "        5    0.000    0.000    0.000    0.000 base_layer.py:1196(name)\n",
       "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:426(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 ragged_functional_ops.py:175(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 structure.py:364(to_batched_tensor_list)\n",
       "        1    0.000    0.000    0.000    0.000 types.py:171(__get__)\n",
       "        2    0.000    0.000    0.000    0.000 serialization_lib.py:55(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:557(can_handle)\n",
       "        2    0.000    0.000    0.000    0.000 base_layer.py:3018(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:931(dtype)\n",
       "        2    0.000    0.000    0.000    0.000 dataset_ops.py:478(_apply_debug_options)\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:106(isna)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:3022(_set_control_flow_context)\n",
       "        2    0.000    0.000    0.000    0.000 np_array_ops.py:1803(_as_spec_tuple)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:1738(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:947(ragged_rank)\n",
       "        4    0.000    0.000    0.000    0.000 tensor_shape.py:1274(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:7564(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 blocks.py:2109(get_values)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:220(_maybe_get_mask)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'group' of 're.Match' objects}\n",
       "        5    0.000    0.000    0.000    0.000 range_op.py:68(element_spec)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:1094(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 type_spec.py:238(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:499(get_compression_method)\n",
       "        2    0.000    0.000    0.000    0.000 range.py:892(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:197(mgr_to_mgr)\n",
       "        3    0.000    0.000    0.000    0.000 polymorphic_function.py:1012(_initialize_uninitialized_variables)\n",
       "        2    0.000    0.000    0.000    0.000 tf_decorator.py:347(decorated_target)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:476(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:3047(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 dataset_ops.py:4630(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:413(get_size)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:753(value)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:353(_na_ok_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 concat.py:80(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 capture_container.py:326(by_val_external)\n",
       "        2    0.000    0.000    0.000    0.000 contextlib.py:375(_create_exit_wrapper)\n",
       "        5    0.000    0.000    0.000    0.000 base.py:4937(_values)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:733(get_dataset)\n",
       "        1    0.000    0.000    0.000    0.000 resource.py:134(_destruction_context)\n",
       "        1    0.000    0.000    0.000    0.000 composite_tensor.py:128(convert_variables_to_tensors)\n",
       "        2    0.000    0.000    0.000    0.000 sparse_tensor.py:216(dense_shape)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:876(_check_data_length)\n",
       "        4    0.000    0.000    0.000    0.000 monomorphic_function.py:1105(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 structure.py:386(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:783(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:435(__exit__)\n",
       "        3    0.000    0.000    0.000    0.000 input_spec.py:169(assert_input_compatibility)\n",
       "        1    0.000    0.000    0.000    0.000 function_wrappers.py:70(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 c_parser_wrapper.py:332(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _validators.py:224(validate_bool_kwarg)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_functional_ops.py:182(_merge_partition_lists)\n",
       "        1    0.000    0.000    0.000    0.000 multiarray.py:420(lexsort)\n",
       "        4    0.000    0.000    0.000    0.000 row_partition.py:753(value_rowids)\n",
       "        4    0.000    0.000    0.000    0.000 monomorphic_function.py:1116(<dictcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:2842(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:5414(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 generic_utils.py:508(validate_kwargs)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
       "        4    0.000    0.000    0.000    0.000 dataset_ops.py:4431(_inputs)\n",
       "        4    0.000    0.000    0.000    0.000 type_spec.py:176(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 concat.py:72(<setcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 ragged_tensor.py:1837(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 training_utils.py:59(handle_partial_sample_weights)\n",
       "        3    0.000    0.000    0.000    0.000 flat_map_op.py:52(element_spec)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:1240(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'pop' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 zip_op.py:57(_inputs)\n",
       "        4    0.000    0.000    0.000    0.000 from_tensors_op.py:41(element_spec)\n",
       "        1    0.000    0.000    0.000    0.000 tf_utils.py:196(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:2978(seed)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:498(is_string_or_object_np_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_util.py:559(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 nest.py:1299(sequence_fn)\n",
       "        4    0.000    0.000    0.000    0.000 trace_type_builder.py:173(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 from_tensor_slices_op.py:39(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 layer_utils.py:835(expects_training_arg)\n",
       "        3    0.000    0.000    0.000    0.000 ops.py:117(tensor_id)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
       "        1    0.000    0.000    0.000    0.000 gen_dataset_ops.py:1099(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:342(_maybe_make_multi_index_columns)\n",
       "        1    0.000    0.000    0.000    0.000 converter.py:239(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 type_spec.py:245(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 nest_util.py:1120(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_functional_ops.py:168(recurse)\n",
       "        2    0.000    0.000    0.000    0.000 sparse_tensor.py:172(values)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:845(can_handle)\n",
       "        2    0.000    0.000    0.000    0.000 tensor_util.py:289(_FlattenToStrings)\n",
       "        3    0.000    0.000    0.000    0.000 zip_op.py:60(element_spec)\n",
       "        1    0.000    0.000    0.000    0.000 tf_inspect.py:312(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup_error}\n",
       "        1    0.000    0.000    0.000    0.000 c_parser_wrapper.py:212(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:1860(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:439(_to_batched_tensor_list)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:6731(enable_numpy_style_type_promotion)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:530(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 cache.py:70(_get_key)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:260(iscode)\n",
       "        1    0.000    0.000    0.000    0.000 base_layer.py:2220(compute_dtype)\n",
       "        5    0.000    0.000    0.000    0.000 trace_type_builder.py:90(naming_scope)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:246(isframe)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:228(is_single_block)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:2109(_validate_skipfooter)\n",
       "        1    0.000    0.000    0.000    0.000 row_partition.py:733(dtype)\n",
       "        1    0.000    0.000    0.000    0.000 _validators.py:445(check_dtype_backend)\n",
       "        1    0.000    0.000    0.000    0.000 np_dtypes.py:79(set_prefer_float32)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape.py:1430(__eq__)\n",
       "        1    0.000    0.000    0.000    0.000 range.py:181(_validate_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 dataset_ops.py:5143(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
       "        3    0.000    0.000    0.000    0.000 base_parser.py:1387(is_index_col)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:1176(broadcast_sample_weight_modes)\n",
       "        1    0.000    0.000    0.000    0.000 default_types.py:219(_flatten)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:236(istraceback)\n",
       "        1    0.000    0.000    0.000    0.000 threading.py:513(is_set)\n",
       "        2    0.000    0.000    0.000    0.000 data_adapter.py:466(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:966(_validate_usecols_arg)\n",
       "        2    0.000    0.000    0.000    0.000 concat.py:71(<setcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:242(_has_complex_date_col)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:60(__call__)\n",
       "        2    0.000    0.000    0.000    0.000 concat.py:79(<setcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:2379(anonymous_name)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:121(clean_fill_method)\n",
       "        2    0.000    0.000    0.000    0.000 multiarray.py:152(concatenate)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:6743(enable_numpy_style_slicing)\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:934(_ensure_vocab_size_unchanged)\n",
       "        2    0.000    0.000    0.000    0.000 regularizers.py:448(get)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:1831(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:57(ref)\n",
       "        2    0.000    0.000    0.000    0.000 policy.py:303(name)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'collections.deque' objects}\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:454(_is_array_like)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4518(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:331(getstate)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:748(should_recreate_iterator)\n",
       "        4    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
       "        2    0.000    0.000    0.000    0.000 lookup_ops.py:368(name)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:145(key_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:4459(control_inputs)\n",
       "        1    0.000    0.000    0.000    0.000 c_parser_wrapper.py:328(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:574(_constructor)\n",
       "        1    0.000    0.000    0.000    0.000 row_partition.py:782(nrows)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2950(_prod_dispatcher)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:1876(pack_x_y_sample_weight)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:190(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 c_parser_wrapper.py:213(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_functional_ops.py:177(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:3027(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 op_def_library.py:77(_SatisfiesIntMinimumConstraint)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 lookup_ops.py:489(key_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'isalpha' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:410(get_dataset)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:233(items)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:326(ndim)\n",
       "        1    0.000    0.000    0.000    0.000 data_adapter.py:215(on_epoch_end)\n",
       "        2    0.000    0.000    0.000    0.000 transpiler.py:198(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 sparse_tensor.py:162(indices)\n",
       "        2    0.000    0.000    0.000    0.000 index_lookup.py:62(value_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 lookup_ops.py:494(value_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:2011(_extract_dialect)\n",
       "        1    0.000    0.000    0.000    0.000 policy.py:257(variable_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 tf_stack.py:87(get_effective_source_map)\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:922(_ensure_known_vocab_size)\n",
       "        2    0.000    0.000    0.000    0.000 index_lookup.py:57(key_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:53(name)\n",
       "        1    0.000    0.000    0.000    0.000 flat_map_op.py:56(_transformation_name)\n",
       "        1    0.000    0.000    0.000    0.000 concatenate_op.py:58(_inputs)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1582(name)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:222(<setcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 row_partition.py:738(row_splits)\n",
       "        2    0.000    0.000    0.000    0.000 contextlib.py:479(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 tf_stack.py:110(get_filtered_filenames)\n",
       "        1    0.000    0.000    0.000    0.000 lookup_ops.py:150(value_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:516(_validate_names)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:198(_get_fill_value)\n",
       "        1    0.000    0.000    0.000    0.000 map_op.py:129(_transformation_name)\n",
       "        1    0.000    0.000    0.000    0.000 composite_tensor.py:88(_convert_variables_to_tensors)\n",
       "        1    0.000    0.000    0.000    0.000 deprecation.py:515(_same_value)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:982(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 resource.py:163(_destroy_resource)\n",
       "        2    0.000    0.000    0.000    0.000 tensor_shape.py:934(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape.py:921(__bool__)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
       "        2    0.000    0.000    0.000    0.000 iterator_ops.py:929(value_type)\n",
       "        1    0.000    0.000    0.000    0.000 base_layer.py:3235(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 contextlib.py:700(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 base_parser.py:234(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1838(ndim)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:2984(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ragged_tensor.py:1832(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:107(_copy_immutable)\n",
       "        2    0.000    0.000    0.000    0.000 parse.py:110(_noop)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:333(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 map_op.py:181(_transformation_name)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:219(get_caching_key)\n",
       "        1    0.000    0.000    0.000    0.000 contextlib.py:703(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 from_tensor_slices_op.py:56(element_spec)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 readers.py:1735(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 index_lookup.py:67(initialize)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "%%prun\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"{root_dir}/im2latex_train.csv\", nrows=1000)\n",
    "\n",
    "train_image_paths = []\n",
    "train_latex_texts = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    train_image_paths += [f\"{root_dir}//formula_images_processed/formula_images_processed/{row.image}\"]\n",
    "    train_latex_texts += [\"<START> \" + row.formula + \" <END>\"]\n",
    "\n",
    "# Enable Numpy behaviour of TF\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "\n",
    "# vocab_size, max_seq_length = fit_tokenizer(train_latex_texts)\n",
    "\n",
    "tokenizer = tf.keras.layers.TextVectorization(max_tokens=max_seq_length, standardize = None)\n",
    "train_images = load_and_preprocess_images(train_image_paths)\n",
    "# train_sequences = prepare_sequences(train_latex_texts, max_seq_length)\n",
    "# train_sequences = np.expand_dims(train_sequences, -1)\n",
    "tokenizer.adapt(train_latex_texts)\n",
    "latex_labels = tokenizer(train_latex_texts)\n",
    "train_sequences = np.asarray(latex_labels)\n",
    "print(\"train_images:\", train_images.shape)\n",
    "print(\"train_sequences:\", train_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "hTF4s-ENIs6Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 149) (1000, 224, 224, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "[13, 1, 65, 4, 3, 51, 3, 81, 97, 29, 74, 2, 2, 1, 88, 4, 3, 21, 1, 18, 2, 1, 3, 99, 2, 4, 3, 21, 2, 3, 16, 3, 7, 11, 20, 8, 5, 3, 21, 2, 2, 3, 6, 5, 3, 6, 21, 11, 10, 2, 2, 2, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TextVectorization' object has no attribute 'sequences_to_texts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(train_sequences))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_sequences[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msequence_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[50], line 18\u001b[0m, in \u001b[0;36msequence_to_text\u001b[0;34m(sequence)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msequence_to_text\u001b[39m(sequence):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert token sequence back to LaTeX text.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequences_to_texts\u001b[49m([sequence])[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextVectorization' object has no attribute 'sequences_to_texts'"
     ]
    }
   ],
   "source": [
    "print(train_sequences.shape, train_images.shape)\n",
    "print(type(train_sequences))\n",
    "print(train_sequences[0].reshape(1,-1).tolist()[0])\n",
    "print(sequence_to_text(train_sequences[0].reshape(1,-1).tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "az_S8OFzIvc1"
   },
   "outputs": [],
   "source": [
    "print(train_image_paths[0])\n",
    "!ls -lart \"{train_image_paths[0]}\"\n",
    "print(train_latex_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR4DR8dtIkgX"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "dAEanssRGlpP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_input (InputLayer)    [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['image_input[0][0]']         \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, 112, 112, 64)         256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, 112, 112, 64)         0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, 56, 56, 256)          0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, 56, 56, 256)          0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, 56, 56, 256)          0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, 56, 56, 256)          0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, 28, 28, 512)          0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, 28, 28, 512)          0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, 28, 28, 512)          0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, 28, 28, 512)          0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, 28, 28, 512)          0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 256)                  524544    ['global_average_pooling2d_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)  [(None, 148)]                0         []                            \n",
      "                                                                                                  \n",
      " repeat_vector_8 (RepeatVec  (None, 148, 256)             0         ['dense_15[0][0]']            \n",
      " tor)                                                                                             \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, 148, 256)             38144     ['decoder_input[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 148, 512)             0         ['repeat_vector_8[0][0]',     \n",
      " )                                                                   'embedding_7[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, 148, 265)             824680    ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDi  (None, 148, 149)             39634     ['lstm_7[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25014714 (95.42 MB)\n",
      "Trainable params: 1427002 (5.44 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_seq_len_1 = max_seq_length-1\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "vocab_size = tokenizer.vocabulary_size()\n",
    "\n",
    "# CNN Encoder\n",
    "image_input = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], IMG_SIZE[2]), name=\"image_input\")\n",
    "if RESNET_MODEL is False:\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(image_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "else:\n",
    "    #rgb_image = tf.keras.layers.Lambda(lambda x: tf.image.grayscale_to_rgb(x), output_shape=(None, ))(image_input)\n",
    "    resnet = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=image_input)\n",
    "    # Freeze ResNet layers\n",
    "    for layer in resnet.layers:\n",
    "        layer.trainable = False\n",
    "    # Pooling to reduce dimensions\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(resnet.output)\n",
    "x = Dense(EMBEDDING_DIM, activation='relu')(x)\n",
    "# Repeat encoder output for each time step\n",
    "encoder_output = RepeatVector(max_seq_len_1)(x)\n",
    "\n",
    "# LSTM Decoder with Attention\n",
    "decoder_input = Input(shape=(max_seq_len_1,), name=\"decoder_input\")  # Sequence input for teacher forcing\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_seq_len_1)\n",
    "embedded_seq = embedding_layer(decoder_input)\n",
    "\n",
    "decoder_lstm_input = tf.keras.layers.Concatenate(axis=-1)([encoder_output, embedded_seq])\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True)(decoder_lstm_input)\n",
    "output_layer = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(decoder_lstm)\n",
    "\n",
    "# Build Model\n",
    "model = Model(inputs=[image_input, decoder_input], outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Z_u6gxZzWVRk"
   },
   "outputs": [],
   "source": [
    "# #dot_img_file =\n",
    "# import keras\n",
    "# keras.utils.plot_model(model,\n",
    "#                        show_shapes=True,\n",
    "#                        show_dtype=True,\n",
    "#                        show_layer_names=True,\n",
    "#                        expand_nested=True,\n",
    "#                        show_layer_activations=True,\n",
    "#                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ePe5hVCKG0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 07:46:33.832222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8700\n",
      "2024-12-04 07:46:34.235469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-12-04 07:46:35.752281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f674657d120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-04 07:46:35.752305: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
      "2024-12-04 07:46:35.756183: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-04 07:46:35.853345: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 658ms/step - loss: 3.0573 - accuracy: 0.5040 - val_loss: 2.2276 - val_accuracy: 0.6139\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 2s 297ms/step - loss: 2.2138 - accuracy: 0.6023 - val_loss: 2.0504 - val_accuracy: 0.6139\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 2s 278ms/step - loss: 2.0823 - accuracy: 0.6023 - val_loss: 1.9655 - val_accuracy: 0.6139\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 1.9519 - accuracy: 0.6023 - val_loss: 1.7738 - val_accuracy: 0.6139\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 1.7217 - accuracy: 0.6091 - val_loss: 1.5565 - val_accuracy: 0.6685\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 2s 257ms/step - loss: 1.5761 - accuracy: 0.6758 - val_loss: 1.4964 - val_accuracy: 0.7086\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 1.5313 - accuracy: 0.6770 - val_loss: 1.4679 - val_accuracy: 0.7221\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 1.5066 - accuracy: 0.6951 - val_loss: 1.4492 - val_accuracy: 0.7239\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 1.4887 - accuracy: 0.7106 - val_loss: 1.4345 - val_accuracy: 0.7271\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 1.4723 - accuracy: 0.7174 - val_loss: 1.4171 - val_accuracy: 0.7294\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 1.4522 - accuracy: 0.7195 - val_loss: 1.3930 - val_accuracy: 0.7298\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 1.4250 - accuracy: 0.7202 - val_loss: 1.3626 - val_accuracy: 0.7302\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 1.3911 - accuracy: 0.7206 - val_loss: 1.3258 - val_accuracy: 0.7305\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 1.3528 - accuracy: 0.7213 - val_loss: 1.2880 - val_accuracy: 0.7321\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 1.3146 - accuracy: 0.7235 - val_loss: 1.2519 - val_accuracy: 0.7366\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 2s 258ms/step - loss: 1.2798 - accuracy: 0.7313 - val_loss: 1.2225 - val_accuracy: 0.7440\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 1.2531 - accuracy: 0.7389 - val_loss: 1.2046 - val_accuracy: 0.7484\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 2s 239ms/step - loss: 1.2336 - accuracy: 0.7430 - val_loss: 1.1833 - val_accuracy: 0.7536\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 1.2157 - accuracy: 0.7453 - val_loss: 1.1682 - val_accuracy: 0.7539\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 1.2015 - accuracy: 0.7462 - val_loss: 1.1540 - val_accuracy: 0.7555\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jayaprakash//latex_model_resnet_lstm.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit([train_images, train_sequences[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],\n\u001b[1;32m      2\u001b[0m           train_sequences[:, \u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m      3\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      4\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      5\u001b[0m           validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBASE_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mOUTPUT_MODEL_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/lib/python3.8/zipfile.py:1253\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jayaprakash//latex_model_resnet_lstm.keras'"
     ]
    }
   ],
   "source": [
    "model.fit([train_images, train_sequences[:, :-1]],\n",
    "          train_sequences[:, 1:],\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save(f'{BASE_DIR}/{OUTPUT_MODEL_NAME}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RZLiNTARQNDE"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at /Users/jayaprakash//latex_model_resnet_lstm.keras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBASE_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mOUTPUT_MODEL_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at /Users/jayaprakash//latex_model_resnet_lstm.keras"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(f'{BASE_DIR}/{OUTPUT_MODEL_NAME}.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_WwX-x7YWRb"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.utils.plot_model(model,\n",
    "                       show_shapes=True,\n",
    "                       show_dtype=True,\n",
    "                       show_layer_names=True,\n",
    "                       expand_nested=True,\n",
    "                       show_layer_activations=True,\n",
    "                       to_file=f'{BASE_DIR}/{OUTPUT_MODEL_NAME}.png'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-8S5vHSLVm1"
   },
   "source": [
    "# Metrics for Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekPJ93DSLbnH"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "def lev_distance(sequence_one, sequence_two):\n",
    "    rows = len(sequence_one)\n",
    "    cols = len(sequence_two)\n",
    "    dist_tab = np.zeros((rows + 1, cols + 1), dtype=int)\n",
    "    for i in range(1, rows + 1):\n",
    "      dist_tab[i][0] = i\n",
    "    for i in range(1, cols + 1):\n",
    "      dist_tab[0][i] = i\n",
    "    for r in range(1, rows + 1):\n",
    "      for c in range(1, cols + 1):\n",
    "\n",
    "        #if tokens match\n",
    "        if sequence_one[r - 1] == sequence_two[c - 1]:\n",
    "\n",
    "          #same cost as min cost from prev tokens\n",
    "          dist_tab[r][c] = dist_tab[r - 1][c - 1]\n",
    "        else:\n",
    "\n",
    "          #min of deletion, insertion, or substitution respectively\n",
    "          dist_tab[r][c] = 1 + min(dist_tab[r - 1][c], dist_tab[r][c - 1], dist_tab[r - 1][c - 1])\n",
    "    return dist_tab[rows][cols] #return top right corner of table: min edit distance\n",
    "\n",
    "def bleu_n_score(generated_sequence, true_sequence, n):\n",
    "    gen_len = len(generated_sequence)\n",
    "    true_len = len(true_sequence)\n",
    "    scores = []\n",
    "\n",
    "    #calculate and store precision for 1-grams to n-grams\n",
    "    for gram_size in range(1,n+1):\n",
    "\n",
    "      #calculate grams\n",
    "      gen_ngrams = [tuple(generated_sequence[i:i+gram_size]) for i in range(gen_len - gram_size + 1)]\n",
    "      true_ngrams = [tuple(true_sequence[i:i+gram_size]) for i in range(true_len - gram_size + 1)]\n",
    "\n",
    "      gen_grams_count = collections.Counter(gen_ngrams) #freq dicts of grams\n",
    "      true_grams_count = collections.Counter(true_ngrams)\n",
    "\n",
    "      #sum of how many grams appear in both the gen sequence and the true\n",
    "      matching_grams_sum = sum(min(gen_grams_count[gram], true_grams_count[gram]) for gram in gen_grams_count)\n",
    "\n",
    "      #divide sum of matching grams by total number of grams in the gen sequence (precision)\n",
    "      gram_score = 0\n",
    "      if len(gen_grams_count) > 0:\n",
    "        gram_score = matching_grams_sum / len(gen_grams_count)\n",
    "      scores.append(gram_score)\n",
    "\n",
    "    #calculate geometric mean of scores for each 1-ngram\n",
    "    geo_mean = 0.0\n",
    "    for gram_score in scores:\n",
    "      if gram_score == 0.0:\n",
    "        #return 0 early: a score of 0 zeroes out mean and thus bleu score\n",
    "        return 0.0\n",
    "      geo_mean += math.log(gram_score)\n",
    "    geo_mean = math.exp(geo_mean/n)\n",
    "\n",
    "    #include brevity penalty in cases where gen sequence is longer than true sequence\n",
    "    if gen_len < true_len:\n",
    "      return math.exp(1 - true_len / gen_len) * geo_mean\n",
    "    return geo_mean #no penalty otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixV3kbyDPr8X"
   },
   "source": [
    "# Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjCZXuZ_Jn-x"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "def lev_distance(sequence_one, sequence_two):\n",
    "    rows = len(sequence_one)\n",
    "    cols = len(sequence_two)\n",
    "    dist_tab = np.zeros((rows + 1, cols + 1), dtype=int)\n",
    "    for i in range(1, rows + 1):\n",
    "      dist_tab[i][0] = i\n",
    "    for i in range(1, cols + 1):\n",
    "      dist_tab[0][i] = i\n",
    "    for r in range(1, rows + 1):\n",
    "      for c in range(1, cols + 1):\n",
    "\n",
    "        #if tokens match\n",
    "        if sequence_one[r - 1] == sequence_two[c - 1]:\n",
    "\n",
    "          #same cost as min cost from prev tokens\n",
    "          dist_tab[r][c] = dist_tab[r - 1][c - 1]\n",
    "        else:\n",
    "\n",
    "          #min of deletion, insertion, or substitution respectively\n",
    "          dist_tab[r][c] = 1 + min(dist_tab[r - 1][c], dist_tab[r][c - 1], dist_tab[r - 1][c - 1])\n",
    "    return 1 - (dist_tab[rows][cols] / max(rows, cols)) #return top right corner of table: min edit distance, normalized by length of max sequence\n",
    "\n",
    "def bleu_n_score(generated_sequence, true_sequence, n):\n",
    "    gen_len = len(generated_sequence)\n",
    "    true_len = len(true_sequence)\n",
    "    scores = []\n",
    "\n",
    "    #calculate overlap for 1-grams to n-grams\n",
    "    for gram_size in range(1,n+1):\n",
    "\n",
    "      #generate grams\n",
    "      gen_ngrams = [tuple(generated_sequence[i:i+gram_size]) for i in range(gen_len - gram_size + 1)]\n",
    "      true_ngrams = [tuple(true_sequence[i:i+gram_size]) for i in range(true_len - gram_size + 1)]\n",
    "\n",
    "      gen_grams_count = collections.Counter(gen_ngrams) #freq dictionaries of grams\n",
    "      true_grams_count = collections.Counter(true_ngrams)\n",
    "\n",
    "      #sum of how many grams appear in both the gen sequence and the true\n",
    "      matching_grams_sum = sum(min(gen_grams_count[gram], true_grams_count[gram]) for gram in gen_grams_count)\n",
    "\n",
    "      #divide sum of matching grams by total number of grams in the gen sequence (precision)\n",
    "      gram_score = 0\n",
    "      if len(gen_grams_count) > 0:\n",
    "        gram_score = matching_grams_sum / len(gen_grams_count)\n",
    "      scores.append(gram_score)\n",
    "\n",
    "    #calculate geometric mean of scores for each gram 1-n\n",
    "    geo_mean = 0.0\n",
    "    for gram_score in scores:\n",
    "      if gram_score == 0.0:\n",
    "        #return 0 early: a score of 0 zeroes out mean and thus bleu score\n",
    "        return 0.0\n",
    "      geo_mean += math.log(gram_score)\n",
    "    geo_mean = math.exp(geo_mean/n)\n",
    "\n",
    "    #include brevity penalty in cases where gen sequence is longer than true sequence\n",
    "    if gen_len < true_len:\n",
    "      return math.exp(1 - true_len / gen_len) * geo_mean\n",
    "    return geo_mean #no penalty otherwise\n",
    "\n",
    "def decode_text(encoded_text, tokenizer):\n",
    "    vocabulary = tokenizer.get_vocabulary()\n",
    "    decoded_text = [vocabulary[index] if index < len(vocabulary) else \"[UNK]\" for index in encoded_text]\n",
    "    return \" \".join(decoded_text)\n",
    "\n",
    "def predict_latex_sequence_cnn(model, image, tokenizer):\n",
    "    \"\"\"\n",
    "    Predict LaTeX sequence from a single image.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained Keras model for predicting LaTeX sequence.\n",
    "    - image: Input image (preprocessed to match training dimensions).\n",
    "    - tokenizer: Tokenizer fitted on LaTeX sequences for decoding predictions.\n",
    "    - max_seq_len: Maximum sequence length for the predicted sequence.\n",
    "\n",
    "    Returns:\n",
    "    - latex_sequence: Predicted LaTeX sequence as a string.\n",
    "    \"\"\"\n",
    "    # Prepare input image and initialize the sequence\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    vocab_dict = {name: id for id, name in enumerate(tokenizer.get_vocabulary())}\n",
    "    start_token = vocab_dict[\"<START>\"]#word_index[\"[START]\"]\n",
    "    end_token = vocab_dict[\"<END>\"]\n",
    "\n",
    "    # Initial sequence with the start token\n",
    "    sequence = [start_token]\n",
    "    # print(max_seq_len_1)\n",
    "    for _ in range(max_seq_len_1):\n",
    "        # Pad the current sequence to match input length\n",
    "        padded_sequence = np.pad(sequence, (0, max_seq_len_1 - len(sequence)), mode='constant')\n",
    "        padded_sequence = np.expand_dims(padded_sequence, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Predict next token\n",
    "        preds = model.predict([image, padded_sequence], verbose = 0)\n",
    "        next_token = np.argmax(preds[0, len(sequence) - 1, :])\n",
    "\n",
    "        # Break if end token is reached\n",
    "        if next_token == end_token:\n",
    "            break\n",
    "\n",
    "        # Add the predicted token to the sequence\n",
    "        sequence.append(next_token)\n",
    "\n",
    "    # print(sequence)\n",
    "    # Decode the token sequence to a string\n",
    "    latex_sequence = decode_text(sequence[1:], tokenizer) #tokenizer.sequences_to_texts([sequence[1:]])[0]  # Skip the start token\n",
    "    return latex_sequence\n",
    "\n",
    "def compute_mean_metrics(predicted, truth):\n",
    "   num_sequences = len(predicted)\n",
    "   #uses BLEU-4 score\n",
    "   mean_bleu = sum(bleu_n_score(predicted[i], truth[i], 4) for i in range(num_sequences)) / num_sequences\n",
    "   mean_lev = sum(lev_distance(predicted[i], truth[i]) for i in range(num_sequences)) / num_sequences\n",
    "   print(\"Mean BLEU-4 score: \", mean_bleu)\n",
    "   print(\"Mean Levenshtein similarity: \", mean_lev)\n",
    "\n",
    "def predict_latex_sequences_cnn(model, images, tokenizer):\n",
    "    result = []\n",
    "    i = 0\n",
    "    for image in images:\n",
    "        print(i)\n",
    "        i+=1\n",
    "        sequence_str = predict_latex_sequence_cnn(model, image, tokenizer)\n",
    "        #print(sequence_str)\n",
    "        result.append(sequence_str.split())\n",
    "    return result\n",
    "\n",
    "def predict_latex_sequences_transformer(images):\n",
    "    result = []\n",
    "    i = 0\n",
    "    for image in images:\n",
    "        print(i)\n",
    "        i+=1\n",
    "        sequence_str = transformer_model.simple_gen(image, temperature = 0)\n",
    "        #print(sequence_str)\n",
    "        result.append(sequence_str.split())\n",
    "    return result  \n",
    "\n",
    "test_images = train_images[:40]\n",
    "print(len(test_images))\n",
    "predicted_sequences = predict_latex_sequences_cnn(model, test_images, tokenizer)\n",
    "#predicted_sequences = predict_latex_sequences_transformer(test_images)\n",
    "test_sequences = [str.split() for str in train_latex_texts[:40]]\n",
    "print(\"Metrics for CNN-RNN: \")\n",
    "compute_mean_metrics(predicted_sequences, test_sequences)\n",
    "\n",
    "# #predicted_sequences = predict_latex_sequences_transform(test_images)\n",
    "# print(\"Metrics for CNN-RNN: \")\n",
    "# compute_mean_metrics(predicted_sequences, test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXu1SSL53mxK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
