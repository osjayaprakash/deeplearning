{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osjayaprakash/deeplearning/blob/main/cnn_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "## This is formatted as code\n",
        "python3 -m venv ~/cs230\n",
        "source ~/cs230/bin/activate\n",
        "pip3 install kagglehub kaggle tensorflow tensorflow-macos tensorflow-metal\n",
        "brew install hdf5\n",
        "pip install line_profiler\n",
        "\n",
        "## AMAZON AWS\n",
        "sudo apt update\n",
        "sudo apt install nvidia-driver-535\n",
        "reboot  # Restart the system after installation\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "## Verify that the GPUs are available\n",
        "python3\n",
        "import tensorflow as tf\n",
        "tf.sysconfig.get_build_info()\n",
        "python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices());\"\n",
        "```"
      ],
      "metadata": {
        "id": "kta8EgzKhJZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install line_profiler\n",
        "!pip install memory_profiler\n",
        "!pip install kagglehub\n",
        "!pip install matplotlib pandas scikit-learn scipy tensorflow\n",
        "!pip install tensorflow[and-cuda]\n",
        "%load_ext line_profiler\n",
        "%load_ext memory_profiler"
      ],
      "metadata": {
        "id": "BKAOqBE2Wzwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZgd8NVaFjfO"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "root_dir = kagglehub.dataset_download(\"shahrukhkhan/im2latex100k\")\n",
        "# path = kagglehub.dataset_download(\"gregoryeritsyan/im2latex-230k\")\n",
        "\n",
        "print(\"Path to dataset files:\", root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Flatten,\n",
        "                                     Dense, GRU, Embedding, Bidirectional,\n",
        "                                     TimeDistributed, Concatenate, RepeatVector, LSTM)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import platform\n",
        "import sys\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import scipy as sp\n",
        "\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "print(f\"Python Platform: {platform.platform()}\")\n",
        "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
        "#print(f\"Keras Version: {tf.keras.__version__}\")\n",
        "print()\n",
        "print(f\"Python {sys.version}\")\n",
        "print(f\"Pandas {pd.__version__}\")\n",
        "print(f\"Scikit-Learn {sk.__version__}\")\n",
        "print(f\"SciPy {sp.__version__}\")\n",
        "print(tf.config.list_physical_devices())\n",
        "\n",
        "# Initialize Tokenizer (Configure it with LaTeX vocabulary)\n",
        "vocab_size = None  # Adjust based on your dataset\n",
        "max_seq_length = 250  # Max length of output sequence\n",
        "RESNET_MODEL = True\n",
        "IMG_SIZE = [50,224,1] # height, width, channels\n",
        "BASE_DIR = \"/Users/jayaprakash/\"\n",
        "#BASE_DIR = \"/home/ubuntu/\"\n",
        "\n",
        "OUTPUT_MODEL_NAME = \"latex_model_cnn_lstm\"\n",
        "EMBEDDING_DIM = 256\n",
        "lstm_units = 265\n",
        "if RESNET_MODEL:\n",
        "    IMG_SIZE = [224,224,3]\n",
        "    OUTPUT_MODEL_NAME = \"latex_model_resnet_lstm\""
      ],
      "metadata": {
        "id": "6TKz3RA-FuOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, filters='', lower=False)\n",
        "def fit_tokenizer(texts):\n",
        "    \"\"\"Fit the tokenizer on the LaTeX text corpus.\"\"\"\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    # max_seq_length = max(len(seq) for seq in tokenizer.texts_to_sequences(texts))\n",
        "    acutal_max_seq_length = max(len(seq) for seq in tokenizer.texts_to_sequences(texts))\n",
        "    assert max_seq_length >= acutal_max_seq_length,  f\"max_seq_length ({max_seq_length}) should be greater than or equal to acutal_max_seq_length ({acutal_max_seq_length})\"\n",
        "    print(f\"Vocabulary size: {vocab_size}, Max sequence length: {max_seq_length}\")\n",
        "    return vocab_size, max_seq_length\n",
        "\n",
        "def text_to_sequence(text):\n",
        "    \"\"\"Convert LaTeX text to a sequence of tokens.\"\"\"\n",
        "    return tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "def sequence_to_text(sequence):\n",
        "    \"\"\"Convert token sequence back to LaTeX text.\"\"\"\n",
        "    return tokenizer.sequences_to_texts([sequence])[0]"
      ],
      "metadata": {
        "id": "gbyzYAzjFwap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "Qo6QNApGGgIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    \"\"\"Preprocess the input image: Resize and normalize.\"\"\"\n",
        "    image = tf.image.resize(image, (IMG_SIZE[0], IMG_SIZE[1]))\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    \"\"\"Load and preprocess a batch of images.\"\"\"\n",
        "    # Use Gray scale\n",
        "    images = [\n",
        "        preprocess_image(\n",
        "            tf.io.decode_image(\n",
        "                tf.io.read_file(path), channels=IMG_SIZE[2]))\n",
        "              for path in image_paths]\n",
        "    return tf.stack(images)\n",
        "\n",
        "def prepare_sequences(latex_texts, max_seq_length):\n",
        "    \"\"\"Convert LaTeX texts to padded sequences of tokens.\"\"\"\n",
        "    sequences = [text_to_sequence(text) for text in latex_texts]\n",
        "    return pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n"
      ],
      "metadata": {
        "id": "wAMBW0OFF_VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%prun\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(f\"{root_dir}/im2latex_train.csv\", nrows=1000)\n",
        "\n",
        "train_image_paths = []\n",
        "train_latex_texts = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    train_image_paths += [f\"{root_dir}//formula_images_processed/formula_images_processed/{row.image}\"]\n",
        "    train_latex_texts += [\"<START> \" + row.formula + \" <END>\"]\n",
        "\n",
        "# Enable Numpy behaviour of TF\n",
        "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
        "\n",
        "vocab_size, max_seq_length = fit_tokenizer(train_latex_texts)\n",
        "\n",
        "train_images = load_and_preprocess_images(train_image_paths)\n",
        "train_sequences = prepare_sequences(train_latex_texts, max_seq_length)\n",
        "train_sequences = np.expand_dims(train_sequences, -1)\n",
        "print(\"train_images:\", train_images.shape)\n",
        "print(\"train_sequences:\", train_sequences.shape)"
      ],
      "metadata": {
        "id": "4NIjhtisIi1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_sequences.shape, train_images.shape)\n",
        "print(type(train_sequences))\n",
        "print(train_sequences[0].reshape(1,-1).tolist()[0])\n",
        "print(sequence_to_text(train_sequences[0].reshape(1,-1).tolist()[0]))"
      ],
      "metadata": {
        "id": "hTF4s-ENIs6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_image_paths[0])\n",
        "!ls -lart \"{train_image_paths[0]}\"\n",
        "print(train_latex_texts[0])"
      ],
      "metadata": {
        "id": "az_S8OFzIvc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "jR4DR8dtIkgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len_1 = max_seq_length-1\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# CNN Encoder\n",
        "image_input = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], IMG_SIZE[2]), name=\"image_input\")\n",
        "if RESNET_MODEL is False:\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(image_input)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "else:\n",
        "    #rgb_image = tf.keras.layers.Lambda(lambda x: tf.image.grayscale_to_rgb(x), output_shape=(None, ))(image_input)\n",
        "    resnet = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=image_input)\n",
        "    # Freeze ResNet layers\n",
        "    for layer in resnet.layers:\n",
        "        layer.trainable = False\n",
        "    # Pooling to reduce dimensions\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(resnet.output)\n",
        "x = Dense(EMBEDDING_DIM, activation='relu')(x)\n",
        "# Repeat encoder output for each time step\n",
        "encoder_output = RepeatVector(max_seq_len_1)(x)\n",
        "\n",
        "# LSTM Decoder with Attention\n",
        "decoder_input = Input(shape=(max_seq_len_1,), name=\"decoder_input\")  # Sequence input for teacher forcing\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_seq_len_1)\n",
        "embedded_seq = embedding_layer(decoder_input)\n",
        "\n",
        "decoder_lstm_input = tf.keras.layers.Concatenate(axis=-1)([encoder_output, embedded_seq])\n",
        "decoder_lstm = LSTM(lstm_units, return_sequences=True)(decoder_lstm_input)\n",
        "output_layer = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(decoder_lstm)\n",
        "\n",
        "# Build Model\n",
        "model = Model(inputs=[image_input, decoder_input], outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "dAEanssRGlpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dot_img_file =\n",
        "import keras\n",
        "keras.utils.plot_model(model,\n",
        "                       show_shapes=True,\n",
        "                       show_dtype=True,\n",
        "                       show_layer_names=True,\n",
        "                       expand_nested=True,\n",
        "                       show_layer_activations=True,\n",
        "                       )"
      ],
      "metadata": {
        "id": "Z_u6gxZzWVRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WPlMAbm6OYh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([train_images, train_sequences[:, :-1]],\n",
        "          train_sequences[:, 1:],\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model.save(f'{BASE_DIR}/{OUTPUT_MODEL_NAME}.keras')"
      ],
      "metadata": {
        "id": "ePe5hVCKG0df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(f'{BASE_DIR}/{OUTPUT_MODEL_NAME}.keras')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "RZLiNTARQNDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.utils.plot_model(model,\n",
        "                       show_shapes=True,\n",
        "                       show_dtype=True,\n",
        "                       show_layer_names=True,\n",
        "                       expand_nested=True,\n",
        "                       show_layer_activations=True,\n",
        "                       to_file=f'{BASE_DIR}/{OUTPUT_MODEL_NAME}.png'\n",
        "                       )"
      ],
      "metadata": {
        "id": "l_WwX-x7YWRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics for Accuracy"
      ],
      "metadata": {
        "id": "U-8S5vHSLVm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "\n",
        "def lev_distance(sequence_one, sequence_two):\n",
        "    rows = len(sequence_one)\n",
        "    cols = len(sequence_two)\n",
        "    dist_tab = np.zeros((rows + 1, cols + 1), dtype=int)\n",
        "    for i in range(1, rows + 1):\n",
        "      dist_tab[i][0] = i\n",
        "    for i in range(1, cols + 1):\n",
        "      dist_tab[0][i] = i\n",
        "    for r in range(1, rows + 1):\n",
        "      for c in range(1, cols + 1):\n",
        "\n",
        "        #if tokens match\n",
        "        if sequence_one[r - 1] == sequence_two[c - 1]:\n",
        "\n",
        "          #same cost as min cost from prev tokens\n",
        "          dist_tab[r][c] = dist_tab[r - 1][c - 1]\n",
        "        else:\n",
        "\n",
        "          #min of deletion, insertion, or substitution respectively\n",
        "          dist_tab[r][c] = 1 + min(dist_tab[r - 1][c], dist_tab[r][c - 1], dist_tab[r - 1][c - 1])\n",
        "    return dp[rows][cols] #return top right corner of table: min edit distance\n",
        "\n",
        "def bleu_n_score(generated_sequence, true_sequence, n):\n",
        "    gen_len = len(generated_sequence)\n",
        "    true_len = len(true_sequence)\n",
        "    scores = []\n",
        "\n",
        "    #calculate and store precision for 1-grams to n-grams\n",
        "    for gram_size in range(1,n+1):\n",
        "\n",
        "      #calculate grams\n",
        "      gen_ngrams = [tuple(generated_sequence[i:i+gram_size]) for i in range(gen_len - gram_size + 1)]\n",
        "      true_ngrams = [tuple(true_sequence[i:i+gram_size]) for i in range(true_len - gram_size + 1)]\n",
        "\n",
        "      gen_grams_count = collections.Counter(gen_ngrams) #freq dicts of grams\n",
        "      true_grams_count = collections.Counter(true_ngrams)\n",
        "\n",
        "      #sum of how many grams appear in both the gen sequence and the true\n",
        "      matching_grams_sum = sum(min(gen_grams_count[gram], reference_counts[gram]) for gram in gen_grams_count)\n",
        "\n",
        "      #divide sum of matching grams by total number of grams in the gen sequence (precision)\n",
        "      gram_score = 0\n",
        "      if len(gen_grams_count) > 0:\n",
        "        gram_score = matching_grams_sum / len(gen_grams_count)\n",
        "      scores.append(gram_score)\n",
        "\n",
        "    #calculate geometric mean of scores for each 1-ngram\n",
        "    geo_mean = 0.0\n",
        "    for gram_score in scores:\n",
        "      if gram_score == 0.0:\n",
        "        #return 0 early: a score of 0 zeroes out mean and thus bleu score\n",
        "        return 0.0\n",
        "      geo_mean += math.log(gram_score)\n",
        "    geo_mean = math.exp(geo_mean/n)\n",
        "\n",
        "    #include brevity penalty in cases where gen sequence is longer than true sequence\n",
        "    if gen_len < true_len:\n",
        "      return math.exp(1 - true_len / gen_len) * geo_mean\n",
        "    return geo_mean #no penalty otherwise"
      ],
      "metadata": {
        "id": "ekPJ93DSLbnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "ixV3kbyDPr8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_latex_sequence(model, image, tokenizer):\n",
        "    \"\"\"\n",
        "    Predict LaTeX sequence from a single image.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model for predicting LaTeX sequence.\n",
        "    - image: Input image (preprocessed to match training dimensions).\n",
        "    - tokenizer: Tokenizer fitted on LaTeX sequences for decoding predictions.\n",
        "    - max_seq_len: Maximum sequence length for the predicted sequence.\n",
        "\n",
        "    Returns:\n",
        "    - latex_sequence: Predicted LaTeX sequence as a string.\n",
        "    \"\"\"\n",
        "    # Prepare input image and initialize the sequence\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    start_token = tokenizer.word_index[\"<START>\"]\n",
        "    end_token = tokenizer.word_index[\"<END>\"]\n",
        "\n",
        "    # Initial sequence with the start token\n",
        "    sequence = [start_token]\n",
        "\n",
        "    for _ in range(max_seq_len_1):\n",
        "        # Pad the current sequence to match input length\n",
        "        padded_sequence = np.pad(sequence, (0, max_seq_len_1 - len(sequence)), mode='constant')\n",
        "        padded_sequence = np.expand_dims(padded_sequence, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Predict next token\n",
        "        preds = model.predict([image, padded_sequence])\n",
        "        next_token = np.argmax(preds[0, len(sequence) - 1, :])\n",
        "\n",
        "        # Break if end token is reached\n",
        "        if next_token == end_token:\n",
        "            break\n",
        "\n",
        "        # Add the predicted token to the sequence\n",
        "        sequence.append(next_token)\n",
        "\n",
        "    # Decode the token sequence to a string\n",
        "    latex_sequence = tokenizer.sequences_to_texts([sequence[1:]])[0]  # Skip the start token\n",
        "    return latex_sequence\n",
        "\n",
        "predicted_latex = predict_latex_sequence(model, train_images[12], tokenizer)\n",
        "print(\"Predicted LaTeX:\", predicted_latex)\n",
        "#print(\"Original Seq:\", train_sequences[0])\n",
        "print(\"Original Seq:\", train_latex_texts[12])"
      ],
      "metadata": {
        "id": "vjCZXuZ_Jn-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXu1SSL53mxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}