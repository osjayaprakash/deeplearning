{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN7QSlkrdcIhubN3XtvOMBL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osjayaprakash/deeplearning/blob/main/CS_230_Full_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "python3 -m venv ~/cs230\n",
        "\n",
        "source ~/cs230/bin/activate\n",
        "\n",
        "pip3 install kagglehub kaggle tensorflow tensorflow-macos tensorflow-metal\n",
        "\n",
        "brew install hdf5\n",
        "\n",
        "\n",
        "## AMAZON AWS\n",
        "\n",
        "\n",
        "```\n",
        "sudo apt update\n",
        "sudo apt install nvidia-driver-535\n",
        "reboot  # Restart the system after installation\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "python3\n",
        "import tensorflow as tf\n",
        "tf.sysconfig.get_build_info()\n",
        "\n",
        "python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices());\"\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kta8EgzKhJZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZgd8NVaFjfO"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "root_dir = kagglehub.dataset_download(\"shahrukhkhan/im2latex100k\")\n",
        "# path = kagglehub.dataset_download(\"gregoryeritsyan/im2latex-230k\")\n",
        "\n",
        "print(\"Path to dataset files:\", root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Flatten,\n",
        "                                     Dense, GRU, Embedding, Bidirectional,\n",
        "                                     TimeDistributed, Concatenate, RepeatVector, LSTM)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import platform\n",
        "import sys\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import scipy as sp\n",
        "\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "print(f\"Python Platform: {platform.platform()}\")\n",
        "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
        "print(f\"Keras Version: {tf.keras.__version__}\")\n",
        "print()\n",
        "print(f\"Python {sys.version}\")\n",
        "print(f\"Pandas {pd.__version__}\")\n",
        "print(f\"Scikit-Learn {sk.__version__}\")\n",
        "print(f\"SciPy {sp.__version__}\")\n",
        "print(tf.config.list_physical_devices())"
      ],
      "metadata": {
        "id": "6TKz3RA-FuOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Tokenizer (Configure it with LaTeX vocabulary)\n",
        "vocab_size = None  # Adjust based on your dataset\n",
        "max_seq_length = None  # Max length of output sequence\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, filters='', lower=False)\n",
        "def fit_tokenizer(texts):\n",
        "    \"\"\"Fit the tokenizer on the LaTeX text corpus.\"\"\"\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    max_seq_length = max(len(seq) for seq in tokenizer.texts_to_sequences(texts))\n",
        "    print(f\"Vocabulary size: {vocab_size}, Max sequence length: {max_seq_length}\")\n",
        "    return vocab_size, max_seq_length\n",
        "\n",
        "def text_to_sequence(text):\n",
        "    \"\"\"Convert LaTeX text to a sequence of tokens.\"\"\"\n",
        "    return tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "def sequence_to_text(sequence):\n",
        "    \"\"\"Convert token sequence back to LaTeX text.\"\"\"\n",
        "    return tokenizer.sequences_to_texts([sequence])[0]"
      ],
      "metadata": {
        "id": "gbyzYAzjFwap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "Qo6QNApGGgIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    \"\"\"Preprocess the input image: Resize and normalize.\"\"\"\n",
        "    image = tf.image.resize(image, (50, 200))  # Resize to (50, 200)\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    \"\"\"Load and preprocess a batch of images.\"\"\"\n",
        "    # Use Gray scale\n",
        "    images = [preprocess_image(tf.io.decode_image(tf.io.read_file(path), channels=1))\n",
        "              for path in image_paths]\n",
        "    return tf.stack(images)\n",
        "\n",
        "def prepare_sequences(latex_texts, max_seq_length):\n",
        "    \"\"\"Convert LaTeX texts to padded sequences of tokens.\"\"\"\n",
        "    sequences = [text_to_sequence(text) for text in latex_texts]\n",
        "    return pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n"
      ],
      "metadata": {
        "id": "wAMBW0OFF_VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(f\"{root_dir}/im2latex_train.csv\", nrows=100000)\n",
        "\n",
        "train_image_paths = []\n",
        "train_latex_texts = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    train_image_paths += [f\"{root_dir}//formula_images_processed/formula_images_processed/{row.image}\"]\n",
        "    train_latex_texts += [\"<START> \" + row.formula + \" <END>\"]\n",
        "\n",
        "# Enable Numpy behaviour of TF\n",
        "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
        "\n",
        "vocab_size, max_seq_length = fit_tokenizer(train_latex_texts)\n",
        "\n",
        "train_images = load_and_preprocess_images(train_image_paths)\n",
        "train_sequences = prepare_sequences(train_latex_texts, max_seq_length)\n",
        "train_sequences = np.expand_dims(train_sequences, -1)\n",
        "print(\"train_images:\", train_images.shape)\n",
        "print(\"train_sequences:\", train_sequences.shape)"
      ],
      "metadata": {
        "id": "4NIjhtisIi1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_sequences.shape, train_images.shape)\n",
        "print(type(train_sequences))\n",
        "print(train_sequences[0].reshape(1,-1).tolist()[0])\n",
        "print(sequence_to_text(train_sequences[0].reshape(1,-1).tolist()[0]))"
      ],
      "metadata": {
        "id": "hTF4s-ENIs6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_image_paths[0])\n",
        "!ls -lart \"{train_image_paths[0]}\"\n",
        "print(train_latex_texts[0])"
      ],
      "metadata": {
        "id": "az_S8OFzIvc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "jR4DR8dtIkgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH, IMG_HEIGHT = 200, 50\n",
        "EMBEDDING_DIM = 256\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "def create_cnn_encoder():\n",
        "    \"\"\"Create the CNN feature extractor.\"\"\"\n",
        "    inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1))  # Grayscale input\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    cnn_output = Dense(EMBEDDING_DIM, activation='relu')(x)\n",
        "    return Model(inputs, cnn_output)\n",
        "\n",
        "class MyLayer(Layer):\n",
        "    def call(self, x):\n",
        "        notq = tf.math.not_equal(x,0)\n",
        "        return tf.cast(notq, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    \"\"\"Create the encoder-decoder model.\"\"\"\n",
        "    cnn_encoder = create_cnn_encoder()\n",
        "\n",
        "    # Encoder\n",
        "    image_input = cnn_encoder.input\n",
        "    image_output = cnn_encoder.output\n",
        "    encoder_output = RepeatVector(max_seq_length, name='enc_output')(image_output)\n",
        "\n",
        "    # Decoder\n",
        "    text_input = Input(shape=(max_seq_length,), name=\"text_input\")\n",
        "    #mask = MyLayer()(text_input)\n",
        "    text_embedding = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_seq_length, mask_zero=False)(text_input)\n",
        "    #text_embedding = tf.keras.layers.Multiply()([text_embedding, mask[:, :, tf.newaxis]])\n",
        "\n",
        "    merged_input = tf.keras.layers.Concatenate()([encoder_output, text_embedding])\n",
        "\n",
        "    lstm_output = LSTM(vocab_size, return_sequences=True)(merged_input)\n",
        "    output = TimeDistributed(Dense(vocab_size, activation='softmax'))(lstm_output)\n",
        "\n",
        "    # Full Model\n",
        "    model = Model([image_input, text_input], output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "dAEanssRGlpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dot_img_file =\n",
        "import keras\n",
        "keras.utils.plot_model(model,\n",
        "                       show_shapes=True,\n",
        "                       show_dtype=True,\n",
        "                       show_layer_names=True,\n",
        "                       expand_nested=True,\n",
        "                       show_layer_activations=True,\n",
        "                       )"
      ],
      "metadata": {
        "id": "Z_u6gxZzWVRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WPlMAbm6OYh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([train_images, train_sequences], train_sequences,\n",
        "          epochs=5, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "ePe5hVCKG0df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXwkVZjbeuEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "ixV3kbyDPr8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_latex(image, model):\n",
        "    \"\"\"Generate LaTeX code from a single input image.\"\"\"\n",
        "    image = preprocess_image(image)\n",
        "    image = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Initialize decoder input with <START> token\n",
        "    decoder_input = tf.zeros((1, max_seq_length), dtype=tf.int32)\n",
        "    # tf.print(decoder_input)\n",
        "    # tf.print(decoder_input.shape)\n",
        "    decoder_input = tf.tensor_scatter_nd_update(decoder_input, [[0, 0]], [tokenizer.word_index['<START>']])\n",
        "\n",
        "\n",
        "    predicted_sequence = []\n",
        "\n",
        "    for i in range(1, 100):\n",
        "        predictions = model([image, decoder_input], training=False)\n",
        "        # tf.print(\"predicted_sequence:\", predicted_sequence)\n",
        "        # tf.print(\"decoder_input:\", decoder_input)\n",
        "        # tf.print(\"predictions:\", predictions)\n",
        "        # tf.print(\"predictions:\", predictions.shape)\n",
        "        next_token = tf.argmax(predictions[0, i-1, 0:], axis=-1).numpy()\n",
        "        _, next_token = max((x,i) for i,x in enumerate(predictions[0, i-1, 0:]) if i != tokenizer.word_index['<START>'])\n",
        "\n",
        "        if next_token == tokenizer.word_index['<END>']:\n",
        "           break\n",
        "\n",
        "        predicted_sequence.append(next_token)\n",
        "        decoder_input = tf.tensor_scatter_nd_update(decoder_input, [[0, i]], [next_token])\n",
        "\n",
        "    print(\"Predicted Seq:\", predicted_sequence)\n",
        "    return sequence_to_text(predicted_sequence)\n",
        "\n",
        "# Example usage: Predict LaTeX from an image\n",
        "print(type(train_images))\n",
        "#test_image = tf.random.uniform((50, 200, 1))  # Replace with your test image\n",
        "predicted_latex = predict_latex(train_images[1], model)\n",
        "print(\"Predicted LaTeX:\", predicted_latex)\n",
        "print(\"Original Seq:\", train_sequences[0])\n",
        "print(\"Original Seq:\", train_latex_texts[0])\n"
      ],
      "metadata": {
        "id": "KmKkdmdUPtjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T9MKLOc1REDl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}