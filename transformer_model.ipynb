{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/osjayaprakash/deeplearning/blob/main/transformer_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xZgd8NVaFjfO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Path to dataset files: /home/ubuntu/.cache/kagglehub/datasets/shahrukhkhan/im2latex100k/versions/7\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "root_dir = kagglehub.dataset_download(\"shahrukhkhan/im2latex100k\")\n",
    "# path = kagglehub.dataset_download(\"gregoryeritsyan/im2latex-230k\")\n",
    "\n",
    "print(\"Path to dataset files:\", root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "6TKz3RA-FuOp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Linux-5.15.0-1071-aws-x86_64-with-glibc2.29\n",
      "Tensor Flow Version: 2.13.1\n",
      "\n",
      "Python 3.8.10 (default, Nov  7 2024, 13:10:47) \n",
      "[GCC 9.4.0]\n",
      "Pandas 2.0.3\n",
      "Scikit-Learn 1.3.2\n",
      "SciPy 1.10.1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Flatten,\n",
    "                                     Dense, GRU, Embedding, Bidirectional,\n",
    "                                     TimeDistributed, Concatenate, RepeatVector, LSTM, MultiHeadAttention, LayerNormalization, Add, Dropout )\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "from tensorflow.python.ops.numpy_ops import np_config  \n",
    "import einops\n",
    "\n",
    "np_config.enable_numpy_behavior()\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "#print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(f\"SciPy {sp.__version__}\")\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo6QNApGGgIk"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256  # We'll resize input images to this size\n",
    "IMG_SHAPE = (256, 256, 1)\n",
    "EMBEDDING_DIM = 256\n",
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wAMBW0OFF_VN"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess the input image: Resize and normalize.\"\"\"\n",
    "    image = tf.image.resize(image, (image_size, image_size))  # Resize to (50, 200)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    \"\"\"Load and preprocess a batch of images.\"\"\"\n",
    "    # Use Gray scale\n",
    "    images = [preprocess_image(tf.io.decode_image(tf.io.read_file(path), channels=1))\n",
    "              for path in image_paths]\n",
    "    return tf.stack(images)\n",
    "\n",
    "def prepare_sequences(latex_texts, max_seq_length):\n",
    "    \"\"\"Convert LaTeX texts to padded sequences of tokens.\"\"\"\n",
    "    sequences = [text_to_sequence(text) for text in latex_texts]\n",
    "    return pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4NIjhtisIi1W"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 07:54:55.003465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-29 07:54:55.004336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-29 07:54:55.005110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-29 07:54:55.667143: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-29 07:54:55.667956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-29 07:54:55.668727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-29 07:54:55.669447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10786 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# %%prun\n",
    "\n",
    "df = pd.read_csv(f\"{root_dir}/im2latex_train.csv\", nrows=n)\n",
    "\n",
    "train_image_paths = []\n",
    "train_latex_texts = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    train_image_paths += [f\"{root_dir}//formula_images_processed/formula_images_processed/{row.image}\"]\n",
    "    train_latex_texts += [\"[START] \" + row.formula + \" [END]\"]\n",
    "\n",
    "train_images = load_and_preprocess_images(train_image_paths)\n",
    "# Enable Numpy behaviour of TF\n",
    "# tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "\n",
    "# vocab_size, max_seq_length = fit_tokenizer(train_latex_texts)\n",
    "\n",
    "# train_sequences = prepare_sequences(train_latex_texts, max_seq_length)\n",
    "# #train_sequences = np.expand_dims(train_sequences, -1)\n",
    "# print(\"train_images:\", train_images.shape)\n",
    "# print(\"train_sequences:\", train_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "GjYzQHDSAAI1"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 5000\n",
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size, standardize = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "WpXdTtsaAAI1"
   },
   "outputs": [],
   "source": [
    "tokenizer.adapt(train_latex_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "WJgjaXn2AAI3"
   },
   "outputs": [],
   "source": [
    "latex_labels = tokenizer(train_latex_texts)\n",
    "train_sequences = np.asarray(latex_labels)\n",
    "input_labels = train_sequences[..., :-1]\n",
    "output_labels = train_sequences[..., 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "az_S8OFzIvc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 152)\n",
      "(10000, 256, 256, 1)\n",
      "{'': 0, '[UNK]': 1, '}': 2, '{': 3, '_': 4, '^': 5, '2': 6, '(': 7, ')': 8, '=': 9, '1': 10, '-': 11, ',': 12, '[START]': 13, '[END]': 14, '\\\\frac': 15, '+': 16, 'i': 17, '0': 18, 'x': 19, 'n': 20, '.': 21, 'a': 22, 'd': 23, '\\\\,': 24, '\\\\mu': 25, 'e': 26, 'k': 27, 'm': 28, 'c': 29, '\\\\partial': 30, 't': 31, 'r': 32, 'p': 33, '\\\\alpha': 34, 'A': 35, '\\\\;': 36, 's': 37, '~': 38, '3': 39, 'j': 40, 'l': 41, '\\\\right)': 42, '\\\\left(': 43, 'g': 44, '4': 45, '\\\\': 46, '\\\\nu': 47, '\\\\prime': 48, '\\\\pi': 49, 'b': 50, '\\\\phi': 51, 'z': 52, '|': 53, '\\\\mathrm': 54, '\\\\delta': 55, 'f': 56, '\\\\cal': 57, 'N': 58, 'q': 59, 'T': 60, '\\\\beta': 61, 'S': 62, 'R': 63, '\\\\lambda': 64, ']': 65, '\\\\int': 66, '[': 67, 'M': 68, 'B': 69, '\\\\bar': 70, 'L': 71, '\\\\operatorname': 72, 'D': 73, '\\\\theta': 74, 'F': 75, 'y': 76, '\\\\sigma': 77, '&': 78, 'h': 79, '\\\\psi': 80, '\\\\\\\\': 81, '\\\\hat': 82, '\\\\gamma': 83, '\\\\sum': 84, '/': 85, '\\\\sqrt': 86, 'u': 87, 'H': 88, '\\\\tilde': 89, '\\\\rho': 90, '\\\\tau': 91, 'C': 92, 'o': 93, 'P': 94, 'G': 95, '\\\\omega': 96, 'I': 97, 'V': 98, 'E': 99, '\\\\epsilon': 100, '\\\\Phi': 101, '\\\\xi': 102, 'X': 103, '\\\\bf': 104, 'J': 105, '\\\\eta': 106, '\\\\quad': 107, '\\\\vec': 108, 'Q': 109, 'v': 110, 'K': 111, '\\\\infty': 112, '\\\\Gamma': 113, '\\\\pm': 114, '5': 115, '\\\\right]': 116, '\\\\left[': 117, '\\\\dot': 118, 'U': 119, '\\\\varphi': 120, 'Z': 121, '\\\\Delta': 122, '*': 123, '\\\\end{array}': 124, '\\\\begin{array}': 125, 'W': 126, '\\\\rangle': 127, '6': 128, '\\\\Lambda': 129, '\\\\Omega': 130, 'w': 131, ';': 132, '\\\\Psi': 133, '\\\\chi': 134, '\\\\qquad': 135, '\\\\}': 136, '\\\\{': 137, '\\\\kappa': 138, '\\\\cdot': 139, '\\\\equiv': 140, '8': 141, '\\\\overline': 142, '>': 143, '\\\\langle': 144, '\\\\!': 145, '\\\\dagger': 146, '\\\\rightarrow': 147, '\\\\zeta': 148, 'Y': 149, '<': 150, '\\\\varepsilon': 151, '\\\\nabla': 152, '\\\\Sigma': 153, '\\\\ell': 154, '\\\\cdots': 155, 'O': 156, ':': 157, '\\\\mathcal': 158, '\\\\ldots': 159, '\\\\left\\\\{': 160, '\\\\vert': 161, '\\\\operatorname*': 162, '\\\\:': 163, '\\\\sim': 164, '\\\\otimes': 165, '!': 166, '\\\\hbar': 167, '\\\\wedge': 168, '\\\\hspace': 169, '7': 170, '\\\\Pi': 171, '\\\\prod': 172, '\\\\to': 173, '\\\\right\\\\}': 174, '\\\\right|': 175, '\\\\in': 176, '9': 177, '\\\\widetilde': 178, '\\\\times': 179, '\\\\left|': 180, '\\\\underline': 181, '\\\\Big': 182, '\\\\mid': 183, '\\\\dots': 184, '\\\\approx': 185, '\\\\leq': 186, '\\\\Theta': 187, '\\\\ast': 188, '\\\\perp': 189, '\\\\stackrel': 190, '\\\\displaystyle': 191, '\\\\left.': 192, '\\\\right\\\\rangle': 193, '\\\\mathbf': 194, '\\\\right.': 195, '\\\\star': 196, '\\\\widehat': 197, '\\\\geq': 198, '\\\\Bigr': 199, '\\\\bigg': 200, '\\\\Bigl': 201, '\\\\mp': 202, '\\\\vartheta': 203, '\\\\big': 204, '\\\\left\\\\langle': 205, \"'\": 206, '\\\\oint': 207, '\\\\dag': 208, '\\\\circ': 209, '\\\\simeq': 210, '\\\\ddot': 211, '\\\\longrightarrow': 212, '\\\\biggr': 213, '\\\\biggl': 214, '\\\\textstyle': 215, '\\\\neq': 216, '\\\\imath': 217, '\\\\boldmath': 218, '\\\\nonumber': 219, '\\\\Xi': 220, '\\\\propto': 221, '\\\\right>': 222, '--': 223, '\\\\bigr': 224, '\\\\oplus': 225, '\\\\triangle': 226, '\\\\bigl': 227, '\\\\varrho': 228, '\\\\le': 229, '\\\\check': 230, '\\\\lbrack': 231, '\\\\textrm': 232, '\\\\sp': 233, '\\\\ge': 234, '\\\\it': 235, '\\\\not': 236, '\\\\|': 237, '\\\\mapsto': 238, '\\\\forall': 239, '\\\\Rightarrow': 240, '\\\\leftrightarrow': 241, '\\\\parallel': 242, '\\\\overrightarrow': 243, '\\\\subset': 244, '\\\\phantom': 245, '\\\\l': 246, '\\\\hline': 247, '\\\\bot': 248, '\\\\rbrack': 249, '\\\\ne': 250, '\\\\Upsilon': 251, '\\\\Bigg': 252, '\\\\slash': 253, '\\\\gg': 254, '\\\\cong': 255, '\\\\breve': 256, '\\\\tt': 257, '\\\\rightharpoonup': 258, '\\\\kern': 259, '\\\\binom': 260, '\\\\Im': 261, '\\\\varsigma': 262, '\\\\small': 263, '\\\\scriptsize': 264, '\\\\ll': 265, '\\\\atop': 266, '\\\\supset': 267, '\\\\protect': 268, '\\\\jmath': 269, '\\\\bigoplus': 270, '\\\\#': 271, '\\\\vee': 272, '\\\\left\\\\vert': 273, '\\\\iota': 274, '\\\\bullet': 275, '\\\\L': 276, '\\\\Biggr': 277, '\\\\vspace': 278, '\\\\tiny': 279, '\\\\scriptscriptstyle': 280, '\\\\d': 281, '\\\\varpi': 282, '\\\\mathsf': 283, '\\\\left<': 284, '\\\\Biggl': 285, '\\\\wp': 286, '\\\\sb': 287, '\\\\mit': 288, '\\\\lbrace': 289, '\\\\sf': 290, '\\\\scriptstyle': 291, '\\\\rbrace': 292, '\\\\llap': 293, '\\\\bigotimes': 294, '\\\\Leftrightarrow': 295, '\\\\right\\\\vert': 296, '\\\\i': 297, '\\\\cap': 298, '\\\\Re': 299, '\\\\right\\\\|': 300, '\\\\mathop': 301, '\\\\left\\\\|': 302, '\\\\doteq': 303, '\\\\Longrightarrow': 304, '\\\\rfloor': 305, '\\\\overleftarrow': 306, '\\\\o': 307, '\\\\leftarrow': 308, '\\\\hfill': 309, '\\\\bigtriangleup': 310, '\\\\Vert': 311, '\\\\vdots': 312, '\\\\underbrace': 313, '\\\\textup': 314, '\\\\subseteq': 315, '\\\\longleftrightarrow': 316, '\\\\cup': 317, '\\\\cdotp': 318, '\\\\acute': 319, '\\\\_': 320, '`': 321, '\\\\vphantom': 322, '\\\\space': 323, '\\\\sharp': 324, '\\\\right\\\\rfloor': 325, '\\\\footnotesize': 326, '\\\\c': 327, '\\\\Large': 328, 'ule': 329, '\\\\thinspace': 330, '\\\\textbf': 331, '\\\\raisebox': 332, '\\\\raise': 333, '\\\\ni': 334, '\\\\mathit': 335, '\\\\lfloor': 336, '\\\\label': 337, '\\\\flat': 338, '\\\\downarrow': 339, '\\\\ddots': 340, '\\\\colon': 341, '\\\\bigtriangledown': 342, '\\\\backslash': 343, '\\\\O': 344, '\\\\Longleftrightarrow': 345, '\"': 346, 'pt': 347, 'mm': 348, 'cm': 349, '\\\\vdash': 350, '\\\\upsilon': 351, '\\\\unitlength': 352, '\\\\smallskip': 353, '\\\\setminus': 354, '\\\\setlength': 355, '\\\\rightleftharpoons': 356, '\\\\relax': 357, '\\\\ref': 358, '\\\\put': 359, '\\\\pounds': 360, '\\\\overbrace': 361, '\\\\odot': 362, '\\\\makebox': 363, '\\\\left\\\\lfloor': 364, '\\\\large': 365, '\\\\land': 366, '\\\\enspace': 367, '\\\\emptyset': 368, '\\\\do': 369, '\\\\diamondsuit': 370, '\\\\diamond': 371, '\\\\circle': 372, '\\\\buildrel': 373, '\\\\bmod': 374, '\\\\bigcup': 375, '\\\\aleph': 376, '\\\\Huge': 377, \"\\\\'\": 378, '\\\\uparrow': 379, '\\\\thicklines': 380, '\\\\textsf': 381, '\\\\textit': 382, '\\\\succeq': 383, '\\\\sl': 384, '\\\\right\\\\rbrace': 385, '\\\\pmod': 386, '\\\\mathbin': 387, '\\\\mathaccent': 388, '\\\\longmapsto': 389, '\\\\lefteqn': 390, '\\\\left\\\\lbrace': 391, '\\\\left/': 392, '\\\\lceil': 393, '\\\\j': 394, '\\\\hphantom': 395, '\\\\grave': 396, '\\\\fbox': 397, '\\\\em': 398, '\\\\b': 399, '\\\\^': 400, '\\\\S': 401, '\\\\P': 402, '\\\\/': 403, '\\\\-': 404, '\\\\&': 405, '[object': 406, 'Object]': 407, '8.5': 408, '20': 409, '0.9': 410, '0.4': 411, '0.14': 412}\n"
     ]
    }
   ],
   "source": [
    "print(latex_labels.shape)\n",
    "print(train_images.shape)\n",
    "vocab_dict = {name: id for id, name in enumerate(tokenizer.get_vocabulary())}\n",
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] \\langle x _ { 5 } ( \\tau _ { 1 } ) x _ { 5 } ( \\tau _ { 2 } ) \\rangle = 2 \\delta ( \\tau _ { 1 } , \\tau _ { 2 } ) . [END]\n",
      "[ 13 144  19   4   3 115   2   7  91   4   3  10   2   8  19   4   3 115\n",
      "   2   7  91   4   3   6   2   8 127   9   6  55   7  91   4   3  10   2\n",
      "  12  91   4   3   6   2   8  21  14   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0]\n",
      "[144  19   4   3 115   2   7  91   4   3  10   2   8  19   4   3 115   2\n",
      "   7  91   4   3   6   2   8 127   9   6  55   7  91   4   3  10   2  12\n",
      "  91   4   3   6   2   8  21  14   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.choice(range(train_images.shape[0]))\n",
    "image = train_images[idx]\n",
    "plt.imshow(image.numpy(), cmap=\"gray\")\n",
    "print(train_latex_texts[idx])\n",
    "print(input_labels[idx])\n",
    "print(output_labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yqt7tRm5AAI5"
   },
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Accx5CSIGji3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 10  # For real training, use num_epochs=100. 10 is a test value\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = EMBEDDING_DIM\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]\n",
    "\n",
    "lstm_units = 256\n",
    "max_seq_len_1 = max(len(seq) for seq in latex_labels) - 1\n",
    "print(num_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "XW0usbBPGATy"
   },
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        input_shape = tf.raw_ops.Shape(input=images)\n",
    "        batch_size = input_shape[0]\n",
    "        height = input_shape[1]\n",
    "        width = input_shape[2]\n",
    "        channels = input_shape[3]\n",
    "        num_patches_h = height // self.patch_size\n",
    "        num_patches_w = width // self.patch_size\n",
    "        patches = tf.image.extract_patches(images=images, sizes=[1,self.patch_size, self.patch_size,1], strides=[1,self.patch_size, self.patch_size,1], padding='VALID', rates=[1, 1, 1, 1])\n",
    "        new_shape = (batch_size, num_patches_h * num_patches_w, self.patch_size * self.patch_size * channels)\n",
    "        # print(f\"PATCHES: {patches.shape}\")\n",
    "        # print(f\"RESHAPE: {new_shape}\")\n",
    "        patches = tf.reshape(\n",
    "            patches,\n",
    "            shape=new_shape,\n",
    "        )\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image.numpy(), cmap=\"gray\")\n",
    "# plt.axis(\"off\")\n",
    "# image = tf.expand_dims(image, axis = 0)\n",
    "\n",
    "# print(f\"Image size: {image.shape}\")\n",
    "# patches = Patches(patch_size)(image)\n",
    "# print(f\"Image size: {image.shape}\")\n",
    "# print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "# print(f\"Patches per image: {patches.shape[1]}\")\n",
    "# print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "# n = int(np.sqrt(patches.shape[1]))\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# for i, patch in enumerate(patches[0]):\n",
    "#     ax = plt.subplot(n, n, i + 1)\n",
    "#     patch_img = tf.reshape(patch, (patch_size, patch_size, 1))\n",
    "#     plt.imshow(patch_img.numpy(), cmap='gray')\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "xnbps4-JHS4b"
   },
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = Dense(units, activation=tf.keras.activations.gelu)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "DWhOTG_7GRpx"
   },
   "outputs": [],
   "source": [
    "class PatchEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = Dense(units=projection_dim)\n",
    "        self.position_embedding = Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.raw_ops.ExpandDims(\n",
    "           input = tf.experimental.numpy.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patch)\n",
    "        #print(projected_patches.shape)\n",
    "        position_embeddings = self.position_embedding(positions)\n",
    "        #print(position_embeddings.shape)\n",
    "        encoded = projected_patches + position_embeddings\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "NHZEjUHRGYcS"
   },
   "outputs": [],
   "source": [
    "def vision_transformer_encoder(input_shape):\n",
    "    inputs =  Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    # representation = Flatten()(representation)\n",
    "    # representation = Dropout(0.2)(representation)\n",
    "    # Add MLP.\n",
    "    # features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.2)\n",
    "    # Classify outputs.\n",
    "    #logits = tf.keras.layers.Dense(2)(features)\n",
    "    # Create the Keras model.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=representation)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "T8jXN2GlGyNC"
   },
   "outputs": [],
   "source": [
    "vit = vision_transformer_encoder(IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "_1htX_wlLj4W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " patches_2 (Patches)         (None, 1764, 36)             0         ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " patch_encoder_2 (PatchEnco  (None, 1764, 256)            461056    ['patches_2[0][0]']           \n",
      " der)                                                                                             \n",
      "                                                                                                  \n",
      " layer_normalization_40 (La  (None, 1764, 256)            512       ['patch_encoder_2[0][0]']     \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (M  (None, 1764, 256)            1051904   ['layer_normalization_40[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_37 (Add)                (None, 1764, 256)            0         ['multi_head_attention_20[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'patch_encoder_2[0][0]']     \n",
      "                                                                                                  \n",
      " layer_normalization_41 (La  (None, 1764, 256)            512       ['add_37[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_40 (Dense)            (None, 1764, 512)            131584    ['layer_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)        (None, 1764, 512)            0         ['dense_40[0][0]']            \n",
      "                                                                                                  \n",
      " dense_41 (Dense)            (None, 1764, 256)            131328    ['dropout_38[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)        (None, 1764, 256)            0         ['dense_41[0][0]']            \n",
      "                                                                                                  \n",
      " add_38 (Add)                (None, 1764, 256)            0         ['dropout_39[0][0]',          \n",
      "                                                                     'add_37[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_42 (La  (None, 1764, 256)            512       ['add_38[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (M  (None, 1764, 256)            1051904   ['layer_normalization_42[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_39 (Add)                (None, 1764, 256)            0         ['multi_head_attention_21[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_38[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_43 (La  (None, 1764, 256)            512       ['add_39[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_42 (Dense)            (None, 1764, 512)            131584    ['layer_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)        (None, 1764, 512)            0         ['dense_42[0][0]']            \n",
      "                                                                                                  \n",
      " dense_43 (Dense)            (None, 1764, 256)            131328    ['dropout_40[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)        (None, 1764, 256)            0         ['dense_43[0][0]']            \n",
      "                                                                                                  \n",
      " add_40 (Add)                (None, 1764, 256)            0         ['dropout_41[0][0]',          \n",
      "                                                                     'add_39[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_44 (La  (None, 1764, 256)            512       ['add_40[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (M  (None, 1764, 256)            1051904   ['layer_normalization_44[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_41 (Add)                (None, 1764, 256)            0         ['multi_head_attention_22[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_40[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_45 (La  (None, 1764, 256)            512       ['add_41[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_44 (Dense)            (None, 1764, 512)            131584    ['layer_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)        (None, 1764, 512)            0         ['dense_44[0][0]']            \n",
      "                                                                                                  \n",
      " dense_45 (Dense)            (None, 1764, 256)            131328    ['dropout_42[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)        (None, 1764, 256)            0         ['dense_45[0][0]']            \n",
      "                                                                                                  \n",
      " add_42 (Add)                (None, 1764, 256)            0         ['dropout_43[0][0]',          \n",
      "                                                                     'add_41[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_46 (La  (None, 1764, 256)            512       ['add_42[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (M  (None, 1764, 256)            1051904   ['layer_normalization_46[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_43 (Add)                (None, 1764, 256)            0         ['multi_head_attention_23[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_42[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_47 (La  (None, 1764, 256)            512       ['add_43[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_46 (Dense)            (None, 1764, 512)            131584    ['layer_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)        (None, 1764, 512)            0         ['dense_46[0][0]']            \n",
      "                                                                                                  \n",
      " dense_47 (Dense)            (None, 1764, 256)            131328    ['dropout_44[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)        (None, 1764, 256)            0         ['dense_47[0][0]']            \n",
      "                                                                                                  \n",
      " add_44 (Add)                (None, 1764, 256)            0         ['dropout_45[0][0]',          \n",
      "                                                                     'add_43[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_48 (La  (None, 1764, 256)            512       ['add_44[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (M  (None, 1764, 256)            1051904   ['layer_normalization_48[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_48[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_45 (Add)                (None, 1764, 256)            0         ['multi_head_attention_24[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_44[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_49 (La  (None, 1764, 256)            512       ['add_45[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_48 (Dense)            (None, 1764, 512)            131584    ['layer_normalization_49[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)        (None, 1764, 512)            0         ['dense_48[0][0]']            \n",
      "                                                                                                  \n",
      " dense_49 (Dense)            (None, 1764, 256)            131328    ['dropout_46[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)        (None, 1764, 256)            0         ['dense_49[0][0]']            \n",
      "                                                                                                  \n",
      " add_46 (Add)                (None, 1764, 256)            0         ['dropout_47[0][0]',          \n",
      "                                                                     'add_45[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_50 (La  (None, 1764, 256)            512       ['add_46[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (M  (None, 1764, 256)            1051904   ['layer_normalization_50[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_50[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_47 (Add)                (None, 1764, 256)            0         ['multi_head_attention_25[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_46[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_51 (La  (None, 1764, 256)            512       ['add_47[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_50 (Dense)            (None, 1764, 512)            131584    ['layer_normalization_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)        (None, 1764, 512)            0         ['dense_50[0][0]']            \n",
      "                                                                                                  \n",
      " dense_51 (Dense)            (None, 1764, 256)            131328    ['dropout_48[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)        (None, 1764, 256)            0         ['dense_51[0][0]']            \n",
      "                                                                                                  \n",
      " add_48 (Add)                (None, 1764, 256)            0         ['dropout_49[0][0]',          \n",
      "                                                                     'add_47[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_52 (La  (None, 1764, 256)            512       ['add_48[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (M  (None, 1764, 256)            1051904   ['layer_normalization_52[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_52[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_49 (Add)                (None, 1764, 256)            0         ['multi_head_attention_26[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_48[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_53 (La  (None, 1764, 256)            512       ['add_49[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_52 (Dense)            (None, 1764, 512)            131584    ['layer_normalization_53[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)        (None, 1764, 512)            0         ['dense_52[0][0]']            \n",
      "                                                                                                  \n",
      " dense_53 (Dense)            (None, 1764, 256)            131328    ['dropout_50[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)        (None, 1764, 256)            0         ['dense_53[0][0]']            \n",
      "                                                                                                  \n",
      " add_50 (Add)                (None, 1764, 256)            0         ['dropout_51[0][0]',          \n",
      "                                                                     'add_49[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_54 (La  (None, 1764, 256)            512       ['add_50[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (M  (None, 1764, 256)            1051904   ['layer_normalization_54[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_54[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_51 (Add)                (None, 1764, 256)            0         ['multi_head_attention_27[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_50[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_55 (La  (None, 1764, 256)            512       ['add_51[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_54 (Dense)            (None, 1764, 512)            131584    ['layer_normalization_55[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)        (None, 1764, 512)            0         ['dense_54[0][0]']            \n",
      "                                                                                                  \n",
      " dense_55 (Dense)            (None, 1764, 256)            131328    ['dropout_52[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)        (None, 1764, 256)            0         ['dense_55[0][0]']            \n",
      "                                                                                                  \n",
      " add_52 (Add)                (None, 1764, 256)            0         ['dropout_53[0][0]',          \n",
      "                                                                     'add_51[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_56 (La  (None, 1764, 256)            512       ['add_52[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10988288 (41.92 MB)\n",
      "Trainable params: 10988288 (41.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, max_length, depth):\n",
    "    super().__init__()\n",
    "    self.pos_embedding = tf.keras.layers.Embedding(input_dim=max_length, output_dim=depth)\n",
    "\n",
    "    self.token_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=depth,\n",
    "        mask_zero=True)\n",
    "\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "  def call(self, seq):\n",
    "    seq = self.token_embedding(seq) # (batch, seq, depth)\n",
    "\n",
    "    x = tf.range(tf.shape(seq)[1])  # (seq)\n",
    "    x = x[tf.newaxis, :]  # (1, seq)\n",
    "    x = self.pos_embedding(x)  # (1, seq, depth)\n",
    "\n",
    "    return self.add([seq,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    # Use Add instead of + so the keras mask propagates through.\n",
    "    self.add = tf.keras.layers.Add() \n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    attn = self.mha(query=x, value=x,\n",
    "                    use_causal_mask=True)\n",
    "    x = self.add([x, attn])\n",
    "    return self.layernorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self,**kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.add = tf.keras.layers.Add() \n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x, y, **kwargs):\n",
    "    attn, attention_scores = self.mha(\n",
    "             query=x, value=y,\n",
    "             return_attention_scores=True)\n",
    "\n",
    "    self.last_attention_scores = attention_scores\n",
    "\n",
    "    x = self.add([x, attn])\n",
    "    return self.layernorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=2*units, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=units),\n",
    "        tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "    ])\n",
    "\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = x + self.seq(x)\n",
    "    return self.layernorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, num_heads=1, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = CausalSelfAttention(num_heads=num_heads,\n",
    "                                              key_dim=units,\n",
    "                                              dropout=dropout_rate)\n",
    "    self.cross_attention = CrossAttention(num_heads=num_heads,\n",
    "                                          key_dim=units,\n",
    "                                          dropout=dropout_rate)\n",
    "    self.ff = FeedForward(units=units, dropout_rate=dropout_rate)\n",
    "\n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "    in_seq, out_seq = inputs\n",
    "\n",
    "    # Text input\n",
    "    out_seq = self.self_attention(out_seq)\n",
    "\n",
    "    out_seq = self.cross_attention(out_seq, in_seq)\n",
    "\n",
    "    self.last_attention_scores = self.cross_attention.last_attention_scores\n",
    "\n",
    "    out_seq = self.ff(out_seq)\n",
    "\n",
    "    return out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Captioner(tf.keras.Model):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, tokenizer, feature_extractor, output_layer, num_layers=1,\n",
    "               units=256, max_length=50, num_heads=1, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.feature_extractor = feature_extractor\n",
    "    self.tokenizer = tokenizer\n",
    "    self.word_to_index = tf.keras.layers.StringLookup(\n",
    "        mask_token=\"\",\n",
    "        vocabulary=tokenizer.get_vocabulary())\n",
    "    self.index_to_word = tf.keras.layers.StringLookup(\n",
    "        mask_token=\"\",\n",
    "        vocabulary=tokenizer.get_vocabulary(),\n",
    "        invert=True) \n",
    "\n",
    "    self.seq_embedding = SeqEmbedding(\n",
    "        vocab_size=tokenizer.vocabulary_size(),\n",
    "        depth=units,\n",
    "        max_length=max_length)\n",
    "\n",
    "    self.decoder_layers = [\n",
    "        DecoderLayer(units, num_heads=num_heads, dropout_rate=dropout_rate)\n",
    "        for n in range(num_layers)]\n",
    "\n",
    "    self.output_layer = output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Captioner.add_method\n",
    "def call(self, inputs):\n",
    "    image, txt = inputs\n",
    "    \n",
    "    image = self.feature_extractor(image)\n",
    "    #print(image.shape)\n",
    "    # Flatten the feature map\n",
    "    \n",
    "    #image = einops.rearrange(image, 'b h w c -> b (h w) c')\n",
    "    \n",
    "    if txt.dtype == tf.string:\n",
    "      # Apply the tokenizer if you get string inputs.\n",
    "      txt = tokenizer(txt)\n",
    "    \n",
    "    txt = self.seq_embedding(txt)\n",
    "    \n",
    "    # Look at the image\n",
    "    for dec_layer in self.decoder_layers:\n",
    "      txt = dec_layer(inputs=(image, txt))\n",
    "    \n",
    "    txt = self.output_layer(txt)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "import tqdm\n",
    "class TokenOutput(tf.keras.layers.Layer):\n",
    "  def __init__(self, tokenizer, banned_tokens=('', '[UNK]'), **kwargs):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(\n",
    "        units=tokenizer.vocabulary_size(), **kwargs)\n",
    "    self.tokenizer = tokenizer\n",
    "    self.banned_tokens = banned_tokens\n",
    "\n",
    "    self.bias = None\n",
    "\n",
    "  def adapt(self, ds):\n",
    "    counts = collections.Counter()\n",
    "    vocab_dict = {name: id \n",
    "                  for id, name in enumerate(self.tokenizer.get_vocabulary())}\n",
    "\n",
    "    for tokens in ds:\n",
    "      counts.update(tokens.flatten())\n",
    "\n",
    "    counts_arr = np.zeros(shape=(self.tokenizer.vocabulary_size(),))\n",
    "    counts_arr[np.array(list(counts.keys()), dtype=np.int32)] = list(counts.values())\n",
    "\n",
    "    counts_arr = counts_arr[:]\n",
    "    for token in self.banned_tokens:\n",
    "      counts_arr[vocab_dict[token]] = 0\n",
    "\n",
    "    total = counts_arr.sum()\n",
    "    p = counts_arr/total\n",
    "    p[counts_arr==0] = 1.0\n",
    "    log_p = np.log(p)  # log(1) == 0\n",
    "\n",
    "    entropy = -(log_p*p).sum()\n",
    "\n",
    "    print()\n",
    "    print(f\"Uniform entropy: {np.log(self.tokenizer.vocabulary_size()):0.2f}\")\n",
    "    print(f\"Marginal entropy: {entropy:0.2f}\")\n",
    "\n",
    "    self.bias = log_p\n",
    "    self.bias[counts_arr==0] = -1e9\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.dense(x)\n",
    "    # TODO(b/250038731): Fix this.\n",
    "    # An Add layer doesn't work because of the different shapes.\n",
    "    # This clears the mask, that's okay because it prevents keras from rescaling\n",
    "    # the losses.\n",
    "    return x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uniform entropy: 6.02\n",
      "Marginal entropy: 3.86\n"
     ]
    }
   ],
   "source": [
    "output_layer = TokenOutput(tokenizer, banned_tokens=('', '[UNK]'))\n",
    "# This might run a little faster if the dataset didn't also have to load the image data.\n",
    "output_layer.adapt(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = Captioner(tokenizer, feature_extractor=vision_transformer_encoder(IMG_SHAPE), output_layer=output_layer,\n",
    "                  units=256, dropout_rate=0.5, num_layers=2, num_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Captioner.add_method\n",
    "def simple_gen(self, image, temperature=0):\n",
    "  initial = self.word_to_index([['[START]']]) # (batch, sequence)\n",
    "  #img_features = self.feature_extractor(image[tf.newaxis, ...])\n",
    "\n",
    "  tokens = initial # (batch, sequence)\n",
    "  for n in range(50):\n",
    "    preds = self((image[tf.newaxis, ...], tokens)).numpy()  # (batch, sequence, vocab)\n",
    "    preds = preds[:,-1, :]  #(batch, vocab)\n",
    "    if temperature==0:\n",
    "        next = tf.argmax(preds, axis=-1)[:, tf.newaxis]  # (batch, 1)\n",
    "    else:\n",
    "        next = tf.random.categorical(preds/temperature, num_samples=1)  # (batch, 1)\n",
    "    tokens = tf.concat([tokens, next], axis=1) # (batch, sequence) \n",
    "\n",
    "    if next[0] == self.word_to_index('[END]'):\n",
    "      break\n",
    "  words = self.index_to_word(tokens[0, 1:-1])\n",
    "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "  return result.numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n",
      "2 { T ^ & { { [START] \\equiv } m { { / \\; \\equiv _\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)\n",
    "result = transformer_model.simple_gen(image, temperature=0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(labels, preds):  \n",
    "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, preds)\n",
    "\n",
    "  mask = (labels != 0) & (loss < 1e8) \n",
    "  mask = tf.cast(mask, loss.dtype)\n",
    "\n",
    "  loss = loss*mask\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "def masked_acc(labels, preds):\n",
    "  mask = tf.cast(labels!=0, tf.float32)\n",
    "  preds = tf.argmax(preds, axis=-1)\n",
    "  labels = tf.cast(labels, tf.int64)\n",
    "  match = tf.cast(preds == labels, mask.dtype)\n",
    "  acc = tf.reduce_sum(match*mask)/tf.reduce_sum(mask)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateText(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.image = image\n",
    "\n",
    "  def on_epoch_end(self, epochs=None, logs=None):\n",
    "    print()\n",
    "    print()\n",
    "    result = self.model.simple_gen(self.image, temperature=0)\n",
    "    print(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2 _ { ~ } } { { e } 0 _\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = GenerateText()\n",
    "g.model = transformer_model\n",
    "g.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_filepath = 'transformer_model'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',  # Save the model with the best validation loss\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_format='tf'\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    GenerateText(),\n",
    "    model_checkpoint_callback,\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, restore_best_weights=True, monitor='val_masked_acc')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "           loss=masked_loss,\n",
    "           metrics=[masked_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"captioner_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_3 (Functional)        (None, 1764, 256)         10988288  \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  multiple                  0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " string_lookup_4 (StringLoo  multiple                  0         \n",
      " kup)                                                            \n",
      "                                                                 \n",
      " string_lookup_5 (StringLoo  multiple                  0         \n",
      " kup)                                                            \n",
      "                                                                 \n",
      " seq_embedding_1 (SeqEmbedd  multiple                  118528    \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " decoder_layer_2 (DecoderLa  multiple                  1316608   \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " decoder_layer_3 (DecoderLa  multiple                  1316608   \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " token_output_1 (TokenOutpu  multiple                  106141    \n",
      " t)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13846173 (52.82 MB)\n",
      "Trainable params: 13846173 (52.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "int64\n",
      "[[ 13 178  83 ...   0   0   0]\n",
      " [ 13   7   3 ...   0   0   0]\n",
      " [ 13  62   4 ...   0   0   0]\n",
      " ...\n",
      " [ 13  54   3 ...   0   0   0]\n",
      " [ 13  71   9 ...   0   0   0]\n",
      " [ 13  22   4 ...   0   0   0]]\n",
      "[[178  83   4 ...   0   0   0]\n",
      " [  7   3  57 ...   0   0   0]\n",
      " [ 62   4   3 ...   0   0   0]\n",
      " ...\n",
      " [ 54   3  23 ...   0   0   0]\n",
      " [ 71   9  75 ...   0   0   0]\n",
      " [ 22   4   3 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(len(train_sequences))\n",
    "print(train_sequences.dtype)\n",
    "print(input_labels)\n",
    "print(output_labels)\n",
    "# print(train_sequences)\n",
    "# print(train_sequences[..., :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 2.9356 - masked_acc: 0.3784\n",
      "\n",
      "f ^ { \\mu } = n , ~ ~ ~ .\n",
      "\n",
      "8000/8000 [==============================] - 3477s 430ms/step - loss: 2.9356 - masked_acc: 0.3784 - val_loss: 2.6120 - val_masked_acc: 0.4316\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 2.6190 - masked_acc: 0.4209\n",
      "\n",
      "G ^ { a } = e ^ { - 1 / ( \\varphi S , \\quad , \\quad N ) = \\; \\; \\; \\; ,\n",
      "\n",
      "8000/8000 [==============================] - 3451s 431ms/step - loss: 2.6190 - masked_acc: 0.4209 - val_loss: 2.4661 - val_masked_acc: 0.4525\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 2.4912 - masked_acc: 0.4384\n",
      "\n",
      "G _ { B } ( x ) = \\frac { B - \\lambda } { \\partial ( X ) + \\phi ,\n",
      "\n",
      "8000/8000 [==============================] - 3453s 432ms/step - loss: 2.4912 - masked_acc: 0.4384 - val_loss: 2.3739 - val_masked_acc: 0.4661\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 2.4088 - masked_acc: 0.4501\n",
      "\n",
      "\\delta S _ { F } = \\partial _ { i } \\partial _ { \\mu } \\Omega _ { \\nu } \\mu _ { \\mu \\nu } F _ { \\mu \\nu } A _ { \\mu \\nu } + \\lambda _ { \\nu } .\n",
      "\n",
      "8000/8000 [==============================] - 3455s 432ms/step - loss: 2.4088 - masked_acc: 0.4501 - val_loss: 2.3242 - val_masked_acc: 0.4715\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 2.3456 - masked_acc: 0.4586\n",
      "\n",
      "\\zeta _ { ~ h } ^ { \\mu \\beta \\alpha } \\theta ^ { * } \\mathcal { A } _ { \\alpha \\beta } ( \\alpha ) \\delta ^ { \\prime } ( x )\n",
      "\n",
      "8000/8000 [==============================] - 3459s 432ms/step - loss: 2.3456 - masked_acc: 0.4586 - val_loss: 2.2689 - val_masked_acc: 0.4839\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 2.2970 - masked_acc: 0.4653\n",
      "\n",
      "S \\cdot x ) = C h _ { 2 } ( y - 1 ) .\n",
      "\n",
      "8000/8000 [==============================] - 3441s 430ms/step - loss: 2.2970 - masked_acc: 0.4653 - val_loss: 2.2479 - val_masked_acc: 0.4843\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 2.2549 - masked_acc: 0.4715\n",
      "\n",
      "u _ { b c } \\omega ^ { b } = A _ { b u } \\partial _ { d } Q _ { b } ,\n",
      "\n",
      "8000/8000 [==============================] - 3460s 432ms/step - loss: 2.2549 - masked_acc: 0.4715 - val_loss: 2.2266 - val_masked_acc: 0.4868\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 2.2246 - masked_acc: 0.4763\n",
      "\n",
      "\\delta B _ { \\theta } ^ { \\prime } + i \\vec { B } + \\alpha P ^ { \\prime } ^ { \\prime } - 1\n",
      "\n",
      "8000/8000 [==============================] - 3460s 433ms/step - loss: 2.2246 - masked_acc: 0.4763 - val_loss: 2.2039 - val_masked_acc: 0.4947\n",
      "Epoch 9/100\n",
      "6849/8000 [========================>.....] - ETA: 7:38 - loss: 2.1899 - masked_acc: 0.4819"
     ]
    }
   ],
   "source": [
    "history = transformer_model.fit([train_images, input_labels],\n",
    "              output_labels,\n",
    "              epochs=100,\n",
    "              batch_size=1,\n",
    "              validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSQExklGAAI7"
   },
   "outputs": [],
   "source": [
    "def build_cnn_encoder(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(EMBEDDING_DIM, activation='relu')(x)\n",
    "    return Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "md8Xz7JzAAI7"
   },
   "outputs": [],
   "source": [
    "def build_rnn_encoder(decoder_input, encoder_output, target_vocab_size, max_seq_len_1):\n",
    "\n",
    "    embedding_layer = Embedding(input_dim=target_vocab_size, output_dim=EMBEDDING_DIM, input_length=max_seq_len_1)\n",
    "    embedded_seq = embedding_layer(decoder_input)\n",
    "\n",
    "    decoder_lstm_input = tf.keras.layers.Concatenate(axis=-1)([encoder_output, embedded_seq])\n",
    "    decoder_lstm = LSTM(lstm_units, return_sequences=True)(decoder_lstm_input)\n",
    "    decoder_output = TimeDistributed(Dense(target_vocab_size, activation=\"softmax\"))(decoder_lstm)\n",
    "\n",
    "    return Model(inputs=[decoder_input, encoder_output], outputs= decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "xWJwvgriAAI7"
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_layers, d_model, num_heads, dff, target_vocab_size, max_seq_len_1):\n",
    "    #encoder = build_cnn_encoder(input_shape)\n",
    "    encoder = vision_transformer_encoder(input_shape)\n",
    "    image_input = Input(shape=input_shape, name=\"image_input\")\n",
    "\n",
    "    encoder_output = encoder(image_input)\n",
    "    encoder_output = RepeatVector(max_seq_len_1)(encoder_output)  # Repeat encoder output for each time step\n",
    "\n",
    "    decoder_input = Input(shape=(max_seq_len_1,), name=\"decoder_input\")\n",
    "    decoder = build_rnn_encoder(decoder_input, encoder_output, target_vocab_size, max_seq_len_1)\n",
    "\n",
    "    decoder_output = decoder([decoder_input, encoder_output])\n",
    "    return Model(inputs=[image_input, decoder_input], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "DeU4cNTsAAI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 256)\n",
      "(1, 1764, 256)\n",
      "(None, None, 256)\n",
      "(1, 1764, 256)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"repeat_vector_5\" is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: (None, 1764, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[194], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMG_SHAPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocabulary_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_len_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#transformer_model = Transformer(tokenizer, output_layer=output_layer, units=128, dropout_rate=0.5, num_layers=2, num_heads=2)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[193], line 7\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, num_layers, d_model, num_heads, dff, target_vocab_size, max_seq_len_1)\u001b[0m\n\u001b[1;32m      4\u001b[0m image_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m encoder(image_input)\n\u001b[0;32m----> 7\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mRepeatVector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_seq_len_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Repeat encoder output for each time step\u001b[39;00m\n\u001b[1;32m      9\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(max_seq_len_1,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m decoder \u001b[38;5;241m=\u001b[39m build_rnn_encoder(decoder_input, encoder_output, target_vocab_size, max_seq_len_1)\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/keras/src/engine/input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    237\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"repeat_vector_5\" is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: (None, 1764, 256)"
     ]
    }
   ],
   "source": [
    "model = build_model(IMG_SHAPE, 2, 256, 2, 256, tokenizer.vocabulary_size(), max_seq_len_1)\n",
    "#transformer_model = Transformer(tokenizer, output_layer=output_layer, units=128, dropout_rate=0.5, num_layers=2, num_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "ba5W_OZFAAI8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_input (InputLayer)    [(None, 50, 200, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " model_15 (Functional)       (None, 512)                  1380070   ['image_input[0][0]']         \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)  [(None, 91)]                 0         []                            \n",
      "                                                                                                  \n",
      " repeat_vector_4 (RepeatVec  (None, 91, 512)              0         ['model_15[0][0]']            \n",
      " tor)                                                                                             \n",
      "                                                                                                  \n",
      " model_16 (Functional)       (None, 91, 385)              1247105   ['decoder_input[0][0]',       \n",
      "                                                                     'repeat_vector_4[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15047809 (57.40 MB)\n",
      "Trainable params: 15047809 (57.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "eDbtc_4eAAI8"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#tf.keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "FZZrLb4DAAI8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 91)\n",
      "(50000, 91)\n",
      "(50000, 92)\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences[..., :-1].shape)\n",
    "print(train_sequences[..., 1:].shape)\n",
    "print(train_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "lzmbXT3WAAI8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - 611s 935ms/step - loss: 1.6553 - accuracy: 0.7445 - val_loss: 1.6281 - val_accuracy: 0.7468\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 575s 920ms/step - loss: 1.6359 - accuracy: 0.7457 - val_loss: 1.6268 - val_accuracy: 0.7468\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 573s 917ms/step - loss: 1.6351 - accuracy: 0.7457 - val_loss: 1.6265 - val_accuracy: 0.7468\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 573s 917ms/step - loss: 1.6345 - accuracy: 0.7457 - val_loss: 1.6269 - val_accuracy: 0.7468\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 572s 916ms/step - loss: 1.6337 - accuracy: 0.7457 - val_loss: 1.6250 - val_accuracy: 0.7468\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 573s 917ms/step - loss: 1.6411 - accuracy: 0.7457 - val_loss: 1.6317 - val_accuracy: 0.7468\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 572s 915ms/step - loss: 1.6391 - accuracy: 0.7457 - val_loss: 1.6297 - val_accuracy: 0.7468\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 572s 915ms/step - loss: 1.6367 - accuracy: 0.7457 - val_loss: 1.6270 - val_accuracy: 0.7468\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 571s 914ms/step - loss: 1.6348 - accuracy: 0.7457 - val_loss: 1.6258 - val_accuracy: 0.7468\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 571s 914ms/step - loss: 1.6333 - accuracy: 0.7457 - val_loss: 1.6238 - val_accuracy: 0.7468\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 572s 915ms/step - loss: 1.6316 - accuracy: 0.7457 - val_loss: 1.6225 - val_accuracy: 0.7468\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 572s 915ms/step - loss: 1.6303 - accuracy: 0.7457 - val_loss: 1.6213 - val_accuracy: 0.7468\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 572s 915ms/step - loss: 1.6293 - accuracy: 0.7457 - val_loss: 1.6207 - val_accuracy: 0.7468\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 571s 915ms/step - loss: 1.6282 - accuracy: 0.7457 - val_loss: 1.6199 - val_accuracy: 0.7468\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 572s 915ms/step - loss: 1.6273 - accuracy: 0.7457 - val_loss: 1.6182 - val_accuracy: 0.7468\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 571s 914ms/step - loss: 1.6268 - accuracy: 0.7457 - val_loss: 1.6180 - val_accuracy: 0.7468\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 572s 915ms/step - loss: 1.6262 - accuracy: 0.7457 - val_loss: 1.6174 - val_accuracy: 0.7468\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 571s 914ms/step - loss: 1.6255 - accuracy: 0.7457 - val_loss: 1.6174 - val_accuracy: 0.7468\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 571s 914ms/step - loss: 1.6252 - accuracy: 0.7457 - val_loss: 1.6163 - val_accuracy: 0.7468\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 572s 915ms/step - loss: 1.6403 - accuracy: 0.7453 - val_loss: 1.6250 - val_accuracy: 0.7468\n",
      "Epoch 21/100\n",
      "108/625 [====>.........................] - ETA: 7:17 - loss: 1.6285 - accuracy: 0.7468"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtrain_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit([train_images, train_sequences[..., :-1]],\n",
    "              train_sequences[..., 1:],\n",
    "              epochs=100,\n",
    "              batch_size=64,\n",
    "              validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGz_H92VAAI8"
   },
   "outputs": [],
   "source": [
    "transformer_model.save('/home/ubuntu/model_av.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdeua_LzAAI9"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePe5hVCKG0df"
   },
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.fit([train_images, train_sequences[:, :-1]],\n",
    "              train_sequences[:, 1:],\n",
    "              epochs=20,\n",
    "              batch_size=128,\n",
    "              validation_split=0.2)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save('/home/ubuntu/latex_model.keras')\n",
    "\n",
    "#model = load_model('latex_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_u6gxZzWVRk"
   },
   "outputs": [],
   "source": [
    "#dot_img_file =\n",
    "import keras\n",
    "keras.utils.plot_model(model,\n",
    "                       show_shapes=True,\n",
    "                       show_dtype=True,\n",
    "                       show_layer_names=True,\n",
    "                       expand_nested=True,\n",
    "                       show_layer_activations=True,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_WwX-x7YWRb"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.utils.plot_model(model,\n",
    "                       show_shapes=True,\n",
    "                       show_dtype=True,\n",
    "                       show_layer_names=True,\n",
    "                       expand_nested=True,\n",
    "                       show_layer_activations=True,\n",
    "                       to_file='/Users/jayaprakash/latex_model.png'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixV3kbyDPr8X"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjCZXuZ_Jn-x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_latex_sequence(model, image, tokenizer):\n",
    "    \"\"\"\n",
    "    Predict LaTeX sequence from a single image.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained Keras model for predicting LaTeX sequence.\n",
    "    - image: Input image (preprocessed to match training dimensions).\n",
    "    - tokenizer: Tokenizer fitted on LaTeX sequences for decoding predictions.\n",
    "    - max_seq_len: Maximum sequence length for the predicted sequence.\n",
    "\n",
    "    Returns:\n",
    "    - latex_sequence: Predicted LaTeX sequence as a string.\n",
    "    \"\"\"\n",
    "    # Prepare input image and initialize the sequence\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    start_token = tokenizer.word_index[\"<START>\"]\n",
    "    end_token = tokenizer.word_index[\"<END>\"]\n",
    "\n",
    "    # Initial sequence with the start token\n",
    "    sequence = [start_token]\n",
    "\n",
    "    for _ in range(max_seq_len_1):\n",
    "        # Pad the current sequence to match input length\n",
    "        padded_sequence = np.pad(sequence, (0, max_seq_len_1 - len(sequence)), mode='constant')\n",
    "        padded_sequence = np.expand_dims(padded_sequence, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Predict next token\n",
    "        preds = model.predict([image, padded_sequence])\n",
    "        next_token = np.argmax(preds[0, len(sequence) - 1, :])\n",
    "\n",
    "        # Break if end token is reached\n",
    "        if next_token == end_token:\n",
    "            break\n",
    "\n",
    "        # Add the predicted token to the sequence\n",
    "        sequence.append(next_token)\n",
    "\n",
    "    # Decode the token sequence to a string\n",
    "    latex_sequence = tokenizer.sequences_to_texts([sequence[1:]])[0]  # Skip the start token\n",
    "    return latex_sequence\n",
    "\n",
    "predicted_latex = predict_latex_sequence(model, train_images[12], tokenizer)\n",
    "print(\"Predicted LaTeX:\", predicted_latex)\n",
    "#print(\"Original Seq:\", train_sequences[0])\n",
    "print(\"Original Seq:\", train_latex_texts[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIlv7RgvQZ9y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9MKLOc1REDl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
